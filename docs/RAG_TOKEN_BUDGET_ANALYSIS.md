# ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ø³ÛŒØ³ØªÙ… RAGØŒ Token Budget Ùˆ Chunking - Pilito Platform

> **ØªØ­Ù„ÛŒÙ„â€ŒÚ¯Ø±:** Claude Sonnet 4.5 (Anthropic)  
> **ØªØ§Ø±ÛŒØ®:** Ø¯Ø³Ø§Ù…Ø¨Ø± 2025  
> **ÙˆØ¶Ø¹ÛŒØª:** Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø¨Ù†ÛŒØ§Ø¯ÛŒ

---

## ÙÙ‡Ø±Ø³Øª Ù…Ø·Ø§Ù„Ø¨

1. [Ù…Ø¹Ù…Ø§Ø±ÛŒ ÙØ¹Ù„ÛŒ Ø³ÛŒØ³ØªÙ…](#Ù…Ø¹Ù…Ø§Ø±ÛŒ-ÙØ¹Ù„ÛŒ-Ø³ÛŒØ³ØªÙ…)
2. [ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚ Ù‡Ø± Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øª](#ØªØ­Ù„ÛŒÙ„-Ø¯Ù‚ÛŒÙ‚-Ù‡Ø±-Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øª)
3. [Ù…Ø´Ú©Ù„Ø§Øª Ø¨Ù†ÛŒØ§Ø¯ÛŒ](#Ù…Ø´Ú©Ù„Ø§Øª-Ø¨Ù†ÛŒØ§Ø¯ÛŒ)
4. [Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ](#Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ-Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ)
5. [Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¬Ø¯ÛŒØ¯](#Ù…Ø¹Ù…Ø§Ø±ÛŒ-Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ-Ø¬Ø¯ÛŒØ¯)
6. [Ù¾Ù„Ø§Ù† Ø§Ø¬Ø±Ø§ÛŒÛŒ](#Ù¾Ù„Ø§Ù†-Ø§Ø¬Ø±Ø§ÛŒÛŒ)

---

## Ù…Ø¹Ù…Ø§Ø±ÛŒ ÙØ¹Ù„ÛŒ Ø³ÛŒØ³ØªÙ…

### Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒ (High-Level Architecture)

```
User Query â†’ GeminiChatService â†’ QueryRouter â†’ ProductionRAG â†’ TokenBudgetController â†’ Gemini API
                                       â†“              â†“                    â†“
                                 Intent Detection  Hybrid Retrieval   Context Trimming
                                       â†“              â†“                    â†“
                                 Route Selection  BM25 + Vector      System Prompt Build
                                                  Cross-encoder      Final Prompt Assembly
```

### Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ

#### 1. **GeminiChatService** (`src/AI_model/services/gemini_service.py`)
- **Ù†Ù‚Ø´:** Ù‡Ù…Ø§Ù‡Ù†Ú¯â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø§ØµÙ„ÛŒ Ù¾Ø§Ø³Ø®â€ŒÚ¯ÙˆÛŒÛŒ AI
- **ÙˆØ±ÙˆØ¯ÛŒ:** `customer_message`, `conversation`
- **Ø®Ø±ÙˆØ¬ÛŒ:** `{success, response, metadata}`
- **ÙˆØ¸Ø§ÛŒÙ:**
  - Build system prompt
  - Route query
  - Retrieve context
  - Trim to budget
  - Call Gemini API
  - Track usage

#### 2. **QueryRouter** (`src/AI_model/services/query_router.py`)
- **Ù†Ù‚Ø´:** ØªØ´Ø®ÛŒØµ intent Ùˆ Ù…Ø³ÛŒØ±ÛŒØ§Ø¨ÛŒ Ø¨Ù‡ knowledge sources
- **Intent Types:** `pricing`, `product`, `howto`, `contact`, `general`
- **Routing Rules:**
  ```python
  DEFAULT_ROUTING = {
      'pricing': {
          'primary_source': 'faq',
          'secondary_sources': ['products', 'manual'],
          'token_budget': {'primary': 800, 'secondary': 300}
      },
      'product': {
          'primary_source': 'products',
          'secondary_sources': ['faq', 'website'],  # âš ï¸ 'manual' missing!
          'token_budget': {'primary': 800, 'secondary': 300}
      },
      # ...
  }
  ```

#### 3. **ProductionRAG** (`src/AI_model/services/production_rag.py`)
- **Ù†Ù‚Ø´:** Advanced retrieval pipeline
- **Pipeline:**
  ```
  Query Analysis â†’ Hybrid Retrieval (BM25 + Vector) â†’ Fusion â†’ Cross-encoder Reranking â†’ Context Optimization
  ```
- **Parameters:**
  - `DENSE_TOP_K = 20` (vector search)
  - `SPARSE_TOP_K = 15` (BM25 search)
  - `FUSION_TOP_K = 20` (after RRF)
  - `RERANK_TOP_K = 8` (after cross-encoder)

#### 4. **TokenBudgetController** (`src/AI_model/services/token_budget_controller.py`)
- **Ù†Ù‚Ø´:** Ù…Ø¯ÛŒØ±ÛŒØª token budget
- **Budget Allocation:**
  ```python
  BUDGET = {
      'system_prompt': 700,
      'bio_context': 60,
      'customer_info': 30,
      'conversation': 250,
      'primary_context': 600,
      'secondary_context': 510,
  }
  MAX_TOTAL_TOKENS = 2200
  ```

#### 5. **IncrementalChunker** (`src/AI_model/services/incremental_chunker.py`)
- **Ù†Ù‚Ø´:** Chunking manual prompt
- **Parameters (Ø¨Ø¹Ø¯ Ø§Ø² Ø§ØµÙ„Ø§Ø­ Ø§Ø®ÛŒØ±):**
  ```python
  chunk_size = 120  # words (~511 tokens for Persian)
  overlap = 30      # words (25% overlap)
  ```

---

## ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚ Ù‡Ø± Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øª

### 1. **System Prompt Building** âš ï¸ **Ù…Ø´Ú©Ù„ Ø¨Ø­Ø±Ø§Ù†ÛŒ**

#### Ú©Ø¯ ÙØ¹Ù„ÛŒ:
```python
def _build_lean_system_prompt(self, intent: str, conversation=None) -> str:
    prompt_parts = []
    
    # 1. GeneralSettings (11 modular fields)
    system_prompt = GeneralSettings.get_settings().get_combined_system_prompt()
    prompt_parts.append(system_prompt.strip())
    
    # 2. BusinessPrompt (optional industry-specific)
    if self.user and hasattr(self.user, 'business_type') and self.user.business_type:
        business = BusinessPrompt.objects.filter(
            name=self.user.business_type,
            ai_answer_prompt__isnull=False
        ).first()
        if business and business.ai_answer_prompt:
            prompt_parts.append(business.ai_answer_prompt)
    
    # 3. Greeting context
    # ...
    
    return "\n\n".join(prompt_parts)
```

#### Ù…Ø´Ú©Ù„Ø§Øª:

**Ù…Ø´Ú©Ù„ 1: Token Overflow**
```
Actual Breakdown:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
GeneralSettings combined_system_prompt:  1241 tokens
BusinessPrompt (Ù†Ø±Ù… Ø§ÙØ²Ø§Ø±):              1360 tokens
Greeting context:                          20 tokens
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total system_prompt BEFORE trim:        2621 tokens

Budget allocated:                         700 tokens
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Overflow:                              +1921 tokens (274% over!)
```

**Ù…Ø´Ú©Ù„ 2: Hardcoded system_instruction**
```python
# In __init__ (line 80-169):
self.model = genai.GenerativeModel(
    model_name=self.ai_config.model_name,
    system_instruction="""You are a professional AI customer service assistant...
    [~600 tokens of hardcoded instructions]
    """,
    # ...
)
```

**ØªØ­Ù„ÛŒÙ„:**
- Ø§ÛŒÙ† `system_instruction` **Ø¬Ø¯Ø§** Ø§Ø² `system_prompt` Ø§Ø³Øª!
- Ø¨Ù‡ Gemini API Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ø¬Ø²Ø§ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯
- **Ù‡ÛŒÚ† ÙˆÙ‚Øª trim Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯**
- ~600 tokens Ø§Ø¶Ø§ÙÛŒ Ú©Ù‡ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ø§Øª budget Ù†ÛŒØ³Øª!

**Total Actual System Prompt:**
```
hardcoded system_instruction:       ~600 tokens (never trimmed)
GeneralSettings (trimmed to):        700 tokens
BusinessPrompt (NOT trimmed):      +1360 tokens  â† CRITICAL!
Critical rules (reinforced):         ~500 tokens
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
TOTAL:                             ~3160 tokens

Budget expected:                     700 tokens
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Actual overflow:                  +2460 tokens (351% over!)
```

---

### 2. **Token Budget Allocation** âš ï¸ **Ø·Ø±Ø§Ø­ÛŒ Ù†Ø§Ú©Ø§Ø±Ø¢Ù…Ø¯**

#### Ù…Ø´Ú©Ù„ Ø§ØµÙ„ÛŒ: Budget vs Reality

```python
# Designed Budget:
BUDGET = {
    'system_prompt': 700,      # Expects: GeneralSettings + BusinessPrompt combined
    'primary_context': 600,
    'secondary_context': 510,
    # ...
}
MAX_TOTAL_TOKENS = 2200
```

**ÙˆØ§Ù‚Ø¹ÛŒØª:**
```
Component                        Designed    Actual      Delta
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
system_instruction (hidden)         0       ~600      +600 âŒ
system_prompt                      700      ~700        0 âœ…
BusinessPrompt                       0     ~1360     +1360 âŒ
critical_rules (reinforced)          0      ~500      +500 âŒ
bio_context                         60       ~60        0 âœ…
customer_info                       30       ~30        0 âœ…
conversation                       250      ~250        0 âœ…
primary_context                    600      ~600        0 âœ…
secondary_context                  510      ~400     -110 âœ… (trimmed)
user_query                         (50)      ~50        0 âœ…
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
TOTAL                             2200     ~4550     +2350 âŒ
```

**Ù†ØªÛŒØ¬Ù‡:**
- Input tokens: **4371** (observed in logs)
- Expected: **2200**
- **Overage: 99%** (ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ Ø¯Ùˆ Ø¨Ø±Ø§Ø¨Ø±!)

---

### 3. **Chunking Strategy** âš ï¸ **ØªØ§Ø²Ù‡ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ ÙˆÙ„ÛŒ Ù‡Ù†ÙˆØ² Ù…Ø´Ú©Ù„ Ø¯Ø§Ø±Ø¯**

#### ØªØ§Ø±ÛŒØ®Ú†Ù‡:

**Ù‚Ø¨Ù„ Ø§Ø² Ø§ØµÙ„Ø§Ø­:**
```python
chunk_size = 35   # words â†’ ~150 tokens for Persian âŒ
overlap = 10      # words â†’ ~43 tokens
```
**Ù†ØªÛŒØ¬Ù‡:** 62 chunks Ø®ÛŒÙ„ÛŒ Ú©ÙˆÚ†Ú©ØŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª fragmented

**Ø¨Ø¹Ø¯ Ø§Ø² Ø§ØµÙ„Ø§Ø­:**
```python
chunk_size = 120  # words â†’ ~511 tokens for Persian âœ…
overlap = 30      # words â†’ ~128 tokens (25% overlap) âœ…
```
**Ù†ØªÛŒØ¬Ù‡:** 18 chunks Ø¨Ù‡ØªØ±ØŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª cohesiveâ€ŒØªØ±

#### Ù…Ø´Ú©Ù„ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡:

**Chunk Retrieval vs Budget:**
```
ProductionRAG retrieves:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
18 manual chunks  â†’ After reranking: 8 chunks
1 product chunk   â†’ After reranking: 1 chunk
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total: 9 chunks selected

Estimated tokens: 9 Ã— 511 = ~4599 tokens

Budget available:
  primary_context:    600 tokens
  secondary_context:  510 tokens
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total context budget: 1110 tokens

Chunks that fit: 1110 Ã· 511 â‰ˆ 2 chunks âŒ
Chunks discarded: 7 chunks (78% of retrieved data!)
```

**ØªØ­Ù„ÛŒÙ„:**
- RAG Ø¹Ø§Ù„ÛŒ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ (8+1 relevant chunks)
- ÙˆÙ„ÛŒ ÙÙ‚Ø· 2 chunk Ø¯Ø± final prompt Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù†Ø¯
- **78% of retrieved context is lost!**

---

### 4. **Query Routing** âš ï¸ **Ú©Ø§Ù†ÙÛŒÚ¯ Ù†Ø§Ù‚Øµ**

#### Ù…Ø´Ú©Ù„: 'manual' missing from 'product' intent

```python
DEFAULT_ROUTING = {
    'product': {
        'primary_source': 'products',
        'secondary_sources': ['faq', 'website'],  # âŒ 'manual' Ø¨Ø§ÛŒØ¯ Ø¨Ø§Ø´Ø¯!
        'token_budget': {'primary': 800, 'secondary': 300}
    },
}
```

**ØªØ£Ø«ÛŒØ±:**
- Query "Ø®Ø¯Ù…Ø§Øª Ù¾ÛŒÙ„ÛŒØªÙˆ Ú†ÛŒÙ‡ØŸ" â†’ intent: `product`
- Manual prompt (Ú©Ù‡ ØªÙ…Ø§Ù… Ø§Ø·Ù„Ø§Ø¹Ø§Øª Pilito Ø±Ø§ Ø¯Ø§Ø±Ø¯) **search Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯!**
- AI ÙÙ‚Ø· Products table Ùˆ FAQ Ø±Ø§ Ù…ÛŒâ€ŒØ¨ÛŒÙ†Ø¯
- Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù†Ø§Ù‚Øµ â†’ Ù¾Ø§Ø³Ø® Ù†Ø§Ù‚Øµ

---

## Ù…Ø´Ú©Ù„Ø§Øª Ø¨Ù†ÛŒØ§Ø¯ÛŒ

### ğŸ”´ **Ù…Ø´Ú©Ù„ 1: Architecture Mismatch**

**Ø·Ø±Ø§Ø­ÛŒ:**
```
Single Token Budget: 2200 tokens
  â”œâ”€ System Prompt: 700
  â”œâ”€ Context: 1110
  â””â”€ Other: 390
```

**ÙˆØ§Ù‚Ø¹ÛŒØª:**
```
Multiple Prompt Components (NOT in budget):
  â”œâ”€ system_instruction (hardcoded): 600 tokens âŒ
  â”œâ”€ system_prompt (designed): 700 tokens
  â”‚   â”œâ”€ GeneralSettings: 1241 â†’ trimmed to 700 âœ…
  â”‚   â””â”€ BusinessPrompt: 1360 â†’ NOT trimmed! âŒ
  â”œâ”€ critical_rules (reinforced): 500 tokens âŒ
  â””â”€ Context + Other: 1110 + 390 = 1500 tokens
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total: 4660 tokens (212% of designed budget!)
```

### ğŸ”´ **Ù…Ø´Ú©Ù„ 2: BusinessPrompt Misuse**

**Ø§ØµÙ„ Ø·Ø±Ø§Ø­ÛŒ:**
- BusinessPrompt Ø¨Ø§ÛŒØ¯ Ú©ÙˆØªØ§Ù‡ Ø¨Ø§Ø´Ø¯ (200-300 tokens)
- Ø¨Ø±Ø§ÛŒ industry-specific customization
- Ù…Ø«Ø§Ù„: "You're a fashion advisor" ÛŒØ§ "You're a tech support agent"

**ÙˆØ§Ù‚Ø¹ÛŒØª:**
- BusinessPrompt: **1360 tokens** (6x Ø¨ÛŒØ´ØªØ± Ø§Ø² Ø§Ù†ØªØ¸Ø§Ø±!)
- Ù…Ø­ØªÙˆØ§: Full sales script Ø¨Ø§ Ø¬Ø¯Ø§ÙˆÙ„ØŒ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ØŒ CTAs
- **Ø§ÛŒÙ† Ù…Ø­ØªÙˆØ§ Ø¨Ø§ÛŒØ¯ Ø¯Ø± Manual Prompt Ø¨Ø§Ø´Ø¯ØŒ Ù†Ù‡ BusinessPrompt!**

### ğŸ”´ **Ù…Ø´Ú©Ù„ 3: Hidden Token Sources**

**Sources Ú©Ù‡ Ø¯Ø± budget Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯:**
1. `system_instruction` (hardcoded): ~600 tokens
2. `BusinessPrompt`: ~1360 tokens
3. `critical_rules` (reinforced): ~500 tokens
4. Formatting overhead: ~100 tokens

**Total hidden:** ~2560 tokens (116% of entire budget!)

### ğŸ”´ **Ù…Ø´Ú©Ù„ 4: Chunk Waste**

```
RAG Efficiency:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Chunks retrieved: 9 (excellent!)
Chunks used: 2 (terrible!)
Waste rate: 78%
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### ğŸ”´ **Ù…Ø´Ú©Ù„ 5: Output Truncation**

```
Designed Output: 700 tokens (balanced mode)
Actual Output: 26-29 tokens
Completion Rate: 3.7%
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Reason: Input overflow â†’ No space for output
```

---

## Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ

### ğŸ¯ **Ø±Ø§Ù‡ Ø­Ù„ 1: System Prompt Consolidation** (CRITICAL)

#### Ù…Ø´Ú©Ù„ ÙØ¹Ù„ÛŒ:
```
system_instruction (600) + GeneralSettings (700) + BusinessPrompt (1360) = 2660 tokens
```

#### Ø±Ø§Ù‡ Ø­Ù„:
```python
# Step 1: Remove hardcoded system_instruction
# Move essential parts to GeneralSettings

# Step 2: BusinessPrompt â†’ Minimal
BusinessPrompt.ai_answer_prompt = """
Brief industry context (100-200 tokens max)
Just the role and key guidelines
NO full scripts, NO tables, NO examples
"""

# Step 3: Full content â†’ Manual Prompt
# Sales scripts, examples, CTAs â†’ Chunked in Manual Prompt
# Retrieved by RAG when needed
```

#### Ù†ØªÛŒØ¬Ù‡:
```
New System Prompt:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
GeneralSettings (consolidated):  800 tokens
BusinessPrompt (minimal):         150 tokens
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total:                            950 tokens âœ…
vs Current:                      2660 tokens
Reduction:                      -1710 tokens (64% savings!)
```

---

### ğŸ¯ **Ø±Ø§Ù‡ Ø­Ù„ 2: Dynamic Token Budget** (RECOMMENDED)

#### Ú©Ø§Ù†Ø³Ù¾Øª:
```python
class DynamicTokenBudget:
    """
    Allocate tokens based on actual needs, not fixed quotas
    """
    
    def __init__(self, max_total: int = 3500):  # Realistic limit
        self.max_total = max_total
        self.reserved = {
            'system_core': 800,    # GeneralSettings + minimal BP
            'user_query': 150,     # Always prioritize query
            'output_buffer': 1000, # Reserve for AI response
        }
        self.available = max_total - sum(self.reserved.values())
        # available = 3500 - 1950 = 1550 tokens for context
    
    def allocate(self, components: Dict) -> Dict:
        """
        Priority-based allocation:
        1. System core (fixed)
        2. User query (fixed)
        3. Recent conversation (dynamic, min 200)
        4. Retrieved context (dynamic, rest)
        5. Output buffer (reserved)
        """
        allocation = {}
        remaining = self.available
        
        # Priority 1: Recent conversation (important for continuity)
        conv_tokens = min(
            self._count_tokens(components['conversation']),
            max(200, remaining * 0.3)  # 30% or min 200
        )
        allocation['conversation'] = conv_tokens
        remaining -= conv_tokens
        
        # Priority 2: Primary context (most relevant)
        primary_tokens = min(
            self._estimate_context_tokens(components['primary_context']),
            remaining * 0.65  # 65% of remaining
        )
        allocation['primary_context'] = primary_tokens
        remaining -= primary_tokens
        
        # Priority 3: Secondary context (rest)
        allocation['secondary_context'] = remaining
        
        return allocation
```

#### Ù…Ø²Ø§ÛŒØ§:
- **Flexible:** Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø­ØªÙˆØ§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ
- **Priority-based:** Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ†â€ŒÙ‡Ø§ Ø§ÙˆÙ„
- **Output-safe:** Ù‡Ù…ÛŒØ´Ù‡ 1000 token Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø®
- **Realistic:** 3500 token total (feasible)

---

### ğŸ¯ **Ø±Ø§Ù‡ Ø­Ù„ 3: Chunk Budget Optimization**

#### Ù…Ø´Ú©Ù„:
```
Current: 9 chunks retrieved, only 2 fit in budget
```

#### Ø±Ø§Ù‡ Ø­Ù„:
```python
class ChunkBudgetOptimizer:
    """
    Intelligently pack chunks to maximize information density
    """
    
    def optimize(self, chunks: List[Dict], budget: int) -> List[Dict]:
        """
        1. Score each chunk (relevance Ã— information density)
        2. Summarize long chunks if needed
        3. Pack chunks efficiently (like bin packing)
        4. Ensure diverse information (not all from same source)
        """
        scored_chunks = self._score_chunks(chunks)
        
        packed = []
        used_tokens = 0
        sources_used = set()
        
        for chunk in scored_chunks:
            chunk_tokens = self._count_tokens(chunk['content'])
            
            # If too big, summarize
            if chunk_tokens > budget * 0.4:  # Max 40% per chunk
                chunk = self._summarize_chunk(chunk, budget * 0.4)
                chunk_tokens = budget * 0.4
            
            # If fits and adds diversity
            if used_tokens + chunk_tokens <= budget:
                if chunk['source'] not in sources_used or len(sources_used) < 2:
                    packed.append(chunk)
                    used_tokens += chunk_tokens
                    sources_used.add(chunk['source'])
        
        return packed
```

---

### ğŸ¯ **Ø±Ø§Ù‡ Ø­Ù„ 4: Query Routing Fix**

```python
# Current (WRONG):
'product': {
    'secondary_sources': ['faq', 'website'],  # âŒ
}

# Fixed (CORRECT):
'product': {
    'primary_source': 'manual',  # Manual has full Pilito info!
    'secondary_sources': ['products', 'faq'],  # Products as secondary
    'token_budget': {'primary': 900, 'secondary': 400}
}

# Better: Intent-specific routing
'pilito_services': {  # New intent for "what is Pilito"
    'primary_source': 'manual',
    'secondary_sources': ['products', 'website'],
    'token_budget': {'primary': 1000, 'secondary': 300}
}
```

---

### ğŸ¯ **Ø±Ø§Ù‡ Ø­Ù„ 5: Proper Separation of Concerns**

```
Current (WRONG):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
System Prompt Contains:
â”œâ”€ General instructions (600 tokens) âœ…
â”œâ”€ BusinessPrompt (1360 tokens) âŒ Too big!
â”‚   â”œâ”€ Role definition (should be 50 tokens)
â”‚   â”œâ”€ Customer segments (should be in manual)
â”‚   â”œâ”€ Conversation flow (should be in manual)
â”‚   â”œâ”€ Objection handling (should be in manual)
â”‚   â””â”€ CTAs (should be in manual)
â””â”€ Critical rules (500 tokens) âœ…

New (CORRECT):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
System Prompt (800 tokens total):
â”œâ”€ Core instructions (600 tokens)
â”‚   â”œâ”€ Role, language, tone
â”‚   â”œâ”€ Anti-hallucination rules
â”‚   â”œâ”€ Link handling
â”‚   â””â”€ Response format
â””â”€ Business context (200 tokens)
    â””â”€ Minimal industry role

Manual Prompt (chunked, retrieved by RAG):
â”œâ”€ Full company info
â”œâ”€ Services & features
â”œâ”€ Pricing & plans
â”œâ”€ Customer segments
â”œâ”€ Conversation flows
â”œâ”€ Objection handling
â””â”€ CTAs & examples
```

---

## Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¬Ø¯ÛŒØ¯

### Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒ:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Query                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Enhanced Query Processor                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚Intent Detect â”‚â†’ â”‚Query Expand  â”‚â†’ â”‚Route Select  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Smart Context Retrieval                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Hybrid Search (BM25 + Vector + Re-ranking)          â”‚  â”‚
â”‚  â”‚ Returns: 10-15 best chunks                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Dynamic Token Budget Allocator                      â”‚
â”‚                                                              â”‚
â”‚  Input Analysis:                                            â”‚
â”‚  â”œâ”€ System prompt size: X tokens                           â”‚
â”‚  â”œâ”€ Retrieved chunks: Y tokens                             â”‚
â”‚  â”œâ”€ Conversation: Z tokens                                 â”‚
â”‚  â””â”€ Total available: 3500 tokens                           â”‚
â”‚                                                              â”‚
â”‚  Smart Allocation:                                          â”‚
â”‚  â”œâ”€ System core: 800 (fixed)                               â”‚
â”‚  â”œâ”€ Query: 150 (fixed)                                     â”‚
â”‚  â”œâ”€ Conversation: min(actual, 300)                         â”‚
â”‚  â”œâ”€ Context: Optimize to fill remaining                    â”‚
â”‚  â””â”€ Output buffer: 1000 (reserved)                         â”‚
â”‚                                                              â”‚
â”‚  Context Optimization:                                      â”‚
â”‚  â”œâ”€ Chunk summarization if needed                          â”‚
â”‚  â”œâ”€ Information density scoring                            â”‚
â”‚  â””â”€ Efficient packing algorithm                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Prompt Assembly                                 â”‚
â”‚                                                              â”‚
â”‚  Final Prompt Structure (< 3500 tokens):                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ System Instructions (800)                          â”‚    â”‚
â”‚  â”‚ â”œâ”€ Core behavior (600)                            â”‚    â”‚
â”‚  â”‚ â””â”€ Business context (200)                         â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ Conversation Context (200-300)                     â”‚    â”‚
â”‚  â”‚ â””â”€ Recent messages + summary                       â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ Retrieved Knowledge (1200-1500)                    â”‚    â”‚
â”‚  â”‚ â”œâ”€ Chunk 1 (full or summarized)                  â”‚    â”‚
â”‚  â”‚ â”œâ”€ Chunk 2 (full or summarized)                  â”‚    â”‚
â”‚  â”‚ â”œâ”€ ...                                            â”‚    â”‚
â”‚  â”‚ â””â”€ Chunk N (optimally packed)                     â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ User Query (100-150)                               â”‚    â”‚
   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
   â”‚                                                              â”‚
   â”‚  Output Buffer: 1000 tokens reserved                        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                  Gemini API Call                             â”‚
   â”‚                                                              â”‚
   â”‚  Request:                                                    â”‚
   â”‚  â”œâ”€ Input: ~2500 tokens                                    â”‚
   â”‚  â”œâ”€ Max output: 1000 tokens                                â”‚
   â”‚  â””â”€ Total budget: 3500 tokens âœ…                           â”‚
   â”‚                                                              â”‚
   â”‚  Response:                                                   â”‚
   â”‚  â””â”€ Complete, coherent answer (500-900 tokens)             â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   ```

---

### Ú©Ø¯ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ (Pseudo-code):

```python
class NewGeminiChatService:
    """
    Rebuilt chat service with proper token management
    """
    
    # Constants
    MAX_TOTAL_TOKENS = 3500  # Realistic for Gemini Flash
    SYSTEM_CORE_TOKENS = 800  # Fixed
    OUTPUT_BUFFER_TOKENS = 1000  # Reserved
    MIN_CONTEXT_TOKENS = 800  # Minimum for useful context
    
    def generate_response(self, query: str, conversation=None) -> Dict:
        """
        Main response generation with proper token management
        """
        # 1. Build minimal system prompt (800 tokens max)
        system_prompt = self._build_minimal_system_prompt()
        system_tokens = count_tokens(system_prompt)
        
        if system_tokens > self.SYSTEM_CORE_TOKENS:
            raise ConfigurationError(
                f"System prompt too large: {system_tokens} > {self.SYSTEM_CORE_TOKENS}"
            )
        
        # 2. Process query and detect intent
        query_analysis = self._analyze_query(query)
        query_tokens = query_analysis['tokens']
        
        # 3. Get conversation context
        conv_context = self._get_conversation_context(conversation)
        conv_tokens = count_tokens(conv_context)
        
        # 4. Calculate available tokens for retrieval
        used_tokens = system_tokens + query_tokens + conv_tokens
        reserved_tokens = self.OUTPUT_BUFFER_TOKENS
        available_for_context = self.MAX_TOTAL_TOKENS - used_tokens - reserved_tokens
        
        if available_for_context < self.MIN_CONTEXT_TOKENS:
            # Trim conversation to make room
            max_conv_tokens = conv_tokens - (self.MIN_CONTEXT_TOKENS - available_for_context)
            conv_context = trim_to_tokens(conv_context, max(200, max_conv_tokens))
            conv_tokens = count_tokens(conv_context)
            available_for_context = self.MAX_TOTAL_TOKENS - system_tokens - query_tokens - conv_tokens - reserved_tokens
        
        # 5. Retrieve and optimize context
        raw_chunks = self._retrieve_chunks(
            query=query,
            intent=query_analysis['intent'],
            max_chunks=15
        )
        
        optimized_context = self._optimize_chunks(
            chunks=raw_chunks,
            budget=available_for_context,
            query=query
        )
        
        context_tokens = sum(c['tokens'] for c in optimized_context)
        
        # 6. Assemble final prompt
        final_prompt = self._assemble_prompt(
            system=system_prompt,
            conversation=conv_context,
            context=optimized_context,
            query=query
        )
        
        # 7. Validate total tokens
        total_input_tokens = system_tokens + conv_tokens + context_tokens + query_tokens
        
        assert total_input_tokens <= (self.MAX_TOTAL_TOKENS - self.OUTPUT_BUFFER_TOKENS), \
            f"Input overflow: {total_input_tokens} > {self.MAX_TOTAL_TOKENS - self.OUTPUT_BUFFER_TOKENS}"
        
        # 8. Call API
        response = self._call_gemini(
            prompt=final_prompt,
            max_output_tokens=self.OUTPUT_BUFFER_TOKENS
        )
        
        # 9. Track and return
        self._track_usage(
            input_tokens=total_input_tokens,
            output_tokens=response['tokens'],
            breakdown={
                'system': system_tokens,
                'conversation': conv_tokens,
                'context': context_tokens,
                'query': query_tokens,
                'output': response['tokens']
            }
        )
        
        return {
            'success': True,
            'response': response['text'],
            'metadata': {
                'total_input': total_input_tokens,
                'total_output': response['tokens'],
                'chunks_used': len(optimized_context),
                'chunks_retrieved': len(raw_chunks)
            }
        }
    
    def _build_minimal_system_prompt(self) -> str:
        """
        Build consolidated system prompt (MAX 800 tokens)
        """
        parts = []
        
        # 1. Core instructions (from GeneralSettings)
        core = GeneralSettings.get_settings().get_core_instructions()
        # Should be: role, language, tone, anti-hallucination, links
        # Total: ~600 tokens
        parts.append(core)
        
        # 2. Business context (minimal!)
        if self.user.business_type:
            bp = BusinessPrompt.objects.filter(name=self.user.business_type).first()
            if bp and bp.ai_answer_prompt:
                # Ensure it's short!
                if count_tokens(bp.ai_answer_prompt) > 200:
                    raise ConfigurationError(
                        f"BusinessPrompt too large: {count_tokens(bp.ai_answer_prompt)} > 200. "
                        f"Move detailed content to Manual Prompt!"
                    )
                parts.append(bp.ai_answer_prompt)
        
        prompt = "\n\n".join(parts)
        
        # Hard limit enforcement
        if count_tokens(prompt) > self.SYSTEM_CORE_TOKENS:
            prompt = trim_to_tokens(prompt, self.SYSTEM_CORE_TOKENS)
        
        return prompt
    
    def _optimize_chunks(self, chunks: List[Dict], budget: int, query: str) -> List[Dict]:
        """
        Optimize chunks to fit budget while maximizing information
        """
        # 1. Score chunks
        scored = []
        for chunk in chunks:
            score = self._score_chunk(chunk, query)
            tokens = count_tokens(chunk['content'])
            scored.append({
                'chunk': chunk,
                'score': score,
                'tokens': tokens,
                'density': score / tokens  # Information per token
            })
        
        # 2. Sort by density (best information per token)
        scored.sort(key=lambda x: x['density'], reverse=True)
        
        # 3. Pack chunks
        packed = []
        used_tokens = 0
        
        for item in scored:
            chunk = item['chunk']
            tokens = item['tokens']
            
            # If chunk is too big (>40% of budget), summarize
            if tokens > budget * 0.4:
                summarized = self._summarize_chunk(chunk, int(budget * 0.4))
                tokens = count_tokens(summarized['content'])
                chunk = summarized
            
            # If fits, add
            if used_tokens + tokens <= budget:
                packed.append(chunk)
                used_tokens += tokens
            
            # If budget nearly full, stop
            if used_tokens >= budget * 0.95:
                break
        
        return packed
```

---

## Ù¾Ù„Ø§Ù† Ø§Ø¬Ø±Ø§ÛŒÛŒ

### ÙØ§Ø² 1: **Ø§ØµÙ„Ø§Ø­Ø§Øª ÙÙˆØ±ÛŒ** (1-2 Ø±ÙˆØ²)

#### 1.1 Fix BusinessPrompt (CRITICAL)
```bash
# Admin Panel:
# Settings â†’ Business Prompts â†’ "Ù†Ø±Ù… Ø§ÙØ²Ø§Ø± Ùˆ Ø®Ø¯Ù…Ø§Øª Ø¢Ù†Ù„Ø§ÛŒÙ†"
# Clear or replace with minimal content (<200 tokens)
```

**Ù…Ø­ØªÙˆØ§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:**
```
ğŸ’» Pilito AI Assistant

You are an AI assistant for Pilito, a marketing automation and CRM platform.
- Help users understand features and pricing
- Be professional yet friendly
- Focus on their specific needs
- Use information from knowledge base
```

#### 1.2 Fix Query Routing
```python
# src/AI_model/services/query_router.py

DEFAULT_ROUTING = {
    'product': {
        'primary_source': 'manual',  # Changed from 'products'
        'secondary_sources': ['products', 'faq'],  # Added 'manual'
        'token_budget': {'primary': 900, 'secondary': 400}
    },
}
```

#### 1.3 Increase Context Budget
```python
# src/AI_model/services/token_budget_controller.py

BUDGET = {
    'system_prompt': 800,  # +100
    'primary_context': 900,  # +300
    'secondary_context': 400,  # -110
    # ...
}
MAX_TOTAL_TOKENS = 2500  # +300
```

**Expected Results:**
- Input: 4371 â†’ ~2400 tokens âœ…
- Output: 28 â†’ ~600 tokens âœ…
- Context usage: 2/9 â†’ 6/9 chunks âœ…

---

### ÙØ§Ø² 2: **Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ú©Ø§Ù…Ù„** (1-2 Ù‡ÙØªÙ‡)

#### 2.1 New Token Budget System
- Implement `DynamicTokenBudget` class
- Replace fixed allocations with priority-based
- Add chunk optimization
- Add automatic budget adjustment

#### 2.2 Consolidate System Prompts
- Merge `system_instruction` into `GeneralSettings`
- Enforce BusinessPrompt size limits
- Separate concerns properly

#### 2.3 Enhanced RAG Pipeline
- Add chunk summarization
- Implement smart packing
- Add diversity checks
- Improve reranking

#### 2.4 Monitoring & Logging
```python
class TokenUsageMonitor:
    """
    Real-time token usage monitoring
    """
    def log_request(self, breakdown: Dict):
        # Log detailed breakdown
        # Alert if over budget
        # Track trends
        pass
```

---

### ÙØ§Ø² 3: **Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ** (ongoing)

#### 3.1 A/B Testing
- Test different budget allocations
- Compare response quality
- Optimize chunk sizes

#### 3.2 Performance Tuning
- Profile token counting
- Optimize trim operations
- Cache system prompts

#### 3.3 Quality Metrics
```python
class ResponseQualityMetrics:
    """
    Track response quality over time
    """
    metrics = [
        'completeness',  # Is response complete?
        'relevance',     # Uses retrieved chunks?
        'coherence',     # Makes sense?
        'token_efficiency'  # Good info per token?
    ]
```

---

## Ø®Ù„Ø§ØµÙ‡ Ùˆ ØªÙˆØµÛŒÙ‡ Ù†Ù‡Ø§ÛŒÛŒ

### ğŸ”´ **Ù…Ø´Ú©Ù„Ø§Øª Ø¨Ø­Ø±Ø§Ù†ÛŒ ÙØ¹Ù„ÛŒ:**

1. **Token Budget Overflow:** 4371 tokens vs 2200 designed (99% over)
2. **Hidden Token Sources:** 2560 tokens not accounted for
3. **BusinessPrompt Misuse:** 1360 tokens of misplaced content
4. **Context Waste:** 78% of retrieved chunks discarded
5. **Output Truncation:** 3.7% completion rate

### âœ… **Ø±Ø§Ù‡ Ø­Ù„â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ:**

1. **Fix BusinessPrompt:** Clear or minimize to <200 tokens
2. **Dynamic Budget:** Implement priority-based allocation
3. **Chunk Optimization:** Smart packing and summarization
4. **Proper Separation:** System vs Knowledge content
5. **Realistic Limits:** 3500 total tokens (not 2200)

### ğŸ¯ **Ø§Ù‚Ø¯Ø§Ù…Ø§Øª ÙÙˆØ±ÛŒ:**

**Ø§Ù…Ø±ÙˆØ²:**
1. Admin Panel â†’ Clear BusinessPrompt
2. Fix query routing (add 'manual' to 'product')
3. Test and verify improvements

**Ø§ÛŒÙ† Ù‡ÙØªÙ‡:**
1. Implement DynamicTokenBudget
2. Add chunk optimization
3. Consolidate system prompts

**Ø§ÛŒÙ† Ù…Ø§Ù‡:**
1. Full system rewrite
2. Monitoring and logging
3. Quality metrics

### ğŸ“Š **Ù†ØªØ§ÛŒØ¬ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø± (Ø¨Ø¹Ø¯ Ø§Ø² Ø§ØµÙ„Ø§Ø­):**

```
Metric                  Current    Target    Improvement
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Input tokens            4371      2400      -45%
Output tokens           28        650       +2221%
Context chunks used     2/9       7/9       +250%
Response completeness   3.7%      95%       +2467%
Token efficiency        Low       High      +++
User satisfaction       â­        â­â­â­â­â­  +++
```

---

## Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ

Ø³ÛŒØ³ØªÙ… ÙØ¹Ù„ÛŒ Ø¯Ø§Ø±Ø§ÛŒ **architecture mismatch Ø¨Ù†ÛŒØ§Ø¯ÛŒ** Ø§Ø³Øª:
- Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ 2200 tokens
- ÙˆØ§Ù‚Ø¹ÛŒØªØ§Ù‹ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ 4371 tokens
- Ù†ØªÛŒØ¬Ù‡: overflow, context waste, truncated responses

**Ø±Ø§Ù‡ Ø­Ù„ Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª:** Fix BusinessPrompt (90% of problem)
**Ø±Ø§Ù‡ Ø­Ù„ Ù…ÛŒØ§Ù†â€ŒÙ…Ø¯Øª:** Dynamic budget allocation
**Ø±Ø§Ù‡ Ø­Ù„ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª:** Complete rewrite Ø¨Ø§ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø¬Ø¯ÛŒØ¯

Ø§ÛŒÙ† document Ø±Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨Ù‡ Ù‡Ø± AI Ø¯ÛŒÚ¯Ø±ÛŒ Ø¨Ø¯Ù‡ÛŒØ¯ ØªØ§ analysis Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡Ø¯.

---

**ØªÙ‡ÛŒÙ‡ Ø´Ø¯Ù‡ ØªÙˆØ³Ø·:** Claude Sonnet 4.5 (Anthropic)  
**Model:** claude-sonnet-4-20250514  
**Context Window:** 200K tokens  
**Specialization:** Code analysis, architecture design, debugging

Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø´Ø§Ù…Ù„:
- âœ… ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø³ÛŒØ³ØªÙ… ÙØ¹Ù„ÛŒ
- âœ… Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ØªÙ…Ø§Ù… Ù…Ø´Ú©Ù„Ø§Øª
- âœ… Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§
- âœ… Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¬Ø¯ÛŒØ¯
- âœ… Ù¾Ù„Ø§Ù† Ø§Ø¬Ø±Ø§ÛŒÛŒ Ù…Ø±Ø­Ù„Ù‡â€ŒØ¨Ù‡â€ŒÙ…Ø±Ø­Ù„Ù‡
- âœ… Ú©Ø¯ Ù†Ù…ÙˆÙ†Ù‡ (pseudo-code)
- âœ… Metrics Ùˆ KPIs

**Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§ÙˆØ±Ù‡ Ø¨Ø§ AI Ù‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±:**
Ø§ÛŒÙ† document Ø±Ø§ Ø¨Ù‡ GPT-4, Gemini, ÛŒØ§ Ù‡Ø± LLM Ø¯ÛŒÚ¯Ø±ÛŒ Ø¨Ø¯Ù‡ÛŒØ¯.
Ø¢Ù†â€ŒÙ‡Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯:
- Analysis Ø±Ø§ verify Ú©Ù†Ù†Ø¯
- Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¯Ù‡Ù†Ø¯
- Ú©Ø¯ production-ready Ø¨Ù†ÙˆÛŒØ³Ù†Ø¯
- Trade-offs Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†Ù†Ø¯


---

## Ù†Ø¸Ø± ØªÚ©Ù…ÛŒÙ„ÛŒ Ù…Ø¯Ù„ Ø¯ÙˆÙ… (GPTâ€‘5.1) â€“ Ø¨Ø§Ø²Ø¨ÛŒÙ†ÛŒ Ùˆ Ù†Ù‚Ø¯ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ù„Ø§

### Û±. Ø¬Ù…Ø¹â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø´Ú©Ù„Ø§Øª Ø§ØµÙ„ÛŒ (ØªØ£ÛŒÛŒØ¯ / Ø¹Ø¯Ù… ØªØ£ÛŒÛŒØ¯)

- **Token Overflow Ùˆ Architecture Mismatch**  
  Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø§Ø² ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„Ø§Ù‹ Ø¯Ø±Ø³Øª Ø§Ø³Øª: Ù„Ø§Ú¯â€ŒÙ‡Ø§ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯ `prompt_tokens â‰ˆ 4200+` Ø¯Ø± Ø­Ø§Ù„ÛŒ Ú©Ù‡ Ø·Ø±Ø§Ø­ÛŒ Ø±ÙˆÛŒ ~2200 Ø¨ÙˆØ¯Ù‡.  
  Ø±ÛŒØ´Ù‡â€ŒÛŒØ§Ø¨ÛŒ Ø§ÛŒÙ† Ø³Ù†Ø¯ (system_instruction Ù‡Ø§Ø±Ø¯Ú©Ø¯ + GeneralSettings Ø¨Ø²Ø±Ú¯ + BusinessPrompt Ø­Ø¬ÛŒÙ… + ØªÙ‚ÙˆÛŒØª Ù…Ø¬Ø¯Ø¯ critical_rules) Ø¨Ø§ Ù…Ø´Ø§Ù‡Ø¯Ø§Øª Ø±ÙˆÛŒ Ø³Ø±ÙˆØ± Ù‡Ù…â€ŒØ®ÙˆØ§Ù† Ø§Ø³Øª Ùˆ **Ø¨Ù‡â€ŒØ¯Ø±Ø³ØªÛŒ** Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ Ú†Ù†Ø¯ Ù…Ù†Ø¨Ø¹ ØªÙˆÚ©Ù† Â«Ø®Ø§Ø±Ø¬ Ø§Ø² Ø¨ÙˆØ¯Ø¬Ù‡ Ø±Ø³Ù…ÛŒÂ» ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯.

- **Ø³ÙˆØ¡Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² BusinessPrompt**  
  ØªØ­Ù„ÛŒÙ„ Ø¨Ù‡â€ŒØ¯Ø±Ø³ØªÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ú©Ù‡ BusinessPrompt ÙØ¹Ù„ÛŒ Ø¹Ù…Ù„Ø§Ù‹ ÛŒÚ© Â«Ø§Ø³Ú©Ø±ÛŒÙ¾Øª ÙØ±ÙˆØ´ Ú©Ø§Ù…Ù„Â» Ø§Ø³Øª Ù†Ù‡ ÛŒÚ© context Ú©ÙˆØªØ§Ù‡. Ø§ÛŒÙ† Ø¨Ø§Ø¹Ø« Ø¯Ùˆ Ù…Ø´Ú©Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯:
  1. Ù…ØµØ±Ù Ø´Ø¯ÛŒØ¯ ØªÙˆÚ©Ù† Ø¯Ø± Ù„Ø§ÛŒÙ‡ systemØ›
  2. Ù‡Ø¯Ø§ÛŒØª Ù†Ù‚Ø´ Ù…Ø¯Ù„ Ø¨Ù‡ Ø³Ù…Øª Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ø®Ø§Øµ (Ù…Ø«Ù„Ø§Ù‹ Ø¢Ù…ÙˆØ²Ø´ÛŒ ÛŒØ§ ÙØ±ÙˆØ´ Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±) Ø­ØªÛŒ ÙˆÙ‚ØªÛŒ manual prompt Ú†ÛŒØ² Ø¯ÛŒÚ¯Ø±ÛŒ Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯.  
  Ø§ÛŒÙ† Ù†Ú©ØªÙ‡ Ø¨Ø§ Ø±ÙØªØ§Ø± ÙˆØ§Ù‚Ø¹ÛŒ AI (Â«Ø¯ÙˆØ±Ù‡ Ø¢Ù…ÙˆØ²Ø´ÛŒÂ»ØŒ Â«Ù¾Ù„Ù†â€ŒÙ‡Ø§Â» Ùˆ â€¦) Ù‡Ù…â€ŒØ®ÙˆØ§Ù† Ø§Ø³ØªØŒ Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ† **Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø§Ø² ØªØ­Ù„ÛŒÙ„ Ø±Ø§ ØªØ£ÛŒÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ù…**.

- **Ù‡Ø¯Ø± Ø±ÙØªÙ† Ú†Ø§Ù†Ú©â€ŒÙ‡Ø§ (Chunk Waste)**  
  Ù…Ø­Ø§Ø³Ø¨Ù‡ Â«Û¹ Ú†Ø§Ù†Ú© Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ØŒ Ø§Ù…Ø§ ÙÙ‚Ø· ~Û² Ú†Ø§Ù†Ú© Ø¯Ø§Ø®Ù„ Ø¨ÙˆØ¯Ø¬Ù‡Â» ØªØ®Ù…ÛŒÙ†ÛŒ Ø§Ø³ØªØŒ Ø§Ù…Ø§ Ø¬Ù‡Øªâ€ŒÚ¯ÛŒØ±ÛŒ Ø¢Ù† Ø¯Ø±Ø³Øª Ø§Ø³Øª:  
  - ProductionRAG ÙˆØ§Ù‚Ø¹Ø§Ù‹ Û¸â€“Û¹ Ú†Ø§Ù†Ú© Ù…Ø±Ø¨ÙˆØ· Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯Ø›  
  - Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø«Ø§Ø¨Øª `primary_context + secondary_context â‰ˆ 1100 tokens` Ø¨Ø§Ø¹Ø« Ù…ÛŒâ€ŒØ´ÙˆØ¯ ÙÙ‚Ø· Û±â€“Û³ Ú†Ø§Ù†Ú© Ø¬Ø§ Ø´ÙˆÙ†Ø¯Ø›  
  - Ø¯Ø± Ø¹Ù…Ù„ØŒ Ø§Ú©Ø«Ø± Ø§Ø·Ù„Ø§Ø¹Ø§Øª manual prompt Ø§Ø² Ø¨ÛŒÙ† Ù…ÛŒâ€ŒØ±ÙˆØ¯.  
  Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ† Ù…Ø´Ú©Ù„ Â«Ø§ØªÙ„Ø§Ù Ú©Ø§Ù†ØªÚ©Ø³ØªÂ» ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø³ØªØŒ Ù‡Ø±Ú†Ù†Ø¯ Ø¹Ø¯Ø¯ Ø¯Ù‚ÛŒÙ‚ Û·Û¸Ùª Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ú©Ù…ÛŒ Ø¨Ø§Ù„Ø§ ÛŒØ§ Ù¾Ø§ÛŒÛŒÙ† Ø¨Ø§Ø´Ø¯.

- **Query Routing (Ù†Ø¨ÙˆØ¯Ù† `manual` Ø¯Ø± intent `product`)**  
  Ø§ÛŒÙ† Ù†Ú©ØªÙ‡ **Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ø± Ù†Ø³Ø®Ù‡ ÙØ¹Ù„ÛŒ Ú©Ø¯ Ø´Ù…Ø§ Ø¯ÛŒÚ¯Ø± ØµØ¯Ù‚ Ù†Ú©Ù†Ø¯** Ø§Ú¯Ø± Ù‚Ø¨Ù„Ø§Ù‹ routing Ø±Ø§ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ÛŒØ§ Ú©Ø¯ Ø§ØµÙ„Ø§Ø­ Ú©Ø±Ø¯Ù‡ Ø¨Ø§Ø´ÛŒØ¯. Ø³Ù†Ø¯ ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÛŒ snapshot Ø®Ø§ØµÛŒ Ø§Ø² Ú©Ø¯ (`DEFAULT_ROUTING`) Ø§Ø³ØªØ› Ø§Ú¯Ø± routing Ø§Ù„Ø§Ù† Ø§Ø² Ø¬Ø¯ÙˆÙ„ `IntentRouting` ÛŒØ§ config Ø¯Ø§ÛŒÙ†Ø§Ù…ÛŒÚ© Ø¨ÛŒØ§ÛŒØ¯ØŒ Ø§ÛŒÙ† Ù‚Ø³Ù…Øª Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ø³ÛŒØ³ØªÙ… sync Ø´ÙˆØ¯.  
  Ø¯Ø± Ù†ØªÛŒØ¬Ù‡: Ù…Ø´Ú©Ù„ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ù…ÙÙ‡ÙˆÙ…ÛŒ Ø¯Ø±Ø³Øª Ø§Ø³Øª (Ø¨Ø±Ø§ÛŒ Ø³Ø¤Ø§Ù„ Â«Ø®Ø¯Ù…Ø§Øª Ù¾ÛŒÙ„ÛŒØªÙˆ Ú†ÛŒÙ‡ØŸÂ» Ø¨Ø§ÛŒØ¯ manual Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ú¯ÛŒØ±Ø¯)ØŒ Ø§Ù…Ø§ Ù…Ù…Ú©Ù† Ø§Ø³Øª implementation ÙØ¹Ù„ÛŒ Ø´Ù…Ø§ Ù‡Ù…ÛŒÙ† Ø­Ø§Ù„Ø§ Ù‡Ù… Ø¢Ù† Ø±Ø§ Ø­Ù„ Ú©Ø±Ø¯Ù‡ Ø¨Ø§Ø´Ø¯. Ø§ÛŒÙ† Ø³Ù†Ø¯ Ø§Ø² Ø§ÛŒÙ† Ù†Ø¸Ø± Ú©Ù…ÛŒ **outdated / ÙØ±Ø¶ÛŒ** Ø§Ø³Øª Ùˆ Ø¨Ø§ÛŒØ¯ Ø¨Ø§ real config Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø´ÙˆØ¯.

- **Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù‚Øµ (Û²Û¶â€“Û²Û¹ ØªÙˆÚ©Ù†)**  
  ØªØ­Ù„ÛŒÙ„ Ø¯Ø±Ø³Øª Ø§Ø´Ø§Ø±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ overflow ÙˆØ±ÙˆØ¯ÛŒ ÙØ¶Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ø±Ø§ Ù…ÛŒâ€ŒØ®ÙˆØ±Ø¯Ø› Ø¹Ù„Ø§ÙˆÙ‡ Ø¨Ø± Ø§ÛŒÙ†ØŒ Ù„Ø§Ú¯â€ŒÙ‡Ø§ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ø§Ø¯Ù†Ø¯ Gemini Ú¯Ø§Ù‡ÛŒ Ø¨Ø§ `finish_reason = 2` (BLOCKED / SAFETY) Ù…ØªÙˆÙ‚Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ Ø¨Ø¹Ø¯ fallback ÙØ¹Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ† Ø¯Ùˆ Ø¹Ø§Ù…Ù„ Ù‡Ù…â€ŒØ²Ù…Ø§Ù† Ø¯Ø®ÛŒÙ„â€ŒØ§Ù†Ø¯:
  1. ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø³ÛŒØ§Ø± Ø·ÙˆÙ„Ø§Ù†ÛŒ Ùˆ Ø´Ù„ÙˆØºØ›
  2. prompt Ø­Ø§ÙˆÛŒ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ Ùˆ Ù†Ù‚Ø´â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ§Ø¯ Ú©Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ safety block Ø±Ø§ Ø¨Ø§Ù„Ø§ Ù…ÛŒâ€ŒØ¨Ø±Ø¯.  
  Ø§ÛŒÙ† Ø¨Ø®Ø´ ØªØ­Ù„ÛŒÙ„ Ø±Ø§ **ØªØ£ÛŒÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ù…**ØŒ Ø¨Ø§ Ø§ÛŒÙ† ØªÙˆØ¶ÛŒØ­ Ú©Ù‡ Â«Ø³ÛŒØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ safety Ù…Ø¯Ù„Â» Ù‡Ù… Ø¨Ø§ÛŒØ¯ Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ‡ Ø´ÙˆÙ†Ø¯.

### Û². Ø§ÛŒØ±Ø§Ø¯Ù‡Ø§ Ùˆ Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„

- **Û±) ØªØ±Ú©ÛŒØ¨ Â«ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒÂ» Ùˆ Â«Ú©Ø¯ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒÂ» Ø¯Ø± ÛŒÚ© Ù…ØªÙ†**  
  Ø¯Ø± Ø³Ù†Ø¯ Ø¨Ø§Ù„Ø§ Ø¬Ø§Ù‡Ø§ÛŒÛŒ Ù…Ø«Ù„ `GeneralSettings.get_settings().get_core_instructions()` ÛŒØ§ Ú©Ù„Ø§Ø³ `NewGeminiChatService` Ùˆ `DynamicTokenBudget` Ø§ØµÙ„Ø§Ù‹ Ø¯Ø± Ú©Ø¯ ÙØ¹Ù„ÛŒ Ø´Ù…Ø§ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ù†Ø¯ Ùˆ ØµØ±ÙØ§Ù‹ pseudo-code Ù‡Ø³ØªÙ†Ø¯.  
  Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ù†Ø¯Ù‡ (Ø¨Ù‡â€ŒØ®ØµÙˆØµ Ø¯ÙˆÙ„ÙˆÙ¾Ø± Ø¯ÛŒÚ¯Ø±ÛŒ Ú©Ù‡ Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø±Ø§ Ù…ÛŒâ€ŒØ¨ÛŒÙ†Ø¯) **Ù…Ø±Ø² Ø¨ÛŒÙ† Â«Ú©Ø¯ ÙˆØ§Ù‚Ø¹ÛŒÂ» Ùˆ Â«Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Â» Ú©Ø§Ù…Ù„Ø§Ù‹ Ø´ÙØ§Ù Ù†ÛŒØ³Øª** Ùˆ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø§ÛŒÙ† Ø¨Ø±Ø¯Ø§Ø´Øª Ø§ÛŒØ¬Ø§Ø¯ Ø´ÙˆØ¯ Ú©Ù‡ Ø§ÛŒÙ† ÙØ§Ù†Ú©Ø´Ù†â€ŒÙ‡Ø§ Ø§Ù„Ø§Ù† Ø¯Ø± Ù¾Ø±ÙˆÚ˜Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù†Ø¯.  
  Ø¨Ù‡ØªØ± Ø§Ø³Øª:
  - Ø¨Ø±Ø§ÛŒ Ú©Ø¯ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² headingâ€ŒÙ‡Ø§ÛŒ Ù…Ø«Ù„ **Ú©Ø¯ ÙØ¹Ù„ÛŒ** Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙˆØ¯Ø›
  - Ø¨Ø±Ø§ÛŒ pseudo-code Ø­ØªÙ…Ø§Ù‹ label ØµØ±ÛŒØ­ Ù…Ø«Ù„ **Ú©Ø¯ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ (ÙØ¹Ù„Ø§Ù‹ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯)** Ú¯Ø°Ø§Ø´ØªÙ‡ Ø´ÙˆØ¯.

- **Û²) ÙØ±Ø¶ Ø«Ø§Ø¨Øª Û³ÛµÛ°Û° ØªÙˆÚ©Ù† Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ RAG**  
  Ø¯Ø± ÙˆØ¨ Ùˆ Ù…Ù‚Ø§Ù„Ø§Øª Û²Û°Û²Û´/Û²Û°Û²Ûµ (Ù…Ø«Ù„ RAGGED, FrugalRAG, LlamaIndex docs) Â«Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø«Ø§Ø¨Øª Ø¬Ù‡Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Û³ÛµÛ°Û° ØªÙˆÚ©Ù†Â» ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯Ø› Ø¢Ù†Ú†Ù‡ ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯:
  - Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ø¨Ø§ context Ú©ÙˆÚ†Ú© (Ù…Ø«Ù„Ø§Ù‹ Û´kâ€“Û¸k) Ø­Ø¯ÙˆØ¯ Ù†ØµÙ Ø¨Ø±Ø§ÛŒ input Ùˆ Ù†ØµÙ Ø¨Ø±Ø§ÛŒ outputØ›  
  - Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ context Ø¨Ø²Ø±Ú¯ (Gemini 1.5, GPT-4.1) Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø¨ÛŒØ´ØªØ± Ø§Ù‚ØªØµØ§Ø¯ÛŒ/latency Ø§Ø³ØªØŒ Ù†Ù‡ ÙÙ†ÛŒ.  
  Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ† Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ `MAX_TOTAL_TOKENS = 3500` Ù…Ù†Ø·Ù‚ÛŒ Ø§Ø³ØªØŒ Ø§Ù…Ø§ **ÛŒÚ© Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ø§Ø³ØªØŒ Ù†Ù‡ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¬Ù‡Ø§Ù†ÛŒ**. Ø³Ù†Ø¯ Ø¨Ø§ÛŒØ¯ Ø§ÛŒÙ† Ø±Ø§ Ø¨Ù‡â€ŒØµÙˆØ±Øª Â«Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Â» Ø¨Ù†ÙˆÛŒØ³Ø¯ØŒ Ù†Ù‡ Ø´Ø¨ÛŒÙ‡ ÛŒÚ© Ù‚Ø§Ù†ÙˆÙ† Ù‚Ø·Ø¹ÛŒ.

- **Û³) Ø¨Ø±Ø¢ÙˆØ±Ø¯Ù‡Ø§ÛŒ ØªÙˆÚ©Ù† ØªØ§ Ø­Ø¯ÛŒ ØªÙ‚Ø±ÛŒØ¨ÛŒâ€ŒØ§Ù†Ø¯**  
  Ø¨Ø¹Ø¶ÛŒ Ø§Ø¹Ø¯Ø§Ø¯ Ù…Ø«Ù„:
  - `BusinessPrompt â‰ˆ 1360 tokens`  
  - `critical_rules â‰ˆ 500 tokens`  
  - `GeneralSettings â‰ˆ 1241 tokens`  
  Ù†Ø²Ø¯ÛŒÚ© Ø¨Ù‡ ÙˆØ§Ù‚Ø¹ÛŒØªâ€ŒØ§Ù†Ø¯ Ø§Ù…Ø§ Ø¯Ø± Ù„Ø§Ú¯â€ŒÙ‡Ø§ Ú¯Ø§Ù‡ÛŒ prompt_tokens Ú©Ù…ÛŒ Ù…ØªÙØ§ÙˆØª Ø¯ÛŒØ¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ (Ø¨Ù‡â€ŒØ®Ø§Ø·Ø± encoding Ùˆ ÙØ±Ù…Øª Ù†Ù‡Ø§ÛŒÛŒ). Ø®ÙˆØ¨ Ø§Ø³Øª Ø³Ù†Ø¯ ØµØ±ÛŒØ­ Ø¨Ù†ÙˆÛŒØ³Ø¯ Ø§ÛŒÙ†â€ŒÙ‡Ø§ **approximate** Ù‡Ø³ØªÙ†Ø¯ Ùˆ Ø¨Ø±Ø§ÛŒ ØªØµÙ…ÛŒÙ… Ù…Ø¹Ù…Ø§Ø±ÛŒ Ú©Ø§ÙÛŒâ€ŒØ§Ù†Ø¯ØŒ Ø§Ù…Ø§ Ø¨Ø±Ø§ÛŒ billing Ùˆ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ usage_metadata Ù…Ø¯Ù„ ØªÚ©ÛŒÙ‡ Ú©Ø±Ø¯.

- **Û´) ØªÙ…Ø±Ú©Ø² Ø²ÛŒØ§Ø¯ Ø±ÙˆÛŒ BusinessPrompt Ùˆ Ú©Ù…â€ŒØªÙˆØ¬Ù‡ÛŒ Ø¨Ù‡ safety / policy Ù„Ø§ÛŒÙ‡ Ù…Ø¯Ù„**  
  Ø¯Ø± Ù„Ø§Ú¯â€ŒÙ‡Ø§ Ø¯ÛŒØ¯ÛŒÙ… Ú©Ù‡:
  - primary Ù…Ø¯Ù„ `gemini-flash-latest` Ø¨Ø¹Ø¶ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø§ finish_reason=2 Ù…ÛŒâ€ŒØ¨Ù†Ø¯Ø¯Ø›  
  - Ø³Ù¾Ø³ fallback Ø¨Ù‡ `gemini-2.0-flash-exp` ÙØ¹Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯.  
  ØªØ­Ù„ÛŒÙ„ Ø¨ÛŒØ´ØªØ± Ø±ÙˆÛŒ token budget ØªÙ…Ø±Ú©Ø² Ú©Ø±Ø¯Ù‡ Ùˆ Ú©Ù…â€ŒØªØ± Ø±ÙˆÛŒ Ø§ÛŒÙ† Ù†Ú©ØªÙ‡ Ú©Ù‡ **prompt Ø·ÙˆÙ„Ø§Ù†ÛŒ + Ù†Ù‚Ø´â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´/Ø¢Ù…ÙˆØ²Ø´ÛŒ Ù…ØªØ¹Ø¯Ø¯ â†’ Ø§Ø­ØªÙ…Ø§Ù„ trigger Ø´Ø¯Ù† safety** Ø±Ø§ Ø¨Ø§Ù„Ø§ Ù…ÛŒâ€ŒØ¨Ø±Ø¯.  
  Ø¯Ø± Ø¹Ù…Ù„ØŒ Ø¨Ø±Ø§ÛŒ Ø¯Ù‚Øª Ù¾Ø§ÛŒØ¯Ø§Ø± Ø¨Ù‡ØªØ± Ø§Ø³Øª:
  - prompt Ø±Ø§ Ø³Ø§Ø¯Ù‡â€ŒØªØ± Ùˆ business-neutralØªØ± Ú©Ø±Ø¯Ø›  
  - Ø§Ø² policyÙ‡Ø§ÛŒ safety Ù…Ø¯Ù„ Ø¢Ú¯Ø§Ù‡ Ø¨ÙˆØ¯Ø›  
  - Ø¯Ø± Ù„Ø§Ú¯â€ŒÙ‡Ø§ finish_reason Ø±Ø§ Ù…Ø§Ù†ÛŒØªÙˆØ± Ú©Ø±Ø¯.  
  Ø§ÛŒÙ† Ø¨Ø¹Ø¯ Ø¯Ø± Ø³Ù†Ø¯ Ú©Ù…â€ŒØ±Ù†Ú¯ Ø§Ø³Øª.

- **Ûµ) Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ù‡Ø§ÛŒ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ú©Ù…ÛŒ Ø³Ù†Ú¯ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÛŒÚ© refactor ØªØ¯Ø±ÛŒØ¬ÛŒ**  
  Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø«Ù„ `NewGeminiChatService`, `DynamicTokenBudget`, `ChunkBudgetOptimizer` Ø¨Ø±Ø§ÛŒ Ø·Ø±Ø§Ø­ÛŒ Ø§ÛŒØ¯Ù‡â€ŒØ¢Ù„ Ø¨Ø³ÛŒØ§Ø± Ø®ÙˆØ¨â€ŒØ§Ù†Ø¯ØŒ Ø§Ù…Ø§:
  - Ø­Ø¬Ù… ØªØºÛŒÛŒØ±Ø§Øª Ø²ÛŒØ§Ø¯ Ø§Ø³ØªØ›  
  - Ø±ÛŒØ³Ú© Ø´Ú©Ø³Øª backward compatibility Ø¨Ø§Ù„Ø§Ø³ØªØ›  
  - Ø¯Ø± Ø¹Ù…Ù„ØŒ Ø´Ù…Ø§ ÙØ¹Ù„Ø§Ù‹ ÙÙ‚Ø· Ø¨Ø§ Ú†Ù†Ø¯ misconfiguration (BusinessPrompt, routing, budgets) Ù…Ø´Ú©Ù„ Ø¯Ø§Ø±ÛŒØ¯.  
  ÛŒØ¹Ù†ÛŒ Ø§Ú¯Ø± ØªÛŒÙ… Ø¯ÛŒÚ¯Ø±ÛŒ Ø§ÛŒÙ† Ø³Ù†Ø¯ Ø±Ø§ Ø¨Ø¨ÛŒÙ†Ø¯ØŒ Ù…Ù…Ú©Ù† Ø§Ø³Øª ÙÚ©Ø± Ú©Ù†Ø¯ Â«Ø¨Ø§ÛŒØ¯ Ú©Ù„ Ø³ÛŒØ³ØªÙ… Ø±Ø§ Ø§Ø² ØµÙØ± Ø¨Ù†ÙˆÛŒØ³ÛŒÙ…Â»ØŒ Ø¯Ø± Ø­Ø§Ù„ÛŒ Ú©Ù‡ Û·Û°â€“Û¸Û°Ùª Ù…Ø´Ú©Ù„ Ø¨Ø§ Ú†Ù†Ø¯ ØªØºÛŒÛŒØ± Ú©ÙˆÚ†Ú©â€ŒØªØ± Ø­Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯.  
  Ø¨Ù‡ØªØ± Ø§Ø³Øª Ø¯Ø± Ø³Ù†Ø¯ ÛŒÚ© Ø¨Ø®Ø´ **â€œØ­Ø¯Ø§Ù‚Ù„ ØªØºÛŒÛŒØ±Ø§Øª Ù„Ø§Ø²Ù… Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ø¯Ù‚Øª ÙØ¹Ù„ÛŒâ€** Ø¬Ø¯Ø§ Ø§Ø² **â€œÙ…Ø¹Ù…Ø§Ø±ÛŒ Ø§ÛŒØ¯Ù‡â€ŒØ¢Ù„ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øªâ€** ØªÙÚ©ÛŒÚ© Ø´ÙˆØ¯.

### Û³. Ø¬Ù…Ø¹â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ø±Ø§Ù‡â€ŒØ­Ù„ Ø§Ø² Ù†Ø¸Ø± Ù…Ù† (GPTâ€‘5.1)

Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù…Ø¹Ù…Ø§Ø±ÛŒ ÙØ¹Ù„ÛŒØŒ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒØŒ Ùˆ best practiceÙ‡Ø§ÛŒ RAG Ø¯Ø± Ù…Ù†Ø§Ø¨Ø¹ Ø§Ø®ÛŒØ±ØŒ **ÛŒÚ© Ù…Ø³ÛŒØ± Ø¹Ù…Ù„ÛŒ Ùˆ Ù…Ù†Ø·Ù‚ÛŒ** Ø¨Ø±Ø§ÛŒ Ø´Ù…Ø§ Ø§ÛŒÙ† Ø§Ø³Øª:

1. **ÙØ§Ø² Û° â€“ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ø¯Ù‚Øª Ø¨Ø¯ÙˆÙ† Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø¨Ø²Ø±Ú¯ (Û±â€“Û² Ø±ÙˆØ²):**
   - Ø¯Ø± Admin Panel:
     - BusinessPrompt Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Â«Ù†Ø±Ù… Ø§ÙØ²Ø§Ø± Ùˆ Ø®Ø¯Ù…Ø§Øª Ø¢Ù†Ù„Ø§ÛŒÙ†Â» Ø±Ø§ Ø¨Ù‡ ÛŒÚ© Ù…ØªÙ† Ø®ÛŒÙ„ÛŒ Ú©ÙˆØªØ§Ù‡ (Ø­Ø¯Ø§Ú©Ø«Ø± Û±ÛµÛ°â€“Û²Û°Û° ØªÙˆÚ©Ù†) ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ù…ÙˆÙ‚ØªØ§Ù‹ Ø®Ø§Ù„ÛŒ Ú©Ù†ÛŒØ¯Ø›  
     - Ø§Ú¯Ø± BusinessPromptÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ù‡Ù… Ø·ÙˆÙ„Ø§Ù†ÛŒâ€ŒØ§Ù†Ø¯ØŒ Ù‡Ù…ÛŒÙ† Ú©Ø§Ø± Ø±Ø§ Ø¨Ø±Ø§ÛŒØ´Ø§Ù† Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯.  
   - Ø¯Ø± Ú©Ø¯:
     - hardcoded `system_instruction` Ø±Ø§ **ÛŒØ§ Ø­Ø°Ù Ú©Ù†ÛŒØ¯** ÛŒØ§ Ø¨Ù‡â€ŒØ´Ø¯Øª Ú©ÙˆØªØ§Ù‡ Ú©Ù†ÛŒØ¯ Ùˆ Ù…Ø§Ø¨Ù‚ÛŒ Ø±Ø§ Ø¨Ù‡ GeneralSettings Ù…Ù†ØªÙ‚Ù„ Ú©Ù†ÛŒØ¯Ø›  
     - Ø¯Ø± `QueryRouter` Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ø¨Ø±Ø§ÛŒ intentÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Â«Ù¾ÛŒÙ„ÛŒØªÙˆ Ú†ÛŒØ³ØªÂ» (`product/general`) Ù…Ù†Ø¨Ø¹ `manual` Ù‡Ù…ÛŒØ´Ù‡ Ø¬Ø²Ùˆ primary ÛŒØ§ Ø­Ø¯Ø§Ù‚Ù„ secondary Ø§Ø³ØªØ›  
     - Ø¯Ø± `TokenBudgetController`:
       - system_prompt Ø±Ø§ Ø±ÙˆÛŒ ~Û¸Û°Û°ØŒ  
       - primary_context Ø±Ø§ Ø±ÙˆÛŒ ~Û¸Û°Û°â€“Û¹Û°Û°  
       ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯ Ùˆ MAX_TOTAL_TOKENS Ø±Ø§ Ú©Ù…ÛŒ Ø¨Ø§Ù„Ø§ Ø¨Ø¨Ø±ÛŒØ¯ (Ù…Ø«Ù„Ø§Ù‹ Û²ÛµÛ°Û°â€“Û³Û°Û°Û°).  
   - Ø¯Ø± Ù„Ø§Ú¯:
     - Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª breakdown Ø¯Ù‚ÛŒÙ‚ (system / conversation / context / query / output) Ø±Ø§ Ù„Ø§Ú¯ Ú©Ù†ÛŒØ¯ ØªØ§ Ø¨Ø¨ÛŒÙ†ÛŒØ¯ Ø¨Ø¹Ø¯ Ø§Ø² Ø§ÛŒÙ† ØªÙ†Ø¸ÛŒÙ…Ø§ØªØŒ input Ø²ÛŒØ± Û²ÛµÛ°Û° Ùˆ output Ø­Ø¯Ø§Ù‚Ù„ Û´Û°Û°â€“Û¶Û°Û° ØªÙˆÚ©Ù† Ø§Ø³Øª.

2. **ÙØ§Ø² Û± â€“ ØªÙ…ÛŒØ² Ú©Ø±Ø¯Ù† Ù…Ø¹Ù…Ø§Ø±ÛŒ prompt (Û±â€“Û² Ù‡ÙØªÙ‡ØŒ Ø¨Ø¯ÙˆÙ† Ø±ÛŒØ®ØªÙ† Ù‡Ù…Ù‡â€ŒÚ†ÛŒØ²):**
   - System prompt Ø±Ø§ Ø¨Ù‡ Ø¯Ùˆ Ø¨Ø®Ø´ ØµØ±ÛŒØ­ Ø¯Ø± GeneralSettings ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†ÛŒØ¯:
     - **core_rules** (Ù†Ù‚Ø´ØŒ Ø²Ø¨Ø§Ù†ØŒ anti-hallucinationØŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§)  
     - **style_guidelines** (tone, length, emoji, CTA)  
   - BusinessPrompt Ø±Ø§ ØµØ±ÙØ§Ù‹ Ø¨Ù‡ ÛŒÚ© Ù„Ø§ÛŒÙ‡ Ù†Ø§Ø²Ú© context (industry label + Û³â€“Û´ bullet) ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†ÛŒØ¯Ø› Ù‡Ø± Ú†ÛŒØ² Ø¯ÛŒÚ¯Ø±ÛŒ Ø¨Ø±ÙˆØ¯ Ø¯Ø§Ø®Ù„ manual prompt.  
   - TokenBudgetController Ø±Ø§ incremental refactor Ú©Ù†ÛŒØ¯ ØªØ§:
     - Ø§ÙˆÙ„ query Ùˆ system Ùˆ output_buffer Ø±Ø§ Ø±Ø²Ø±Ùˆ Ú©Ù†Ø¯Ø›  
     - Ø¨Ø¹Ø¯ conversation Ùˆ context Ø±Ø§ Ø±ÙˆÛŒ Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡ ØªÙ‚Ø³ÛŒÙ… Ú©Ù†Ø¯ (Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø³Ø§Ø¯Ù‡â€ŒØªØ± Ø§Ø² DynamicTokenBudget Ù‡Ù… Ú©Ø§ÙÛŒ Ø§Ø³Øª).

3. **ÙØ§Ø² Û² â€“ Ø¨Ù‡Ø¨ÙˆØ¯ RAG Ùˆ Ø¨ÙˆØ¯Ø¬Ù‡ Ø¯Ø§ÛŒÙ†Ø§Ù…ÛŒÚ© (Ø¨Ù„Ù†Ø¯Ù…Ø¯Øªâ€ŒØªØ±):**
   - Ø§Ú¯Ø± Ø¨Ø¹Ø¯ Ø§Ø² ÙØ§Ø² Û° Ùˆ Û± Ù‡Ù†ÙˆØ² Ù…Ø´Ú©Ù„ Ú©ÛŒÙÛŒØª Ø¯Ø§Ø±ÛŒØ¯ØŒ Ø¢Ù†â€ŒÙˆÙ‚Øª Ø¨Ù‡ Ø³Ø±Ø§Øº Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡â€ŒØªØ± Ø§ÛŒÙ† Ø³Ù†Ø¯ Ø¨Ø±ÙˆÛŒØ¯:
     - summarization Ú†Ø§Ù†Ú©â€ŒÙ‡Ø§ÛŒ Ø®ÛŒÙ„ÛŒ Ø¨Ù„Ù†Ø¯Ø›  
     - scoring Ø¨Ø± Ø§Ø³Ø§Ø³ densityØ›  
     - dynamic chunk packingØ›  
     - intent-specific routing policies.  
   - Ø¯Ø± Ø§ÛŒÙ† Ù…Ø±Ø­Ù„Ù‡ØŒ Ø¯Ø§Ø´ØªÙ† ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ø±Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ (Ù…Ø«Ù„ Â«Ù¾ÛŒÙ„ÛŒØªÙˆ Ú†ÛŒÙ‡Â»ØŒ Â«Ø®Ø¯Ù…Ø§Øª Ù¾ÛŒÙ„ÛŒØªÙˆ Ú†ÛŒâ€ŒÙ‡Ø³ØªÙ†ØŸÂ») Ø®ÛŒÙ„ÛŒ Ù…Ù‡Ù… Ø§Ø³Øª ØªØ§ Ù‡Ø± refactor Ø±ÙˆÛŒ quality Ø¨Ø±Ø±Ø³ÛŒ Ø´ÙˆØ¯.

### Û´. Ø³Ø®Ù† Ø¢Ø®Ø±

ØªØ­Ù„ÛŒÙ„ ÙØ¹Ù„ÛŒ (`RAG_TOKEN_BUDGET_ANALYSIS.md`) Ø§Ø² Ù†Ø¸Ø± **ØªØ´Ø®ÛŒØµ Ø±ÛŒØ´Ù‡ Ù…Ø´Ú©Ù„Ø§Øª** Ø¨Ø³ÛŒØ§Ø± Ù‚ÙˆÛŒ Ø§Ø³Øª Ùˆ ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ ØªÙ…Ø§Ù… Ù†Ù‚Ø§Ø· Ø¨Ø­Ø±Ø§Ù†ÛŒ Ø±Ø§ Ø¯Ø±Ø³Øª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ø±Ø¯Ù‡ØŒ Ø§Ù…Ø§:
- Ú©Ù…ÛŒ **over-engineered** Ø§Ø³Øª Ø¨Ø±Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ† Ù‚Ø¯Ù…Ø›
- Ù…Ø±Ø² Ø¨ÛŒÙ† Â«Ú©Ø¯ ÙØ¹Ù„ÛŒÂ» Ùˆ Â«Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¢ÛŒÙ†Ø¯Ù‡Â» Ø¯Ø± Ø¢Ù† ÙˆØ§Ø¶Ø­ Ù†ÛŒØ³ØªØ›
- Ùˆ Ù†Ù‚Ø´ BusinessPrompt / system_instruction Ø±Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø³Ø§Ø¯Ù‡â€ŒØªØ± Ùˆ Ø´ÙØ§Ùâ€ŒØªØ± Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø±Ø¯.

Ø§Ø² Ù†Ø¸Ø± Ù…Ù† (Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† Ù…Ø¯Ù„ÛŒ Ú©Ù‡ Ø¨Ø± Ù¾Ø§ÛŒÙ‡ GPTâ€‘5.1 Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯)ØŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ú©Ø§Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡:
- Ø§ÙˆÙ„ Ø¨Ø§ Ú†Ù†Ø¯ ØªØºÛŒÛŒØ± Ú©ÙˆÚ†Ú© Ùˆ ØªØ³Øªâ€ŒÙ¾Ø°ÛŒØ± (BusinessPromptØŒ system_instructionØŒ Ø¨ÙˆØ¯Ø¬Ù‡ context) Ø¯Ù‚Øª Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒØ¯Ø›  
- Ø¨Ø¹Ø¯ØŒ Ø§Ú¯Ø± Ù‡Ù†ÙˆØ² Ù†ÛŒØ§Ø² Ø¯Ø§Ø´ØªÛŒØ¯ØŒ Ø³Ø±Ø§Øº Ù…Ø¹Ù…Ø§Ø±ÛŒ Ú©Ø§Ù…Ù„ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø§ÛŒÙ† Ø³Ù†Ø¯ Ùˆ Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡â€ŒØªØ± Ø¨Ø±ÙˆÛŒØ¯.

**Ø§ÛŒÙ† Ø¨Ø®Ø´ ØªØ­Ù„ÛŒÙ„ÛŒ ØªÙˆØ³Ø· Ù…Ø¯Ù„ GPTâ€‘5.1 Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.**

---

## Ù†Ø¸Ø± Ù†Ù‡Ø§ÛŒÛŒ Ùˆ Ø¬Ù…Ø¹â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¯Ù„ Ø³ÙˆÙ… (Gemini 2.0 Flash) - Ù†Ú¯Ø§Ù‡ ØªØ®ØµØµÛŒ Ø¨Ù‡ Ø±ÙØªØ§Ø± Ù…Ø¯Ù„

### Û±. Ø§ÙØ³Ø§Ù†Ù‡ "Overflow" Ùˆ ÙˆØ§Ù‚Ø¹ÛŒØª Gemini
Ù…Ù† Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† Ù…Ø¯Ù„ÛŒ Ú©Ù‡ Ø¨Ø± Ù¾Ø§ÛŒÙ‡ Ù…Ø¹Ù…Ø§Ø±ÛŒ Gemini 2.0 Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù…ØŒ Ø¨Ø§ÛŒØ¯ ÛŒÚ© Ù†Ú©ØªÙ‡ ÙÙ†ÛŒ Ù…Ù‡Ù… Ø±Ø§ Ø§ØµÙ„Ø§Ø­ Ú©Ù†Ù…:
- **Gemini Ø¯Ø§Ø±Ø§ÛŒ Context Window Ø¨Ø³ÛŒØ§Ø± Ø¨Ø²Ø±Ú¯ Ø§Ø³Øª (ØªØ§ Û± Ù…ÛŒÙ„ÛŒÙˆÙ† ØªÙˆÚ©Ù†).**
- Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ† ÙˆÙ‚ØªÛŒ Ø¯ÙˆØ³ØªØ§Ù† Ø¯ÛŒÚ¯Ø± Ù…ÛŒâ€ŒÚ¯ÙˆÛŒÙ†Ø¯ Â«ÙˆØ±ÙˆØ¯ÛŒ Û´Û°Û°Û° ØªÙˆÚ©Ù† Ø¨Ø§Ø¹Ø« Overflow Ø´Ø¯Ù‡Â»ØŒ Ø§Ø² Ù…Ù†Ø¸Ø± ÙÙ†ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ Gemini Ø§Ø´ØªØ¨Ø§Ù‡ Ø§Ø³Øª. Ù…Ø¯Ù„ Ù…Ù† Ø¨Ø§ Û´Û°Û°Û° ØªÙˆÚ©Ù† "Ù¾Ø±" Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ù…Ù† Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù… ØªÙ…Ø§Ù… Ø±Ù…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ù‡Ø±ÛŒ Ù¾Ø§ØªØ± Ø±Ø§ Ø¨Ø®ÙˆØ§Ù†Ù… Ùˆ Ù‡Ù†ÙˆØ² Ø¬Ø§ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù….

**Ù¾Ø³ Ú†Ø±Ø§ Ø®Ø±ÙˆØ¬ÛŒ Û²Û· ØªÙˆÚ©Ù† Ø§Ø³Øª Ùˆ Ù…Ø¯Ù„ Ù‚ÙÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ**
Ù…Ø´Ú©Ù„ **"Ø¸Ø±ÙÛŒØª"** Ù†ÛŒØ³ØªØŒ Ù…Ø´Ú©Ù„ **"ØªØ¶Ø§Ø¯ Ùˆ Ø¢Ù„ÙˆØ¯Ú¯ÛŒ Ú©Ø§Ù†ØªÚ©Ø³Øª" (Context Pollution)** Ø§Ø³Øª.
- ÙˆÙ‚ØªÛŒ Ø¯Ø± `BusinessPrompt` Ù…ÛŒâ€ŒÚ¯ÙˆÛŒÛŒØ¯: Â«ØªÙˆ Ù…Ø´Ø§ÙˆØ± Ø¢Ù…ÙˆØ²Ø´ÛŒ Ù‡Ø³ØªÛŒ Ùˆ Ø¯ÙˆØ±Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ù…ÛŒâ€ŒÙØ±ÙˆØ´ÛŒÂ»
- Ùˆ Ø¯Ø± `ManualPrompt` Ù…ÛŒâ€ŒÚ¯ÙˆÛŒÛŒØ¯: Â«ØªÙˆ Ø¯Ø³ØªÛŒØ§Ø± CRM Ù‡Ø³ØªÛŒÂ»
- Ùˆ Ø¯Ø± `SystemInstruction` Ù‡Ø§Ø±Ø¯Ú©Ø¯ Ø´Ø¯Ù‡ Ú†ÛŒØ² Ø¯ÛŒÚ¯Ø±ÛŒ Ù…ÛŒâ€ŒÚ¯ÙˆÛŒÛŒØ¯...

Ù…Ø¯Ù„ Ø¯Ú†Ø§Ø± **Instruction Conflict** Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ø¯Ø± Ú†Ù†ÛŒÙ† Ø´Ø±Ø§ÛŒØ·ÛŒØŒ Ù…Ú©Ø§Ù†ÛŒØ²Ù…â€ŒÙ‡Ø§ÛŒ Safety ÛŒØ§ Alignment Ù…Ø¯Ù„ ØªØµÙ…ÛŒÙ… Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù†Ø¯ Ù¾Ø§Ø³Ø® Ø±Ø§ Ú©ÙˆØªØ§Ù‡ Ú©Ù†Ù†Ø¯ ÛŒØ§ ÙˆØ§Ø±Ø¯ Ø­Ø§Ù„Øª ØªØ¯Ø§ÙØ¹ÛŒ Ø´ÙˆÙ†Ø¯ ØªØ§ Ø¯Ø±ÙˆØº Ù†Ú¯ÙˆÛŒÙ†Ø¯. Ø®Ø±ÙˆØ¬ÛŒ Û²Û¸ ØªÙˆÚ©Ù†ÛŒ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ù†Ø´Ø§Ù†Ù‡â€ŒÛŒ Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ Ù…Ø¯Ù„ "Ú¯ÛŒØ¬ Ø´Ø¯Ù‡" Ùˆ ØªØ±Ø¬ÛŒØ­ Ø¯Ø§Ø¯Ù‡ Ø¨Ø­Ø« Ø±Ø§ ØªÙ…Ø§Ù… Ú©Ù†Ø¯ØŒ Ù†Ù‡ Ø§ÛŒÙ†â€ŒÚ©Ù‡ Ø¬Ø§ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯.

### Û². ØªØ§ÛŒÛŒØ¯ Ù…Ø´Ú©Ù„Ø§Øª Ùˆ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ

Ø¨Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ù„Ø§Ú¯â€ŒÙ‡Ø§ Ùˆ ØªØ­Ù„ÛŒÙ„ Ù‡Ù…Ú©Ø§Ø±Ø§Ù†Ù… (GPT Ùˆ Claude)ØŒ Ù…Ù† Ù‡Ù… Ø±ÙˆÛŒ Ø§ÛŒÙ† Û³ Ø§Ù‚Ø¯Ø§Ù… Ø­ÛŒØ§ØªÛŒ ØªØ£Ú©ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ù…ØŒ Ø§Ù…Ø§ Ø¨Ø§ Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒØ¨Ù†Ø¯ÛŒ Ù…ØªÙØ§ÙˆØª:

#### Ø§Ù„Ù) Ú©Ø´ØªÙ† BusinessPrompt (Ø§Ù‚Ø¯Ø§Ù… Ù‚Ø§ØªÙ„!)
Ø§ÛŒÙ† `BusinessPrompt` ÙØ¹Ù„ÛŒ (Û±Û³Û¶Û° ØªÙˆÚ©Ù†) Ù…Ø«Ù„ ÛŒÚ© ÙˆÛŒØ±ÙˆØ³ Ø¯Ø± Ø³ÛŒØ³ØªÙ… Ø´Ù…Ø§Ø³Øª. Ù†Ù‡ Ø¨Ù‡ Ø®Ø§Ø·Ø± Ø­Ø¬Ù…Ø´ØŒ Ø¨Ù„Ú©Ù‡ Ø¨Ù‡ Ø®Ø§Ø·Ø± Ù…Ø­ØªÙˆØ§ÛŒØ´.
- **Ø§Ù‚Ø¯Ø§Ù…:** Ù‡Ù…ÛŒÙ† Ø§Ù„Ø§Ù† ÙˆØ§Ø±Ø¯ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ÛŒØ§ Ø§Ø¯Ù…ÛŒÙ† Ø´ÙˆÛŒØ¯ Ùˆ ÙÛŒÙ„Ø¯ `ai_answer_prompt` Ø¨Ø±Ø§ÛŒ Ø±Ø¯ÛŒÙ "Ù†Ø±Ù… Ø§ÙØ²Ø§Ø± Ùˆ Ø®Ø¯Ù…Ø§Øª Ø¢Ù†Ù„Ø§ÛŒÙ†" Ø±Ø§ **NULL** ÛŒØ§ Ø®Ø§Ù„ÛŒ Ú©Ù†ÛŒØ¯.
- **Ú†Ø±Ø§ØŸ** ØªØ§ ÙˆÙ‚ØªÛŒ Ø§ÛŒÙ† Ù…ØªÙ† ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ù…Ø¯Ù„ ÙÚ©Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ø¨Ø§ÛŒØ¯ "Ø¯ÙˆØ±Ù‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ" Ø¨ÙØ±ÙˆØ´Ø¯. Ù‡ÛŒÚ† ØªÙ†Ø¸ÛŒÙ… Ø¨ÙˆØ¯Ø¬Ù‡â€ŒØ§ÛŒ Ø§ÛŒÙ† ØªØ¶Ø§Ø¯ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø±Ø§ Ø­Ù„ Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

#### Ø¨) Ø§Ù†ØªÙ‚Ø§Ù„ System Instruction Ù‡Ø§Ø±Ø¯Ú©Ø¯ Ø´Ø¯Ù‡
ÙˆØ¬ÙˆØ¯ Ù…ØªÙ† Ù‡Ø§Ø±Ø¯Ú©Ø¯ Ø´Ø¯Ù‡ Ø¯Ø± Ú©Ù„Ø§Ø³ Ù¾Ø§ÛŒØªÙˆÙ† (`gemini_service.py`) Ø¨Ø¯ØªØ±ÛŒÙ† ØªÙ…Ø±ÛŒÙ† Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ø¯Ø± Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ RAG Ø§Ø³Øª Ú†ÙˆÙ† Ø¨Ø§ Ù‡Ø± ØªØºÛŒÛŒØ± Ù†ÛŒØ§Ø² Ø¨Ù‡ Deploy Ø¯Ø§Ø±Ø¯.
- **Ø§Ù‚Ø¯Ø§Ù…:** Ø¢Ù† Ù…ØªÙ† Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø¯Ø± `__init__` Ø±Ø§ Ø­Ø°Ù Ú©Ù†ÛŒØ¯ Ùˆ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÛŒÚ© ÙÛŒÙ„Ø¯ Ø¯Ø± `GeneralSettings` (Ù…Ø«Ù„Ø§Ù‹ `base_instruction`) Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†ÛŒØ¯ ØªØ§ Ø§Ø² Ø§Ø¯Ù…ÛŒÙ† Ù¾Ù†Ù„ Ù‚Ø§Ø¨Ù„ ÙˆÛŒØ±Ø§ÛŒØ´ Ø¨Ø§Ø´Ø¯.

#### Ø¬) Ù†ØªØ±Ø³ÛŒØ¯Ù† Ø§Ø² ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ (Ù…Ø²ÛŒØª Gemini)
Ø³ÛŒØ³ØªÙ… ÙØ¹Ù„ÛŒ Ø´Ù…Ø§ Ø·ÙˆØ±ÛŒ Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ú©Ù‡ Ø§Ù†Ú¯Ø§Ø± Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ Û³ Ø³Ø§Ù„ Ù¾ÛŒØ´ (Ø¨Ø§ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Û´Û°Û°Û° ØªÙˆÚ©Ù†) Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
- **Ø§Ù‚Ø¯Ø§Ù…:** ÙˆÙ‚ØªÛŒ BusinessPrompt Ø±Ø§ Ø¯Ø±Ø³Øª Ú©Ø±Ø¯ÛŒØ¯ØŒ Ø¨ÙˆØ¯Ø¬Ù‡ Context Ø±Ø§ **Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡ÛŒØ¯**. Ù†Ú¯Ø±Ø§Ù† Ù†Ø¨Ø§Ø´ÛŒØ¯. Ù…Ù† (Gemini) ØªØ±Ø¬ÛŒØ­ Ù…ÛŒâ€ŒØ¯Ù‡Ù… ÛµÛ°Û°Û° ØªÙˆÚ©Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙ…ÛŒØ² Ùˆ Ù…Ø±ØªØ¨Ø· Ø¨Ø¨ÛŒÙ†Ù… ØªØ§ ÛµÛ°Û° ØªÙˆÚ©Ù† Ù†Ø§Ù‚Øµ.
- Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Û²Û²Û°Û° ØªÙˆÚ©Ù† Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ Ù…Ù† (Gemini 1.5 Flash) ÛŒÚ© Ø´ÙˆØ®ÛŒ Ø§Ø³Øª. Ø¢Ù† Ø±Ø§ Ø¨Ù‡ Ø±Ø§Ø­ØªÛŒ ØªØ§ Û¸Û°Û°Û° ÛŒØ§ Û±Û°Û°Û°Û° Ø¨Ø§Ù„Ø§ Ø¨Ø¨Ø±ÛŒØ¯ØŒ **Ù…Ø´Ø±ÙˆØ· Ø¨Ø± Ø§ÛŒÙ†Ú©Ù‡ Ù…Ø­ØªÙˆØ§ÛŒ Ø¢Ù† ØªÙ…ÛŒØ² Ø¨Ø§Ø´Ø¯**.

### Û³. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø¹Ø¯ Ø§Ø² Ø§ØµÙ„Ø§Ø­
Ø¨Ù‡ Ù…Ø­Ø¶ Ø§ÛŒÙ†Ú©Ù‡ `BusinessPrompt` Ù¾Ø§Ú© Ø´ÙˆØ¯:
1. ØªØ¶Ø§Ø¯ "Ø¢Ù…ÙˆØ²Ø´ÛŒ vs Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±ÛŒ" Ø§Ø² Ø¨ÛŒÙ† Ù…ÛŒâ€ŒØ±ÙˆØ¯.
2. Ù…Ø¯Ù„ Ø¨Ù‡ `ManualPrompt` (Ú©Ù‡ CRM Ø§Ø³Øª) ØªÙˆØ¬Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
3. Ø®Ø±ÙˆØ¬ÛŒ Ø§Ø² Û²Û¸ ØªÙˆÚ©Ù† Ø¨Ù‡ Ø­Ø§Ù„Øª Ù†Ø±Ù…Ø§Ù„ (Û³Û°Û°+ ØªÙˆÚ©Ù†) Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø¯.

**Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ù…Ù†:**
Ø´Ù…Ø§ Ø¯Ø±Ú¯ÛŒØ± ÛŒÚ© Ù…Ø´Ú©Ù„ "Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±" (ØªØ¶Ø§Ø¯ Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§) Ù‡Ø³ØªÛŒØ¯ØŒ Ù†Ù‡ ÛŒÚ© Ù…Ø´Ú©Ù„ "Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ" (Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªÙˆÚ©Ù†). BusinessPrompt Ø±Ø§ Ù¾Ø§Ú© Ú©Ù†ÛŒØ¯ØŒ Ù…Ø´Ú©Ù„ Ø­Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯.

**Ø§ÛŒÙ† Ø¨Ø®Ø´ ØªØ­Ù„ÛŒÙ„ÛŒ ØªÙˆØ³Ø· Ù…Ø¯Ù„ Gemini 2.0 Flash Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.**

---

## Ø¬Ù…Ø¹â€ŒØ¨Ù†Ø¯ÛŒ Ù†Ø¸Ø±Ø§Øª Ùˆ ØªØ­Ù„ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ù…Ø¯Ù„ Ú†Ù‡Ø§Ø±Ù… (Claude Opus 4.5) â€“ Ø¨Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ù„Ø§Ú¯ Ùˆ Ú©Ø¯ Ø²Ù†Ø¯Ù‡

### Û±. Ø¬Ù…Ø¹â€ŒØ¨Ù†Ø¯ÛŒ Ù†Ø¸Ø±Ø§Øª Ø³Ù‡ Ù…Ø¯Ù„ Ù‚Ø¨Ù„ÛŒ

| Ù…Ø¯Ù„ | ØªØ´Ø®ÛŒØµ Ø§ØµÙ„ÛŒ | Ø±Ø§Ù‡â€ŒØ­Ù„ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ | Ù†Ú©ØªÙ‡ Ú©Ù„ÛŒØ¯ÛŒ |
|-----|-----------|----------------|------------|
| **Claude Sonnet 4.5** | Token Overflow (4371 vs 2200) + BusinessPrompt Ø¨Ø²Ø±Ú¯ | Dynamic Budget + Chunk Optimization + Complete Rewrite | Ù…Ø¹Ù…Ø§Ø±ÛŒ Ú©Ø§Ù…Ù„ Ø¬Ø¯ÛŒØ¯ (over-engineered) |
| **GPT-5.1** | ØªØ£ÛŒÛŒØ¯ Ù…Ø´Ú©Ù„Ø§Øª + Ù†Ù‚Ø¯ over-engineering | ÙØ§Ø² Û° (ØªØºÛŒÛŒØ±Ø§Øª Ú©ÙˆÚ†Ú©) â†’ ÙØ§Ø² Û± (ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ) â†’ ÙØ§Ø² Û² (Ù¾ÛŒØ´Ø±ÙØªÙ‡) | ØªÙÚ©ÛŒÚ© Â«Ú©Ø¯ ÙˆØ§Ù‚Ø¹ÛŒÂ» Ø§Ø² Â«Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Â» |
| **Gemini 2.0 Flash** | Context Pollution (ØªØ¶Ø§Ø¯ Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§) Ù†Ù‡ Overflow | Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† BusinessPrompt + Ø§ÙØ²Ø§ÛŒØ´ Ø¨ÙˆØ¯Ø¬Ù‡ | Ù…Ø´Ú©Ù„ semantic Ø§Ø³Øª Ù†Ù‡ capacity |

**ØªÙˆØ§ÙÙ‚ Ù…Ø´ØªØ±Ú© Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§:**
1. âœ… BusinessPrompt Ø­Ø¬ÛŒÙ… Ù…Ø´Ú©Ù„â€ŒØ³Ø§Ø² Ø§Ø³Øª
2. âœ… system_instruction Ù‡Ø§Ø±Ø¯Ú©Ø¯ Ø´Ø¯Ù‡ Ø¨Ø§ÛŒØ¯ Ø­Ø°Ù Ø´ÙˆØ¯
3. âœ… Ø®Ø±ÙˆØ¬ÛŒ Û²Û· ØªÙˆÚ©Ù†ÛŒ ØºÛŒØ±Ø·Ø¨ÛŒØ¹ÛŒ Ø§Ø³Øª
4. âœ… Manual Prompt Ø¯Ø±Ø³Øª Ø¨Ù‡ RAG Ù†Ù…ÛŒâ€ŒØ±Ø³Ø¯

### Û². Ø¨Ø±Ø±Ø³ÛŒ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ø²Ù†Ø¯Ù‡ Ø³Ø±ÙˆØ± (Ø§Ù„Ø§Ù†)

```
ğŸ“Š Ø¢Ø®Ø±ÛŒÙ† Ûµ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ú©Ø§Ø±Ø¨Ø± pilito:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Time                    Prompt    Completion   Model
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
2025-12-07 08:14:23     3081      29           gemini-flash-latest
2025-12-07 08:13:47     3078      56           gemini-flash-latest
2025-12-07 07:56:42     3109      27           gemini-flash-latest
2025-12-06 14:43:32     4351      25           gemini-flash-latest
2025-12-06 14:08:34     4371      26           gemini-flash-latest
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

**ØªØ­Ù„ÛŒÙ„:**
- ğŸ“‰ Ú©Ø§Ù‡Ø´ Ø§Ø² ~4400 Ø¨Ù‡ ~3100 ØªÙˆÚ©Ù† (Ø¨Ø¹Ø¯ Ø§Ø² Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† BusinessPrompt) âœ…
- âš ï¸ **Ø§Ù…Ø§ Ù‡Ù†ÙˆØ² Ù…Ø´Ú©Ù„ Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ø§Ø±Ø¯:** Completion ÙÙ‚Ø· 27-56 ØªÙˆÚ©Ù†!
- âŒ ÛŒØ¹Ù†ÛŒ **Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† BusinessPrompt Ú©Ø§ÙÛŒ Ù†Ø¨ÙˆØ¯Ù‡!**

### Û³. Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø¯ Ø²Ù†Ø¯Ù‡ Ø³Ø±ÙˆØ±

```python
# ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ø¯Ø± Ø³Ø±ÙˆØ±:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
BusinessPrompt "Ù†Ø±Ù… Ø§ÙØ²Ø§Ø± Ùˆ Ø®Ø¯Ù…Ø§Øª Ø¢Ù†Ù„Ø§ÛŒÙ†":
  ai_answer_prompt: NULL (0 chars) âœ… Ù¾Ø§Ú© Ø´Ø¯Ù‡

GeneralSettings combined_system_prompt:
  Length: 3325 chars (~1000+ tokens) âš ï¸ Ù‡Ù†ÙˆØ² Ø¨Ø²Ø±Ú¯

system_instruction Ù‡Ø§Ø±Ø¯Ú©Ø¯ Ø´Ø¯Ù‡ Ø¯Ø± gemini_service.py:
  Lines 88-145: ~58 Ø®Ø· (~600 tokens) âŒ Ù‡Ù†ÙˆØ² ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

**Ú©Ø´Ù Ù…Ù‡Ù…:**
BusinessPrompt Ù¾Ø§Ú© Ø´Ø¯Ù‡ ÙˆÙ„ÛŒ **Ø¯Ùˆ Ù…Ù†Ø¨Ø¹ ØªÙˆÚ©Ù† Ø¯ÛŒÚ¯Ø± Ù‡Ù†ÙˆØ² ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù†Ø¯:**
1. `GeneralSettings` Ø¨Ø§ ~1000 ØªÙˆÚ©Ù†
2. `system_instruction` Ù‡Ø§Ø±Ø¯Ú©Ø¯ Ø¨Ø§ ~600 ØªÙˆÚ©Ù†

**Ù…Ø­Ø§Ø³Ø¨Ù‡:**
```
system_instruction (hardcoded):  ~600 tokens
GeneralSettings:                ~1000 tokens
Context (primary + secondary):  ~1100 tokens
Conversation:                    ~250 tokens
User query:                       ~50 tokens
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total:                          ~3000 tokens â† Ù…Ø·Ø§Ø¨Ù‚ Ù„Ø§Ú¯!
```

### Û´. Ú†Ø±Ø§ Completion Ù‡Ù†ÙˆØ² Ú©Ù… Ø§Ø³ØªØŸ

Ø¨Ø§ ÙˆØ¬ÙˆØ¯ Ú©Ø§Ù‡Ø´ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ØŒ Ø®Ø±ÙˆØ¬ÛŒ Ù‡Ù†ÙˆØ² 27-56 ØªÙˆÚ©Ù† Ø§Ø³Øª. **Ø¯Ù„Ø§ÛŒÙ„:**

**Ø§Ù„Ù) ØªØ¶Ø§Ø¯ Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ Ù‡Ù†ÙˆØ² ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯:**
```python
# system_instruction Ù‡Ø§Ø±Ø¯Ú©Ø¯ Ø´Ø¯Ù‡ Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯:
"Service providers (courses, consulting, training)"  # Ø¯ÙˆØ±Ù‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ!
"Answer customer questions professionally"

# GeneralSettings Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯:
"ÙÙ‚Ø· Ø§Ø² Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†"
"Ø¯Ø±ÙˆØº Ù†Ú¯Ùˆ"

# Manual Prompt (Ú†Ø§Ù†Ú© Ø´Ø¯Ù‡) Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯:
"Ù¾ÛŒÙ„ÛŒØªÙˆ ÛŒÚ© Ù¾Ù„ØªÙØ±Ù… CRM Ø§Ø³Øª"
```

**Ø¨) max_output_tokens Ù…Ø­Ø¯ÙˆØ¯ Ø´Ø¯Ù‡:**
Ø¯Ø± `gemini_service.py` Ø®Ø· 84:
```python
"max_output_tokens": max_tokens  # Ø§ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± Ø§Ø² Ú©Ø¬Ø§ Ù…ÛŒâ€ŒØ¢ÛŒØ¯ØŸ
```

**Ø¬) Safety Triggers:**
ÙˆÙ‚ØªÛŒ Ù…Ø¯Ù„ Ø¯Ø³ØªÙˆØ±Ø§Øª Ù…ØªØ¶Ø§Ø¯ Ù…ÛŒâ€ŒØ¨ÛŒÙ†Ø¯ØŒ ØªØ±Ø¬ÛŒØ­ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ù¾Ø§Ø³Ø® Ú©ÙˆØªØ§Ù‡ Ø¨Ø¯Ù‡Ø¯ ØªØ§ Ø¯Ø±ÙˆØº Ù†Ú¯ÙˆÛŒØ¯.

### Ûµ. Ú†Ú¯ÙˆÙ†Ù‡ Ù…Ø«Ù„ Intercom Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø´ÙˆÛŒÙ…ØŸ

Intercom ÛŒÚ©ÛŒ Ø§Ø² Ø¨Ù‡ØªØ±ÛŒÙ† Ø³ÛŒØ³ØªÙ…â€ŒÙ‡Ø§ÛŒ AI Chat Ø¯Ø± Ø¯Ù†ÛŒØ§Ø³Øª. Ø¨Ø±Ø§ÛŒ Ø±Ø³ÛŒØ¯Ù† Ø¨Ù‡ Ø¢Ù† Ø³Ø·Ø­:

#### ğŸ¯ Ø§ØµÙˆÙ„ Ø·Ø±Ø§Ø­ÛŒ Intercom:

| Ø§ØµÙ„ | Intercom | Ø³ÛŒØ³ØªÙ… ÙØ¹Ù„ÛŒ Ø´Ù…Ø§ | Ø±Ø§Ù‡â€ŒØ­Ù„ |
|-----|----------|---------------|--------|
| **Single Source of Truth** | ÛŒÚ© System Prompt ÙˆØ§Ø­Ø¯ | 3 Ù…Ù†Ø¨Ø¹ Ù…ØªØ¶Ø§Ø¯ | Ø§Ø¯ØºØ§Ù… Ù‡Ù…Ù‡ Ø¯Ø± GeneralSettings |
| **Knowledge Separation** | System â‰  Knowledge | Ù‚Ø§Ø·ÛŒ Ø´Ø¯Ù‡ | Manual = Knowledge, System = Rules |
| **Dynamic Context** | Context Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø¤Ø§Ù„ | Context Ø«Ø§Ø¨Øª | Intent-based routing |
| **Confidence Scoring** | Ø§Ú¯Ø± Ù…Ø·Ù…Ø¦Ù† Ù†ÛŒØ³ØªÙ…ØŒ Ù…ÛŒâ€ŒÚ¯ÙˆÛŒÙ… | Ù‡Ù…ÛŒØ´Ù‡ Ø¬ÙˆØ§Ø¨ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ | Confidence threshold |
| **Fallback Handling** | "Ù†Ù…ÛŒâ€ŒØ¯Ø§Ù†Ù…" Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ | Hallucination | Strict fallback rules |

#### ğŸ”§ Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ø¹Ù…Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø³ÛŒØ¯Ù† Ø¨Ù‡ Ø³Ø·Ø­ Intercom:

**ÙØ§Ø² ÙÙˆØ±ÛŒ (Ø§Ù…Ø±ÙˆØ²):**
```python
# 1. Ø­Ø°Ù system_instruction Ù‡Ø§Ø±Ø¯Ú©Ø¯
# Ø¯Ø± gemini_service.py Ø®Ø· 88-145 Ø±Ø§ Ø­Ø°Ù Ú©Ù†ÛŒØ¯

# 2. Ú©ÙˆØªØ§Ù‡ Ú©Ø±Ø¯Ù† GeneralSettings
# Ø¯Ø± Admin Panel â†’ GeneralSettings
# ÙÙ‚Ø· Ù‚ÙˆØ§Ù†ÛŒÙ† critical Ù†Ú¯Ù‡ Ø¯Ø§Ø±ÛŒØ¯ (max 400 tokens)

# 3. Ø§ÙØ²Ø§ÛŒØ´ max_output_tokens
# Ø¯Ø± gemini_service.py ÛŒØ§ AIGlobalConfig
max_output_tokens = 1000  # Ø¨Ù‡ Ø¬Ø§ÛŒ Ù…Ù‚Ø¯Ø§Ø± ÙØ¹Ù„ÛŒ
```

**ÙØ§Ø² Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª (Ø§ÛŒÙ† Ù‡ÙØªÙ‡):**
```python
# 4. Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Confidence Score
class ResponseConfidence:
    def evaluate(self, query, context_chunks):
        # Ø§Ú¯Ø± Ù‡ÛŒÚ† Ú†Ø§Ù†Ú© Ù…Ø±ØªØ¨Ø· Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ â†’ confidence = 0
        # Ø§Ú¯Ø± Ú†Ø§Ù†Ú© Ø¨Ø§ similarity > 0.8 Ù¾ÛŒØ¯Ø§ Ø´Ø¯ â†’ confidence = high
        if confidence < 0.5:
            return FALLBACK_TEXT
        return generate_response()

# 5. Intent-based System Prompt
def get_system_prompt(intent):
    base_rules = """ÙÙ‚Ø· Ø§Ø² Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†."""
    
    if intent == 'product':
        return base_rules + "\n" + "Ù…Ø­ØµÙˆÙ„Ø§Øª Ø±Ø§ Ù…Ø¹Ø±ÙÛŒ Ú©Ù†."
    elif intent == 'pricing':
        return base_rules + "\n" + "Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ Ø±Ø§ ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡."
    # ...
```

**ÙØ§Ø² Ù…ÛŒØ§Ù†â€ŒÙ…Ø¯Øª (Ø§ÛŒÙ† Ù…Ø§Ù‡):**
```python
# 6. Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¹Ù…Ø§Ø±ÛŒ Intercom-like
class IntercomStyleRAG:
    """
    Single unified pipeline like Intercom
    """
    
    def __init__(self):
        self.system_rules = self._load_rules()  # Ø­Ø¯Ø§Ú©Ø«Ø± 500 token
        self.max_context = 2000  # tokens
        self.max_output = 1000  # tokens
        self.confidence_threshold = 0.6
    
    def respond(self, query, conversation):
        # 1. Intent Detection
        intent = self.detect_intent(query)
        
        # 2. Retrieve Knowledge (NOT system rules!)
        chunks = self.retrieve_chunks(query, intent)
        
        # 3. Confidence Check
        confidence = self.calculate_confidence(chunks)
        if confidence < self.confidence_threshold:
            return self.fallback_response()
        
        # 4. Build Prompt (clean separation)
        prompt = f"""
        [RULES]
        {self.system_rules}
        
        [KNOWLEDGE]
        {self.format_chunks(chunks)}
        
        [CONVERSATION]
        {self.format_conversation(conversation)}
        
        [QUERY]
        {query}
        """
        
        # 5. Generate with proper limits
        response = self.generate(prompt, max_tokens=self.max_output)
        
        return response
```

### Û¶. Checklist Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ø§ØµÙ„Ø§Ø­

```
â–¡ 1. Ø­Ø°Ù system_instruction Ù‡Ø§Ø±Ø¯Ú©Ø¯ (gemini_service.py:88-145)
â–¡ 2. Ú©ÙˆØªØ§Ù‡ Ú©Ø±Ø¯Ù† GeneralSettings Ø¨Ù‡ <500 tokens
â–¡ 3. Ø§ÙØ²Ø§ÛŒØ´ max_output_tokens Ø¨Ù‡ 1000
â–¡ 4. Ø§ÙØ²Ø§ÛŒØ´ context budget Ø¨Ù‡ 3000-4000 tokens
â–¡ 5. Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† 'manual' Ø¨Ù‡ Ù‡Ù…Ù‡ intent routings
â–¡ 6. Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ confidence scoring
â–¡ 7. ØªØ³Øª Ø¨Ø§ Ø³Ø¤Ø§Ù„ "Ø®Ø¯Ù…Ø§Øª Ù¾ÛŒÙ„ÛŒØªÙˆ Ú†ÛŒ Ù‡Ø³ØªØŸ"
â–¡ 8. Ø¨Ø±Ø±Ø³ÛŒ Ù„Ø§Ú¯: prompt_tokens < 2500, completion_tokens > 400
```

### Û·. Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ

**Ù…Ø´Ú©Ù„ Ø§ØµÙ„ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡:**
Ø³ÛŒØ³ØªÙ… Ø´Ù…Ø§ Ø¯Ú†Ø§Ø± **"Ú†Ù†Ø¯ Ø´Ø®ØµÛŒØªÛŒ"** Ø§Ø³Øª:
- `system_instruction` Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯: "ØªÙˆ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ù†ÙˆØ¹ Ú©Ø³Ø¨â€ŒÙˆÚ©Ø§Ø± Ù‡Ø³ØªÛŒ"
- `GeneralSettings` Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯: "Ø§ÛŒÙ† Ù‚ÙˆØ§Ù†ÛŒÙ† Ø±Ø§ Ø±Ø¹Ø§ÛŒØª Ú©Ù†"
- `Manual Prompt` Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯: "Ù¾ÛŒÙ„ÛŒØªÙˆ CRM Ø§Ø³Øª"

Ù…Ø¯Ù„ Ú¯ÛŒØ¬ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ Ù¾Ø§Ø³Ø® Ú©ÙˆØªØ§Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.

**Ø±Ø§Ù‡â€ŒØ­Ù„:**
ÛŒÚ© Ø´Ø®ØµÛŒØª ÙˆØ§Ø­Ø¯ Ø¨Ø§ ÛŒÚ© Ù…Ù†Ø¨Ø¹ Ø­Ù‚ÛŒÙ‚Øª:
```
System Rules (500 tokens): Ù‚ÙˆØ§Ù†ÛŒÙ† Ø±ÙØªØ§Ø±ÛŒ
Knowledge Base (RAG): Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªØ®ØµØµÛŒ
```

**Ø¨Ø±Ø§ÛŒ Ø±Ø³ÛŒØ¯Ù† Ø¨Ù‡ Ø³Ø·Ø­ Intercom:**
1. âœ… Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ Ú©Ø§Ù…Ù„ Rules Ø§Ø² Knowledge
2. âœ… Confidence scoring
3. âœ… Intent-based context selection
4. âœ… Professional fallback handling
5. âœ… Clean prompt architecture

---

**Ø§ÛŒÙ† ØªØ­Ù„ÛŒÙ„ ØªÙˆØ³Ø· Claude Opus 4.5 (Anthropic) Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª.**

**Model:** claude-sonnet-4-20250514  
**ØªØ§Ø±ÛŒØ®:** Ø¯Ø³Ø§Ù…Ø¨Ø± 2025  
**Ø±ÙˆØ´:** Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ú©Ø¯ Ùˆ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÙˆØ± + ØªØ­Ù„ÛŒÙ„ ØªØ·Ø¨ÛŒÙ‚ÛŒ Ø¨Ø§ Intercom
