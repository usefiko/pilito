# ๐งช ุฑุงูููุง ุชุณุช Product Auto-Extraction

## โก ูุงุจูุช ุฌุฏุฏ: Auto-ON!

โ **ูพุดโูุฑุถ:** `auto_extract_products = True`  
๐ค **ููุดููุฏ:** Pre-filter ุชุดุฎุต ูุฏู ุตูุญู ูุญุตูู ุฏุงุฑู ุง ูู  
๐ฐ **ฺฉูโูุฒูู:** ููุท ุตูุญุงุช ุจุง confidence >= 0.4 ุจู AI ูุฑู

---

## ๐ ูุฑุญูู ฑ: Push ฺฉุฑุฏู ฺฉุฏ

```bash
# ุงุฒ ุฏุงุฑฺฉุชูุฑ ุงุตู ูพุฑูฺู
cd /Users/omidataei/Documents/GitHub/Fiko-Backend

# ุจุฑุฑุณ ุชุบุฑุงุช
git status

# Add ุชุบุฑุงุช
git add src/web_knowledge/models.py
git add src/web_knowledge/services/product_extractor.py
git add src/web_knowledge/tasks.py
git add src/web_knowledge/serializers.py

# Commit
git commit -m "feat: AI-powered product auto-extraction with Gemini 1.5 Pro

- Enhanced Product model: pricing, discounts, features, stock, images
- Added auto_extract_products toggle to WebsiteSource
- Created ProductExtractor service with Gemini 1.5 Pro (high accuracy)
- Hybrid extraction: rule-based pre-filter + AI extraction
- Integrated with crawl system (optional, non-breaking)
- Updated serializers to expose new fields
- Source tracking: links products to pages/websites"

# Push
git push origin main
```

---

## ๐ฅ๏ธ ูุฑุญูู ฒ: ุฑู ุณุฑูุฑ (SSH)

### ฒ.ฑ ุงุชุตุงู ู Pull

```bash
# SSH ุจู ุณุฑูุฑ
ssh ubuntu@your-server-ip

# ุฑูุชู ุจู ูพุฑูฺู
cd ~/fiko-backend

# Pull
git pull origin main
```

### ฒ.ฒ ุงุฌุงุฏ ู ุงุฌุฑุง Migration

```bash
# ุณุงุฎุช migration
docker compose exec django_app python src/manage.py makemigrations web_knowledge

# ุจุงุฏ ุงู ุฑู ุจุจูุฏ:
# Migrations for 'web_knowledge':
#   web_knowledge/migrations/0XXX_enhance_product_model.py
#     - Add field auto_extract_products to websitesource
#     - Add field short_description to product
#     - Add field long_description to product
#     - ... (20+ fields)

# ุงุฌุฑุง migration
docker compose exec django_app python src/manage.py migrate web_knowledge

# ุจุงุฏ ุจุจูุฏ:
# Running migrations:
#   Applying web_knowledge.0XXX_enhance_product_model... OK
```

### ฒ.ณ Restart ุณุฑูุณโูุง

```bash
# Restart
docker compose restart django_app celery_worker

# ฺฺฉ ฺฉุฑุฏู ฺฉู ุจุงูุง ุงููุฏู
docker compose ps

# ุจุงุฏ django_app ู celery_worker ูุฑ ุฏู "Up" ุจุงุดู
```

---

## โ ูุฑุญูู ณ: ุชุณุช ุงููู (ุจุฑุฑุณ Migration)

```bash
# ูุงุฑุฏ Django shell ุดูุฏ
docker compose exec django_app python src/manage.py shell
```

**ุฏุฑ shell ุงู ุฏุณุชูุฑุงุช ุฑู ุจุฒูุฏ:**

```python
# 1. ฺฺฉ ฺฉุฑุฏู ููุฏูุง ุฌุฏุฏ Product
from web_knowledge.models import Product

# ูุณุช ููู ููุฏูุง
fields = [f.name for f in Product._meta.fields]
print("Product fields:", fields)

# ุจุงุฏ ุงู ููุฏูุง ุฑู ุจุจูุฏ:
# 'short_description', 'long_description', 'original_price', 
# 'discount_percentage', 'currency', 'features', 'brand', 
# 'category', 'in_stock', 'main_image', 'source_website',
# 'source_page', 'extraction_method', etc.

# 2. ฺฺฉ ฺฉุฑุฏู WebsiteSource toggle
from web_knowledge.models import WebsiteSource

website = WebsiteSource.objects.first()
if website:
    print(f"Website: {website.name}")
    print(f"Auto-extract enabled: {website.auto_extract_products}")
    # ุจุงุฏ False ุจุงุดู (ูพุดโูุฑุถ)

# 3. ฺฺฉ ฺฉุฑุฏู ProductExtractor
from web_knowledge.services.product_extractor import ProductExtractor

if website:
    extractor = ProductExtractor(website.user)
    print(f"Extractor initialized: {extractor.gemini_model is not None}")
    # ุจุงุฏ True ุจุงุดู

# ุจุฑูู ุงููุฏู
exit()
```

**โ ุงฺฏุฑ ููู ฺ OK ุจูุฏุ ุงุฏุงูู ุจุฏุฏ!**

---

## ๐งช ูุฑุญูู ด: ุชุณุช ูุงูุน (ุฏู ุฑูุด)

### ุฑูุด ฑ: ุชุณุช ุจุง ฺฉ ุตูุญู ููุฌูุฏ (ุณุฑุน)

```bash
# ูุงุฑุฏ shell ุดูุฏ
docker compose exec django_app python src/manage.py shell
```

```python
from web_knowledge.models import WebsitePage, Product
from web_knowledge.services.product_extractor import ProductExtractor

# ูพุฏุง ฺฉุฑุฏู ฺฉ ุตูุญู ฺฉู ุงุญุชูุงูุงู ูุญุตูู ุฏุงุฑู
page = WebsitePage.objects.filter(
    word_count__gte=200  # ุตูุญุงุช ุจุง ูุญุชูุง ฺฉุงู
).first()

if page:
    print(f"Testing with page: {page.url}")
    print(f"Title: {page.title}")
    
    # ุชุณุช extraction
    extractor = ProductExtractor(page.website.user)
    
    # Pre-filter test
    should_extract, confidence = extractor.should_extract_from_page(page)
    print(f"\nPre-filter result:")
    print(f"  Should extract: {should_extract}")
    print(f"  Confidence: {confidence:.2f}")
    
    if should_extract:
        # ุงฺฏุฑ confidence ุจุงูุง ุจูุฏุ AI extraction
        print("\n๐ค Running AI extraction...")
        products = extractor.extract_and_save(page)
        
        print(f"\nโ Extracted {len(products)} products:")
        for p in products:
            print(f"\n  ๐ฆ {p.title}")
            print(f"     Price: {p.get_display_price()}")
            print(f"     Type: {p.product_type}")
            print(f"     Features: {p.features[:2] if p.features else []}")
            print(f"     Confidence: {p.extraction_confidence}")
    else:
        print("โฉ Page doesn't look like a product page")
else:
    print("โ No pages found")

exit()
```

---

### ุฑูุด ฒ: ูุนุงู ฺฉุฑุฏู ุจุฑุง ฺฉ Website ู Crawl ุฌุฏุฏ

```bash
docker compose exec django_app python src/manage.py shell
```

```python
from web_knowledge.models import WebsiteSource
from accounts.models import User

# ุงูุชุฎุงุจ ฺฉ user
user = User.objects.first()  # ุง get(email='your@email.com')

# ุณุงุฎุช ฺฉ website ุชุณุช ุจุง ูุญุตููุงุช
# (ูุซุงู: ฺฉ ุณุงุช ูุฑูุดฺฏุงู ุง ุณุงุช ุฎูุฏุชูู)
website = WebsiteSource.objects.create(
    user=user,
    name="Test Shop - Product Extraction",
    url="https://example-shop.com",  # ุณุงุช ฺฉู ูุญุตูู ุฏุงุฑู
    description="Testing auto product extraction",
    max_pages=5,  # ููุท 5 ุตูุญู ุจุฑุง ุชุณุช
    crawl_depth=2,
    auto_extract_products=True  # โ ูุนุงู!
)

print(f"โ Created website: {website.name}")
print(f"   Auto-extract: {website.auto_extract_products}")

# ุดุฑูุน crawl
from web_knowledge.tasks import crawl_website_task

task = crawl_website_task.delay(str(website.id))
print(f"๐ Crawl started! Task ID: {task.id}")

exit()
```

**ฺฺฉ ฺฉุฑุฏู ูุชุงุฌ:**

```bash
# ูุดุงูุฏู logs ุฏุฑ real-time
docker compose logs -f --tail=100 django_app celery_worker

# ุฏูุจุงู ุงู ูพุงูโูุง ุจฺฏุฑุฏุฏ:
# "๐ Starting product auto-extraction"
# "Pre-filter: ... โ Extract: True"
# "โ Gemini 1.5 Pro extracted X products"
# "โ Saved product: ..."
```

---

## ๐ ูุฑุญูู ต: ุจุฑุฑุณ ูุชุงุฌ

### ต.ฑ ุงุฒ Django Shell

```bash
docker compose exec django_app python src/manage.py shell
```

```python
from web_knowledge.models import Product

# ููู ูุญุตููุงุช auto-extracted
auto_products = Product.objects.filter(extraction_method='ai_auto')
print(f"Found {auto_products.count()} auto-extracted products\n")

# ููุงุด ุฌุฒุฆุงุช
for p in auto_products[:5]:
    print(f"{'='*60}")
    print(f"๐ฆ {p.title}")
    print(f"   Type: {p.product_type}")
    print(f"   Price: {p.get_display_price()}")
    print(f"   Currency: {p.currency}")
    
    if p.has_discount:
        print(f"   Discount: {p.discount_info}")
    
    if p.features:
        print(f"   Features: {p.features[:3]}")
    
    if p.brand:
        print(f"   Brand: {p.brand}")
    
    print(f"   In Stock: {p.in_stock}")
    print(f"   Source: {p.source_page.url if p.source_page else 'N/A'}")
    print(f"   Confidence: {p.extraction_confidence:.2f}")
    print(f"   Tags: {p.tags}")

exit()
```

### ต.ฒ ุงุฒ Django Admin

```
1. ุจุฑู ุจู: https://api.fiko.net/admin/web_knowledge/product/
2. ููุชุฑ ฺฉู: extraction_method = 'AI Auto-extracted'
3. ฺฺฉ ฺฉู:
   โ ูุญุตููุงุช auto-extracted ุฑู ูโุจู
   โ ููุชโูุง ุฏุฑุณุช ูุณุชู
   โ ุชุฎููโูุง (ุงฺฏู ูุณุช) ููุงุด ุฏุงุฏู ูุดู
   โ source_page ููฺฉ ุดุฏู
   โ features ู tags ูพุฑ ุดุฏู
```

### ต.ณ ุงุฒ API

```bash
# ูุณุช ูุญุตููุงุช
curl -H "Authorization: Bearer YOUR_TOKEN" \
  https://api.fiko.net/api/v1/web-knowledge/products/ | jq .

# ุจุงุฏ ููุฏูุง ุฌุฏุฏ ุฑู ุจุจูุฏ:
# - short_description
# - original_price, discount_percentage
# - currency, billing_period
# - features, brand, category
# - extraction_method, extraction_confidence
# - source_website, source_page
```

---

## ๐ฏ ฺุฒูุง ฺฉู ุจุงุฏ ฺฺฉ ฺฉูุฏ

### โ Checklist ุชุณุช:

- [ ] Migration ุจุฏูู ุฎุทุง ุงุฌุฑุง ุดุฏ
- [ ] Django ู Celery restart ุดุฏู
- [ ] ProductExtractor initialize ูุดู
- [ ] Pre-filter ฺฉุงุฑ ูโฺฉูู (confidence ูุญุงุณุจู ูุดู)
- [ ] Gemini 1.5 Pro extraction ฺฉุงุฑ ูโฺฉูู
- [ ] ูุญุตููุงุช ุฏุฑ database ุฐุฎุฑู ูุดู
- [ ] ููุฏูุง ุฌุฏุฏ (price, features, etc.) ูพุฑ ูุดู
- [ ] source_page ุจู ุฏุฑุณุช ููฺฉ ูุดู
- [ ] API ููุฏูุง ุฌุฏุฏ ุฑู ุจุฑูโฺฏุฑุฏููู
- [ ] Admin panel ูุญุตููุงุช ุฑู ูุดูู ูุฏู
- [ ] ุงฺฏู auto_extract_products=False ุจุงุดูุ extract ููฺฉูู

---

## ๐ ุนุจโุงุจ (Troubleshooting)

### ูุดฺฉู ฑ: Migration ุฎุทุง ูุฏู

```bash
# ฺฺฉ ฺฉุฑุฏู ูุถุนุช migrations
docker compose exec django_app python src/manage.py showmigrations web_knowledge

# ุงฺฏู conflict ุจูุฏ:
docker compose exec django_app python src/manage.py migrate web_knowledge --fake-initial
```

### ูุดฺฉู ฒ: "Gemini not available"

```bash
# ฺฺฉ ฺฉุฑุฏู API key
docker compose exec django_app python src/manage.py shell

from settings.models import GeneralSettings
settings = GeneralSettings.get_settings()
print(f"Gemini API key configured: {bool(settings.gemini_api_key)}")
exit()
```

### ูุดฺฉู ณ: ูฺ ูุญุตูู extract ููุดู

```python
# ุฏุฑ shell:
from web_knowledge.models import WebsitePage

# ฺฺฉ ฺฉุฑุฏู ูุญุชูุง ุตูุญู
page = WebsitePage.objects.first()
print(f"Content preview: {page.cleaned_content[:500]}")
print(f"Word count: {page.word_count}")

# ฺฺฉ ฺฉุฑุฏู pre-filter
from web_knowledge.services.product_extractor import ProductExtractor
extractor = ProductExtractor(page.website.user)
should, conf = extractor.should_extract_from_page(page)
print(f"Should extract: {should}, Confidence: {conf}")
```

### ูุดฺฉู ด: Logs ูุดูู ููุฏู

```bash
# ุงูุฒุงุด ุณุทุญ logging
docker compose exec django_app python src/manage.py shell

import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('web_knowledge')
logger.setLevel(logging.DEBUG)
```

---

## ๐ฐ ูุฒูู ุชุฎูู

```
Gemini 1.5 Pro:
- Pre-filter: ุฑุงฺฏุงู (rule-based)
- AI extraction: ~$0.00125 per request
- ููุท ุตูุญุงุช ฺฉู confidence >= 0.4 ุฏุงุฑู ูพุฑุฏุงุฒุด ูุดู

ูุซุงู:
- 100 ุตูุญู crawl โ ~40 ุตูุญู candidate โ $0.05
- ุจุณุงุฑ ฺฉู! ๐
```

---

## ๐ ูฺฉุงุช ููู

1. **ุบุฑูุนุงู ุจู ุตูุฑุช ูพุดโูุฑุถ:**
   - `auto_extract_products = False`
   - ุจุงุฏ ุฏุณุช ูุนุงู ฺฉูุฏ

2. **Pre-filter ููุดููุฏ:**
   - ููุท ุตูุญุงุช ฺฉู ุดุจู ูุญุตูู ูุณุชูุฏ ูพุฑุฏุงุฒุด ูุดู
   - ุตุฑููโุฌู ุฏุฑ ูุฒูู AI

3. **Non-breaking:**
   - ุงฺฏู ุฎุทุง ุจุฎูุฑูุ ููุท product extraction fail ูุดู
   - Q&A ู crawl ุงุฏุงูู ูพุฏุง ูโฺฉูู

4. **Source tracking:**
   - ูุฑ ูุญุตูู ุจู ุตูุญู ู website ููุจุน ููฺฉ ูุดู
   - ูโุชููุฏ ุจุจูุฏ ุงุฒ ฺฉุฌุง extract ุดุฏู

---

## ๐ ููููุช!

ุงฺฏู ููู ุชุณุชโูุง OK ุจูุฏ:

โ ุณุณุชู ุขูุงุฏู production ุงุณุช!
โ ูโุชููุฏ ุจุฑุง websiteูุง ูุงูุน ูุนุงูุด ฺฉูุฏ
โ ูุญุตููุงุช ุฎูุฏฺฉุงุฑ ุงุณุชุฎุฑุงุฌ ู ุฐุฎุฑู ูุดู
โ AI ูโุชููู ุงุฒ ุงู ูุญุตููุงุช ุจุฑุง ูพุงุณุฎโุฏู ุงุณุชูุงุฏู ฺฉูู

---

**ููุณูุฏู:** AI Assistant  
**ุชุงุฑุฎ:** October 2025  
**ูุณุฎู:** 1.0

