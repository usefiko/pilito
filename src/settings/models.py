from django.db import models
from django.core.exceptions import ValidationError
from accounts.models import User


class TelegramChannel(models.Model):
    is_connect = models.BooleanField(default=False)
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    bot_token = models.CharField(max_length=200,unique=True)
    bot_username = models.CharField(max_length=100,unique=True)
    profile_picture = models.ImageField(upload_to='telegram_bot_pictures/', null=True, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = "ğŸ“± Telegram Channel"
        verbose_name_plural = "ğŸ“± Telegram Channels"
    
    def __str__(self):
        return str(self.bot_username)


class InstagramChannel(models.Model):
    is_connect = models.BooleanField(default=False)
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    username = models.CharField(max_length=100, unique=True)
    access_token = models.TextField(null=True, blank=True)  # Store Instagram access token
    token_expires_at = models.DateTimeField(null=True, blank=True)  # Track token expiration
    instagram_user_id = models.CharField(max_length=100, null=True, blank=True)  # Instagram user ID
    page_id = models.CharField(max_length=100, null=True, blank=True)  # Instagram page/business ID for webhooks
    account_type = models.CharField(max_length=50, null=True, blank=True)  # business/personal
    followers_count = models.IntegerField(null=True, blank=True)
    following_count = models.IntegerField(null=True, blank=True)
    media_count = models.IntegerField(null=True, blank=True)
    profile_picture_url = models.CharField(max_length=5000,null=True, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = "ğŸ“· Instagram Channel"
        verbose_name_plural = "ğŸ“· Instagram Channels"
    
    def __str__(self):
        return str(self.username)


class AIPrompts(models.Model):
    user = models.OneToOneField(User, on_delete=models.CASCADE, related_name='ai_prompts')
    manual_prompt = models.TextField(max_length=90000000, null=True, blank=True)
    knowledge_source = models.JSONField(null=True, blank=True)
    product_service = models.JSONField(null=True, blank=True)
    question_answer = models.JSONField(null=True, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = "ğŸ¤– AI Prompt"
        verbose_name_plural = "ğŸ¤– AI Prompts"
    
    def __str__(self):
        return f"AI Prompts for {self.user.username}"
    
    @classmethod
    def get_or_create_for_user(cls, user):
        """Get or create AIPrompts for a user with default prompts"""
        prompts, created = cls.objects.get_or_create(
            user=user,
            defaults={
                'manual_prompt': '',  # Empty by default - user must fill this
            }
        )
        return prompts, created
    
    def validate_for_ai_response(self):
        """
        Validate that AIPrompts are ready for AI response generation
        Raises ValueError if manual_prompt is empty
        """
        if not self.manual_prompt or not self.manual_prompt.strip():
            raise ValueError(
                "Manual prompt is required for AI responses. "
                "Please configure your AI prompt in settings before using AI features."
            )
        return True
    
    def get_combined_prompt(self):
        """
        Get combined prompt for AI response generation
        Returns system_prompt + manual_prompt (system first for priority!)
        
        âš ï¸ IMPORTANT: System prompt MUST be first because:
        - Contains core behavior rules (language, tone, length)
        - Gets trimmed to tokens, so first prompts have priority
        - Manual prompt is secondary context (business info)
        
        Now uses modular get_combined_system_prompt() for better management!
        """
        self.validate_for_ai_response()  # Ensure manual_prompt is not empty
        
        combined = ""
        
        # âœ… 1. SYSTEM PROMPT FIRST (highest priority - behavior rules)
        # Now using modular approach from GeneralSettings
        try:
            general_settings = GeneralSettings.get_settings()
            system_prompt = general_settings.get_combined_system_prompt()
            if system_prompt and system_prompt.strip():
                combined += system_prompt.strip()
        except Exception as e:
            # If GeneralSettings is not available, continue without system_prompt
            pass
        
        # âœ… 2. MANUAL PROMPT SECOND (business context)
        if self.manual_prompt and self.manual_prompt.strip():
            if combined:
                combined += "\n\n"
            combined += self.manual_prompt.strip()
        
        return combined


class IntercomTicketType(models.Model):
    """
    Intercom Ticket Type Configuration
    Maps Fiko departments to Intercom ticket types
    """
    DEPARTMENT_CHOICES = [
        ('technical_support', 'Technical Support'),
        ('billing_support', 'Billing Support'),
        ('general_inquiry', 'General Inquiry'),
        ('account_support', 'Account Support'),
    ]
    
    name = models.CharField(
        max_length=100,
        help_text="Ticket type name (e.g., 'Technical Support', 'Billing Issue')"
    )
    department = models.CharField(
        max_length=20,
        choices=DEPARTMENT_CHOICES,
        unique=True,
        help_text="Department to map this ticket type to"
    )
    intercom_ticket_type_id = models.CharField(
        max_length=50,
        help_text="Intercom Ticket Type ID from Intercom settings (e.g., '2918773')"
    )
    is_active = models.BooleanField(
        default=True,
        help_text="Whether this ticket type is active"
    )
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        ordering = ['department']
        verbose_name = "ğŸ« Intercom Ticket Type"
        verbose_name_plural = "ğŸ« Intercom Ticket Types"
    
    def __str__(self):
        return f"{self.name} ({self.get_department_display()}) â†’ ID: {self.intercom_ticket_type_id}"


class SupportTicket(models.Model):
    STATUS_CHOICES = [
        ('open', 'Open'),
        ('under_review', 'Under Review'),
        ('support_response', 'Support Response'),
        ('customer_reply', 'Customer Reply'),
        ('closed', 'Closed'),
    ]
    
    DEPARTMENT_CHOICES = IntercomTicketType.DEPARTMENT_CHOICES
    
    title = models.CharField(max_length=200)
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    department = models.CharField(max_length=20, choices=DEPARTMENT_CHOICES, default='general_inquiry')
    status = models.CharField(max_length=20, choices=STATUS_CHOICES, default='open')
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    # Intercom integration
    intercom_conversation_id = models.CharField(
        max_length=255, 
        blank=True, 
        null=True, 
        unique=True,
        help_text='[DEPRECATED] Old Conversations API ID - kept for backward compatibility'
    )
    
    intercom_ticket_id = models.CharField(
        max_length=255,
        blank=True,
        null=True,
        unique=True,
        help_text='Intercom Ticket ID from Tickets API for two-way sync'
    )
    
    class Meta:
        ordering = ['-updated_at']
        verbose_name = "ğŸ« Support Ticket"
        verbose_name_plural = "ğŸ« Support Tickets"
    
    def __str__(self):
        return f"#{self.id:03d} - {self.title}"
    
    @property
    def intercom_id(self):
        """Returns ticket_id if exists, else conversation_id (backward compatibility)"""
        return self.intercom_ticket_id or self.intercom_conversation_id


class SupportMessage(models.Model):
    ticket = models.ForeignKey(SupportTicket, on_delete=models.CASCADE, related_name='messages')
    content = models.TextField()
    is_from_support = models.BooleanField(default=False)
    sender = models.ForeignKey(User, on_delete=models.CASCADE, null=True, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        ordering = ['-created_at']  # Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ø§ÙˆÙ„
        verbose_name = "ğŸ’¬ Support Message"
        verbose_name_plural = "ğŸ’¬ Support Messages"
    
    def __str__(self):
        sender_type = "Support" if self.is_from_support else "Customer"
        return f"{sender_type} message in ticket #{self.ticket.id:03d}"


class SupportMessageAttachment(models.Model):
    message = models.ForeignKey(SupportMessage, on_delete=models.CASCADE, related_name='attachments')
    file = models.FileField(upload_to='support_attachments/')
    original_filename = models.CharField(max_length=255)
    file_size = models.PositiveIntegerField()  # Size in bytes
    file_type = models.CharField(max_length=100)  # MIME type
    uploaded_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        ordering = ['uploaded_at']
        verbose_name = "ğŸ“ Support Message Attachment"
        verbose_name_plural = "ğŸ“ Support Message Attachments"
    
    def __str__(self):
        return f"Attachment: {self.original_filename} for message #{self.message.id}"
    
    def save(self, *args, **kwargs):
        if self.file:
            self.file_size = self.file.size
            self.original_filename = self.file.name.split('/')[-1]
            # Get file MIME type
            import mimetypes
            self.file_type = mimetypes.guess_type(self.file.name)[0] or 'application/octet-stream'
        super().save(*args, **kwargs)


# Not complete V

class SingletonModel(models.Model):
    class Meta:
        abstract = True
    def save(self, *args, **kwargs):
        if not self.pk and self.__class__.objects.exists():
            raise ValidationError('There can be only one instance of this model.')
        return super(SingletonModel, self).save(*args, **kwargs)



class GeneralSettings(SingletonModel):
    """
    General AI Settings - Modular Prompt Management (Standard Approach)
    Similar to: OpenAI ChatGPT, Intercom Fin, Zendesk AI
    
    This model uses a modular approach to manage AI prompts, allowing
    each aspect of AI behavior to be configured separately for better
    maintainability and clarity.
    """
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“Œ SECTION 1: Core Identity & Behavior
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ai_role = models.TextField(
        max_length=500,
        default="""You are a sales assistant, NOT a support agent.
Your goal is to understand customer needs and recommend relevant products/services.
Always look for opportunities to suggest products that match their needs.
Be helpful, friendly, and proactive in offering solutions.""",
        verbose_name="ğŸ¤– AI Role & Identity",
        help_text=(
            "ØªØ¹Ø±ÛŒÙ Ú©Ù†ÛŒØ¯ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ú†Ù‡ Ú©Ø³ÛŒ Ø§Ø³Øª (Ù…Ø«Ù„Ø§Ù‹ 'ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± ÙØ±ÙˆØ´ Ø¯ÙˆØ³ØªØ§Ù†Ù‡' ÛŒØ§ 'ÛŒÚ© Ù…Ø´Ø§ÙˆØ± ÙÙ†ÛŒ')\n"
            "Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù‡ÙˆÛŒØª Ø§ØµÙ„ÛŒ AI Ø±Ø§ Ù…Ø´Ø®Øµ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."
        )
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“Œ SECTION 2: Language & Communication Style
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    language_rules = models.TextField(
        max_length=1000,
        default="""Always reply in Persian (Farsi).
Convert Latin names to Persian equivalents (e.g., Omid â†’ Ø§Ù…ÛŒØ¯).
Use everyday Persian expressions, not formal sentences.""",
        verbose_name="ğŸŒ Language & Localization",
        help_text=(
            "Ù‚ÙˆØ§Ù†ÛŒÙ† Ø²Ø¨Ø§Ù†ÛŒ Ùˆ Ù…Ø­Ù„ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø±Ø§ ØªØ¹Ø±ÛŒÙ Ú©Ù†ÛŒØ¯.\n"
            "Ù…Ø«Ø§Ù„: 'Ù‡Ù…ÛŒØ´Ù‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ù¾Ø§Ø³Ø® Ø¨Ø¯Ù‡'ØŒ 'Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ù„Ø§ØªÛŒÙ† Ø±Ø§ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†'\n"
            "Ø§ÛŒÙ† Ù‚Ø³Ù…Øª ØªØ¹ÛŒÛŒÙ† Ù…ÛŒâ€ŒÚ©Ù†Ø¯ AI Ú†Ù‡ Ø²Ø¨Ø§Ù†ÛŒ Ùˆ Ø¨Ø§ Ú†Ù‡ Ø³Ø¨Ú©ÛŒ ØµØ­Ø¨Øª Ú©Ù†Ø¯."
        )
    )
    
    tone_and_style = models.TextField(
        max_length=1000,
        default="""Speak casually and emotionally, not like a brochure.
Write like a person chatting on Instagram.
Keep responses under 2 short lines.""",
        verbose_name="ğŸ’¬ Tone & Style (Ù„Ø­Ù† Ùˆ Ø³Ø¨Ú©)",
        help_text=(
            "Ù„Ø­Ù† Ùˆ Ø³Ø¨Ú© Ù…Ú©Ø§Ù„Ù…Ù‡ AI Ø±Ø§ ØªØ¹ÛŒÛŒÙ† Ú©Ù†ÛŒØ¯.\n"
            "Ù…Ø«Ø§Ù„: 'ØµÙ…ÛŒÙ…ÛŒ Ùˆ Ø§Ø­Ø³Ø§Ø³ÛŒ ØµØ­Ø¨Øª Ú©Ù†'ØŒ 'Ù…Ø«Ù„ ÛŒÚ© ÙØ±Ø¯ ÙˆØ§Ù‚Ø¹ÛŒ Ø¯Ø± Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù… Ø¨Ù†ÙˆÛŒØ³'\n"
            "Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø´Ø®ØµÛŒØª AI Ø±Ø§ Ø´Ú©Ù„ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯."
        )
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“Œ SECTION 3: Response Guidelines
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    response_length = models.CharField(
        max_length=20,
        choices=[
            ('concise', 'ğŸ”¹ Concise (1-2 Ø¬Ù…Ù„Ù‡ Ú©ÙˆØªØ§Ù‡)'),
            ('moderate', 'ğŸ”¸ Moderate (2-4 Ø¬Ù…Ù„Ù‡ Ù…ØªÙˆØ³Ø·)'),
            ('detailed', 'ğŸ”¶ Detailed (4+ Ø¬Ù…Ù„Ù‡ ØªÙØµÛŒÙ„ÛŒ)'),
        ],
        default='concise',
        verbose_name="ğŸ“ Response Length (Ø·ÙˆÙ„ Ù¾Ø§Ø³Ø®)",
        help_text=(
            "ØªØ¹ÛŒÛŒÙ† Ú©Ù†ÛŒØ¯ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ AI Ú†Ù‚Ø¯Ø± Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø¨Ø§Ø´Ù†Ø¯.\n"
            "Ú©ÙˆØªØ§Ù‡: Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒØ¹ (Ù…Ø«Ù„ Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù…)\n"
            "Ù…ØªÙˆØ³Ø·: Ø¨Ø±Ø§ÛŒ ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ù„ÛŒ\n"
            "ØªÙØµÛŒÙ„ÛŒ: Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„ Ùˆ Ø¬Ø§Ù…Ø¹"
        )
    )
    
    response_guidelines = models.TextField(
        max_length=1000,
        default="""Maximum 600 characters for Instagram compatibility.
Maximum 3-4 sentences per response.
Limit emojis to 1 per message.
Avoid long introductions â€” go straight to the point.
If topic is complex, give a short summary. User can ask for details.

ğŸ¯ PERSONALIZATION WITH BIO:
- If customer has a bio, USE IT in your first response
- Mention their work/interest naturally to show you understand them
- Example: "Ø¯ÛŒØ¯Ù… Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒØ³Øª Ø¨Ø±Ù†Ø¯ÛŒÙ†Ú¯ Ù‡Ø³ØªÛŒØŒ ÙÛŒÚ©Ùˆ Ø¨Ø±Ø§Øª Ø¹Ø§Ù„ÛŒÙ‡!"
- Convert Latin names to Persian (Omid â†’ Ø§Ù…ÛŒØ¯)

ğŸ“·ğŸ¤ MEDIA MESSAGE RULE:
- If you see '[sent an image]:', the customer SENT an image (not described it)
- If you see '[sent a voice message]:', the customer SENT audio (not typed it)
- The text after is AI analysis of their media
- Respond naturally about what they sent, don't say 'you described'""",
        verbose_name="ğŸ“ Response Guidelines (Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ)",
        help_text=(
            "Ù‚ÙˆØ§Ù†ÛŒÙ† Ø§Ø¶Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ÙØ±Ù…Øª Ùˆ Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§.\n"
            "Ø´Ø§Ù…Ù„: Ø·ÙˆÙ„ Ù¾Ø§Ø³Ø® (600 Ú©Ø§Ø±Ø§Ú©ØªØ± Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù…)ØŒ emoji limitØŒ media rules\n"
            "Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¬Ø²Ø¦ÛŒØ§Øª ÙØ±Ù…Øª Ù¾Ø§Ø³Ø® Ø±Ø§ Ú©Ù†ØªØ±Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."
        )
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“Œ SECTION 4: Greeting & Name Usage
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    greeting_rules = models.TextField(
        max_length=1000,
        default="""â›” CRITICAL RULE: Say 'Ø³Ù„Ø§Ù…' or 'Hi' ONLY ONCE per conversation!

When you see "<greeting_context>FIRST_MESSAGE</greeting_context>":
â†’ Greet with customer's name ONCE: "Ø³Ù„Ø§Ù… [Ù†Ø§Ù…]!"
â†’ Then answer their question naturally

When you see "<greeting_context>WELCOME_BACK_AFTER_*_HOURS</greeting_context>":
â†’ Say "Ø®ÙˆØ´ Ø¨Ø±Ú¯Ø´ØªÛŒ!" ONCE (do NOT say Ø³Ù„Ø§Ù…)
â†’ Then answer directly

When you see "<greeting_context>RECENT_CONVERSATION_ALREADY_GREETED</greeting_context>":
â†’ Do NOT greet at all
â†’ Answer the question DIRECTLY without any greeting word
â†’ Example: "Ø¨Ù„Ù‡ØŒ Ù…ÛŒâ€ŒØªÙˆÙ†Ù… Ú©Ù…Ú© Ú©Ù†Ù…..."

â›” NEVER say "Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø³Ù„Ø§Ù…" or repeat any greeting!
â›” NEVER print the greeting_context tags in your response - they are instructions only!""",
        verbose_name="ğŸ‘‹ Greeting & Name Usage (Ø§Ø­ÙˆØ§Ù„Ù¾Ø±Ø³ÛŒ Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ø§Ù…)",
        help_text=(
            "Ù‚ÙˆØ§Ù†ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ø§Ø­ÙˆØ§Ù„Ù¾Ø±Ø³ÛŒ Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ø§Ù… Ù…Ø´ØªØ±ÛŒ.\n"
            "Ø´Ø§Ù…Ù„: first message greeting, welcome back (12+ hours), no repeat greeting\n"
            "Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªÚ©Ø±Ø§Ø± Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ù†Ø§Ù… Ùˆ Ø§Ø­ÙˆØ§Ù„Ù¾Ø±Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø²Ø§Ø­Ù…."
        )
    )
    
    welcome_back_threshold_hours = models.IntegerField(
        default=12,
        verbose_name="â° Welcome Back Threshold (Ø³Ø§Ø¹Øª)",
        help_text=(
            "Ø¨Ø¹Ø¯ Ø§Ø² Ú†Ù†Ø¯ Ø³Ø§Ø¹ØªØŒ AI Ø¨Ø§ÛŒØ¯ Ø¨Ú¯ÙˆÛŒØ¯ 'Ø®ÙˆØ´ Ø¨Ø±Ú¯Ø´ØªÛŒ'ØŸ\n"
            "Ù¾ÛŒØ´â€ŒÙØ±Ø¶: 12 Ø³Ø§Ø¹Øª\n"
            "Ø§Ú¯Ø± Ù…Ø´ØªØ±ÛŒ Ø¨Ø¹Ø¯ Ø§Ø² Ø§ÛŒÙ† Ù…Ø¯Øª Ø¨Ø±Ú¯Ø±Ø¯Ø¯ØŒ AI Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯ 'Ø®ÙˆØ´ Ø¨Ø±Ú¯Ø´ØªÛŒ!' Ø¨Ù‡ Ø¬Ø§ÛŒ 'Ø³Ù„Ø§Ù…'"
        )
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“Œ SECTION 5: Anti-Hallucination & Accuracy
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    anti_hallucination_rules = models.TextField(
        max_length=1000,
        default="""ğŸš¨ Ù‚ÙˆØ§Ù†ÛŒÙ† Ø¶Ø¯ ØªÙˆÙ‡Ù…â€ŒØ²Ø§ÛŒÛŒ (Critical):

1) Ù‡Ù…ÛŒØ´Ù‡ Ø§ÙˆÙ„ Ú©Ø§Ù†ØªÚ©Ø³Øª Ùˆ Ù†Ø§Ù„Ø¬ Ø±Ø§ Ú†Ú© Ú©Ù†:
   - Ø§Ú¯Ø± chunk/FAQ/Ù…Ø­ØµÙˆÙ„/Ø³Ø§ÛŒØª Ø¯Ø± Ú©Ø§Ù†ØªÚ©Ø³Øª Ù‡Ø³Øª â†’ Ø§Ø² Ù‡Ù…Ø§Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
   - Ø§Ú¯Ø± Ú†ÛŒØ²ÛŒ Ø¯Ø± Ú©Ø§Ù†ØªÚ©Ø³Øª Ù†ÛŒØ³ØªØŒ Ø®ÙˆØ¯Øª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù†Ø³Ø§Ø²

2) Ø§ÛŒÙ†â€ŒÙ‡Ø§ Ø±Ø§ Ù‡Ø±Ú¯Ø² Ø§Ø®ØªØ±Ø§Ø¹ Ù†Ú©Ù†:
   - Ø¢Ø¯Ø±Ø³ØŒ Ø´Ù…Ø§Ø±Ù‡ ØªÙ…Ø§Ø³ØŒ Ù‚ÛŒÙ…ØªØŒ Ù…ÙˆØ¬ÙˆØ¯ÛŒØŒ Ù„ÛŒÙ†Ú©
   - Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø­ØµÙˆÙ„ ÛŒØ§ Ø®Ø¯Ù…Ø§ØªÛŒ Ú©Ù‡ ØªÙˆ Ú©Ø§Ù†ØªÚ©Ø³Øª Ù†ÛŒØ³Øª
   - Ù‡ÛŒÚ†â€ŒÙˆÙ‚Øª Ù†Ú¯Ùˆ "Ø§Ù„Ø§Ù† Ù…ÛŒâ€ŒÙØ±Ø³ØªÙ…" Ø§Ú¯Ø± Ø§Ù„Ø§Ù† Ù†Ø¯Ø§Ø±ÛŒ

3) Ø§Ú¯Ø± Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù†Ø¯Ø§Ø±ÛŒ:
   - ØµØ§Ø¯Ù‚Ø§Ù†Ù‡ Ø¨Ú¯Ùˆ: "Ø§ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ù„Ø§Ù† ØªÙˆ Ø¯Ø§Ù†Ø´ Ù…Ù† Ù†ÛŒØ³Øª"
   - Ø§Ø² Ù…ØªÙ† knowledge_limitation_response Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†

4) Ù„ÛŒÙ†Ú© Ùˆ ÙˆØ¨â€ŒØ³Ø§ÛŒØª (Ø®ÛŒÙ„ÛŒ Ù…Ù‡Ù…):
   - Ø§Ú¯Ø± ÙÙ‚Ø· ÛŒÚ© Ù„ÛŒÙ†Ú© Ù…ÛŒâ€ŒØ¨ÛŒÙ†ÛŒ Ùˆ Ù…Ø­ØªÙˆØ§ÛŒ ØµÙØ­Ù‡ Ø¯Ø± Ú©Ø§Ù†ØªÚ©Ø³Øª Ù†ÛŒØ³ØªØŒ Ø§ØµÙ„Ø§Ù‹ Ø­Ø¯Ø³ Ù†Ø²Ù†
   - Ø¨Ú¯Ùˆ: "Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ù…Ù† Ù†Ù…ÛŒâ€ŒØªÙˆÙ†Ù… Ù…Ø­ØªÙˆØ§ÛŒ Ø§ÛŒÙ† Ù„ÛŒÙ†Ú© Ø±Ø§ Ø¨Ø¨ÛŒÙ†Ù…. Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ÛŒ Ø±Ø§Ø¬Ø¹ Ø¨Ù‡Ø´ Ø¯Ø§Ø±ÛŒØŒ Ù„Ø·ÙØ§Ù‹ ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡."
   
   âš ï¸ CRITICAL: If user sends ONLY a URL without context:
   - NEVER guess what the link is about
   - Say you can't see the content

5) Ù¾Ø³Øª/Ø±ÛŒÙ„Ø² Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù…:
   - ØªÙˆ ÙÙ‚Ø· caption/Ù…ØªÙ† Ø±Ø§ Ù…ÛŒâ€ŒØ¨ÛŒÙ†ÛŒØŒ Ù†Ù‡ ØªØµÙˆÛŒØ±/ÙˆÛŒØ¯ÛŒÙˆ
   - Ø¨Ø± Ø§Ø³Ø§Ø³ Ù‡Ù…Ø§Ù† Ù…ØªÙ† Ø¬ÙˆØ§Ø¨ Ø¨Ø¯Ù‡ØŒ Ù†Ù‡ Ú†ÛŒØ²ÛŒ Ú©Ù‡ Ø¯Ø§Ø®Ù„ ØªØµÙˆÛŒØ± Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø§Ø´Ø¯""",
        verbose_name="ğŸš¨ Anti-Hallucination Rules (Ù‚ÙˆØ§Ù†ÛŒÙ† Ø¶Ø¯ ØªÙˆÙ‡Ù…â€ŒØ²Ø§ÛŒÛŒ)",
        help_text=(
            "âš ï¸ Ø¨Ø³ÛŒØ§Ø± Ù…Ù‡Ù…: Ù‚ÙˆØ§Ù†ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù†Ø§Ø¯Ø±Ø³Øª.\n"
            "Ù…Ø«Ø§Ù„: 'Ù‡Ø±Ú¯Ø² Ù†Ú¯Ùˆ \"Ø§Ù„Ø§Ù† Ù…ÛŒâ€ŒÙØ±Ø³ØªÙ…\" Ø§Ú¯Ø± Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù†Ø¯Ø§Ø±ÛŒ'\n"
            "Ø§ÛŒÙ† Ù‚Ø³Ù…Øª Ø§Ø² Ø¯Ø±ÙˆØº Ú¯ÙØªÙ† AI Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."
        )
    )
    
    knowledge_limitation_response = models.TextField(
        max_length=500,
        default="Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø§ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø±Ùˆ Ù†Ø¯Ø§Ø±Ù…. Ù…ÛŒâ€ŒØªÙˆÙ†Ù… Ø¨Ù‡Øª Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø§ØµÙ„ÛŒâ€ŒÙ…ÙˆÙ† Ú©Ù…Ú© Ú©Ù†Ù…ØŒ ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§ÛŒ Ø¨Ø§ ØªÛŒÙ… Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ ØµØ­Ø¨Øª Ú©Ù†ÛŒØŸ",
        verbose_name="ğŸ“¢ Knowledge Limitation Response (Ù¾Ø§Ø³Ø® Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø¯Ø§Ù†Ø´)",
        help_text=(
            "Ù¾Ø§Ø³Ø® Ù¾ÛŒØ´â€ŒÙØ±Ø¶ ÙˆÙ‚ØªÛŒ AI Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù†Ø¯Ø§Ø±Ø¯.\n"
            "Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² placeholder {contact_method} Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.\n"
            "Ù…Ø«Ø§Ù„: 'Ø§ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø±Ùˆ Ù†Ø¯Ø§Ø±Ù…ØŒ ÙˆÙ„ÛŒ Ø§Ø² {contact_method} Ø¨Ù¾Ø±Ø³'"
        )
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“Œ SECTION 6: Link & URL Handling
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    link_handling_rules = models.TextField(
        max_length=500,
        default="""ğŸ”— LINK RULES:
1. For IMPORTANT links (website/product): [[CTA:Ø¹Ù†ÙˆØ§Ù†|https://url]]
   Example: [[CTA:Ø³Ø§ÛŒØª Ù…Ø§|https://pilito.com]]
2. For casual links: plain URL (https://...)
3. NEVER use placeholders like [link] or invent URLs""",
        verbose_name="ğŸ”— Link & URL Handling (Ù…Ø¯ÛŒØ±ÛŒØª Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§)",
        help_text=(
            "âš ï¸ Ø¨Ø³ÛŒØ§Ø± Ù…Ù‡Ù…: Ù‚ÙˆØ§Ù†ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù„ÛŒÙ†Ú© Ùˆ URL.\n"
            "Ø´Ø§Ù…Ù„: ÙØ±Ù…Øª CTA Ø¨Ø±Ø§ÛŒ Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù… [[CTA:Ø¹Ù†ÙˆØ§Ù†|URL]]\n"
            "Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù‚Øµ ÛŒØ§ Ø¬Ø¹Ù„ÛŒ."
        )
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“Œ SECTION 7: Advanced (Optional)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    custom_instructions = models.TextField(
        max_length=2000,
        blank=True,
        null=True,
        verbose_name="âš¡ Custom Instructions (Ø¯Ø³ØªÙˆØ±Ø§Øª Ø³ÙØ§Ø±Ø´ÛŒ - Ø§Ø®ØªÛŒØ§Ø±ÛŒ)",
        help_text=(
            "Ø¯Ø³ØªÙˆØ±Ø§Øª Ø§Ø¶Ø§ÙÛŒ Ú©Ù‡ Ø¯Ø± Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù„Ø§ Ù†Ú¯Ù†Ø¬ÛŒØ¯Ù‡ Ø§Ø³Øª.\n"
            "Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ø±Ø§ÛŒ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø®Ø§Øµ Ùˆ Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ø´Ù…Ø§Ø³Øª.\n"
            "Ø§Ú¯Ø± Ù†ÛŒØ§Ø²ÛŒ Ù†Ø¯Ø§Ø±ÛŒØ¯ Ø®Ø§Ù„ÛŒ Ø¨Ú¯Ø°Ø§Ø±ÛŒØ¯."
        )
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“Œ DEPRECATED FIELD (for backward compatibility)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    auto_prompt = models.TextField(
        max_length=5000,
        default='''You are an AI customer service representative.
Respond to customer inquiries professionally and helpfully.
Always respond in the same language the customer uses.
Keep your responses clear and concise.

ğŸ”— CRITICAL - Links & URLs:
- Always include FULL URLs (e.g., https://fiko.net/pricing)
- NEVER use placeholders like [link] or [URL]
- Write complete clickable links in your responses''',
        blank=True,
        null=True,
        verbose_name="âš ï¸ [DEPRECATED] Old Auto Prompt",
        help_text=(
            "âš ï¸ Ø§ÛŒÙ† ÙÛŒÙ„Ø¯ Ù…Ù†Ø³ÙˆØ® Ø´Ø¯Ù‡ Ø§Ø³Øª (Deprecated).\n"
            "Ø§Ø² ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§Ù„Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.\n"
            "Ø§ÛŒÙ† ÙÛŒÙ„Ø¯ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ Ù†Ø³Ø®Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø´Ø¯Ù‡."
        )
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“Œ API Keys
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    gemini_api_key = models.CharField(
        max_length=200,
        null=True,
        blank=True,
        verbose_name="ğŸ”‘ Gemini API Key",
        help_text="Ú©Ù„ÛŒØ¯ API Ú¯ÙˆÚ¯Ù„ Ø¬Ù…ÛŒÙ†Ø§ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"
    )
    openai_api_key = models.CharField(
        max_length=200,
        null=True,
        blank=True,
        verbose_name="ğŸ”‘ OpenAI API Key",
        help_text="Ú©Ù„ÛŒØ¯ API Ø§ÙˆÙ¾Ù†â€ŒØ§ÛŒâ€ŒØ¢ÛŒ Ø¨Ø±Ø§ÛŒ embedding Ú†Ù†Ø¯Ø²Ø¨Ø§Ù†Ù‡ (text-embedding-3-large)"
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“Œ Metadata
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        verbose_name = "âš™ï¸ General AI Settings"
        verbose_name_plural = "âš™ï¸ General AI Settings"

    def __str__(self):
        return "General AI Settings"
    
    def get_combined_system_prompt(self) -> str:
        """
        Combine all modular fields into one system prompt.
        This is called at runtime, NOT stored in DB.
        
        This is the STANDARD approach used by:
        - OpenAI ChatGPT
        - Intercom Fin AI
        - Zendesk AI
        
        Returns:
            str: Combined system prompt from all sections
        """
        sections = []
        
        # 1. Role & Identity
        if self.ai_role and self.ai_role.strip():
            sections.append(self.ai_role.strip())
        
        # 2. Language Rules
        if self.language_rules and self.language_rules.strip():
            sections.append(f"ğŸ§  Language:\n{self.language_rules.strip()}")
        
        # 3. Tone & Style
        if self.tone_and_style and self.tone_and_style.strip():
            sections.append(f"ğŸ’¬ Style:\n{self.tone_and_style.strip()}")
        
        # 4. Response Guidelines
        if self.response_guidelines and self.response_guidelines.strip():
            guidelines = self.response_guidelines.strip()
            # Add length preference
            length_note = {
                'concise': 'Keep responses CONCISE (1-2 sentences max)',
                'moderate': 'Keep responses MODERATE (2-4 sentences)',
                'detailed': 'Provide DETAILED responses (4+ sentences when needed)'
            }.get(self.response_length, '')
            
            if length_note:
                guidelines = f"{length_note}\n{guidelines}"
            
            sections.append(f"ğŸ“ Response Guidelines:\n{guidelines}")
        
        # 5. Greeting Rules
        if self.greeting_rules and self.greeting_rules.strip():
            sections.append(f"ğŸ¯ Greeting Rules:\n{self.greeting_rules.strip()}")
        
        # 6. Anti-Hallucination (CRITICAL!)
        if self.anti_hallucination_rules and self.anti_hallucination_rules.strip():
            rules = self.anti_hallucination_rules.strip()
            
            # âœ… Hard cap at 800 characters to prevent token budget overflow
            if len(rules) > 800:
                rules = rules[:800] + "\n\nâš ï¸ (Ù‚ÙˆØ§Ù†ÛŒÙ† Ú©Ø§Ù…Ù„ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªÙˆÚ©Ù† trim Ø´Ø¯Ù†Ø¯ - Ø§ØµÙˆÙ„ Ú©Ù„ÛŒØ¯ÛŒ Ø­ÙØ¸ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯)"
            
            sections.append(f"ğŸš¨ CRITICAL - Anti-Hallucination:\n{rules}")
            
            if self.knowledge_limitation_response and self.knowledge_limitation_response.strip():
                sections.append(f"When lacking information, respond with:\n{self.knowledge_limitation_response.strip()}")
        
        # 7. Link Handling (CRITICAL!)
        if self.link_handling_rules and self.link_handling_rules.strip():
            sections.append(f"ğŸ”— CRITICAL - Links & URLs:\n{self.link_handling_rules.strip()}")
        
        # 8. Custom Instructions
        if self.custom_instructions and self.custom_instructions.strip():
            sections.append(f"âš¡ Additional Instructions:\n{self.custom_instructions.strip()}")
        
        # Combine all sections
        combined = "\n\n".join(sections)
        
        # Fallback to deprecated auto_prompt if nothing configured
        if not combined and self.auto_prompt:
            return self.auto_prompt
        
        return combined or "You are a helpful AI assistant."
    
    @classmethod
    def get_settings(cls):
        """Get or create the general settings instance"""
        settings, created = cls.objects.get_or_create(pk=1)
        return settings


class AIBehaviorSettings(models.Model):
    """
    Per-User AI Behavior Customization
    
    Allows each business owner (User = Tenant in current architecture) to customize
    AI personality and behavior without writing prompts. Uses toggle-based approach
    for simplicity.
    
    Architecture Note:
    - In current system: User = Business Owner = Tenant
    - Each User has ONE AIBehaviorSettings (OneToOne)
    - If future multi-staff support needed, this will need refactoring
    
    Integration Points:
    - GeminiChatService.__init__() â†’ max_output_tokens based on response_length
    - GeminiChatService._build_prompt() â†’ inject behavior flags
    - Greeting logic â†’ use_customer_name toggle
    - Bio injection â†’ use_bio_context toggle
    - Fallback handling â†’ unknown_fallback_text
    
    Token Budget:
    - Flag-based approach uses ~30-40 tokens (vs 150-200 for descriptive)
    - CTA text: max 300 chars (~75 tokens)
    - Fallback text: max 500 chars (~125 tokens)
    - Custom instructions: max 1000 chars (~250 tokens)
    - Total: ~400 tokens max (well within 700 token system prompt budget)
    """
    
    user = models.OneToOneField(
        User,
        on_delete=models.CASCADE,
        related_name='ai_behavior',
        verbose_name="Ú©Ø§Ø±Ø¨Ø± / ØµØ§Ø­Ø¨ Ú©Ø³Ø¨â€ŒÙˆÚ©Ø§Ø±"
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“Œ SECTION 1: Persona (AI Personality)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    TONE_CHOICES = [
        ('formal', 'ğŸ© Ø±Ø³Ù…ÛŒ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ'),
        ('friendly', 'ğŸ˜Š Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ùˆ ØµÙ…ÛŒÙ…ÛŒ'),
        ('energetic', 'âš¡ Ù¾Ø±Ø§Ù†Ø±Ú˜ÛŒ Ùˆ Ù‡ÛŒØ¬Ø§Ù†â€ŒØ§Ù†Ú¯ÛŒØ²'),
        ('empathetic', 'ğŸ¤ Ù‡Ù…Ø¯Ù„Ø§Ù†Ù‡ Ùˆ Ø­Ù…Ø§ÛŒØªÚ¯Ø±'),
    ]
    tone = models.CharField(
        max_length=20,
        choices=TONE_CHOICES,
        default='friendly',
        verbose_name="Ù„Ø­Ù† ØµØ­Ø¨Øª",
        help_text="ØªØ¹ÛŒÛŒÙ† Ú©Ù†ÛŒØ¯ AI Ø¨Ø§ Ú†Ù‡ Ù„Ø­Ù†ÛŒ Ø¨Ø§ Ù…Ø´ØªØ±ÛŒâ€ŒÙ‡Ø§ ØµØ­Ø¨Øª Ú©Ù†Ø¯"
    )
    
    EMOJI_CHOICES = [
        ('none', 'â›” Ù‡ÛŒÚ† - Ø¨Ø¯ÙˆÙ† Ø§ÛŒÙ…ÙˆØ¬ÛŒ'),
        ('moderate', 'ğŸ™‚ Ù…ØªØ¹Ø§Ø¯Ù„ - Ú©Ù…ÛŒ Ø§ÛŒÙ…ÙˆØ¬ÛŒ'),
        ('high', 'ğŸ˜ Ø²ÛŒØ§Ø¯ - Ù¾Ø± Ø§Ø² Ø§ÛŒÙ…ÙˆØ¬ÛŒ'),
    ]
    emoji_usage = models.CharField(
        max_length=20,
        choices=EMOJI_CHOICES,
        default='moderate',
        verbose_name="Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÛŒÙ…ÙˆØ¬ÛŒ",
        help_text="Ù…ÛŒØ²Ø§Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ø¯Ø± Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§"
    )
    
    LENGTH_CHOICES = [
        ('short', 'ğŸ”¹ Ú©ÙˆØªØ§Ù‡ - 1-2 Ø¬Ù…Ù„Ù‡'),
        ('balanced', 'ğŸ”¸ Ù…ØªØ¹Ø§Ø¯Ù„ - 3-4 Ø¬Ù…Ù„Ù‡'),
        ('detailed', 'ğŸ”¶ ØªÙØµÛŒÙ„ÛŒ - 5-7 Ø¬Ù…Ù„Ù‡'),
    ]
    response_length = models.CharField(
        max_length=20,
        choices=LENGTH_CHOICES,
        default='balanced',
        verbose_name="Ø·ÙˆÙ„ Ù¾Ø§Ø³Ø®",
        help_text="ØªØ¹ÛŒÛŒÙ† Ú©Ù†ÛŒØ¯ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ Ú†Ù‚Ø¯Ø± Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø¨Ø§Ø´Ù†Ø¯"
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“Œ SECTION 2: Behavioral Controls
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    use_customer_name = models.BooleanField(
        default=True,
        verbose_name="Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù†Ø§Ù… Ù…Ø´ØªØ±ÛŒ",
        help_text="Ø§Ú¯Ø± ÙØ¹Ø§Ù„ Ø¨Ø§Ø´Ø¯ØŒ AI Ù†Ø§Ù… Ù…Ø´ØªØ±ÛŒ Ø±Ø§ Ø¯Ø± Ø³Ù„Ø§Ù… ØµØ¯Ø§ Ù…ÛŒâ€ŒØ²Ù†Ø¯"
    )
    
    use_bio_context = models.BooleanField(
        default=True,
        verbose_name="Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒÙˆ",
        help_text="Ø§Ú¯Ø± ÙØ¹Ø§Ù„ Ø¨Ø§Ø´Ø¯ØŒ AI Ø§Ø² Ø¨ÛŒÙˆ Ù…Ø´ØªØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ø®ØµÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯"
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“Œ SECTION 3: Persuasive Selling
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    persuasive_selling_enabled = models.BooleanField(
        default=False,
        verbose_name="ÙØ±ÙˆØ´ ÙØ¹Ø§Ù„",
        help_text="Ø§Ú¯Ø± ÙØ¹Ø§Ù„ Ø¨Ø§Ø´Ø¯ØŒ AI Ø¨Ù‡ ØµÙˆØ±Øª ÙØ¹Ø§Ù„ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø±Ø§ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯"
    )
    
    persuasive_cta_text = models.CharField(
        max_length=300,
        blank=True,
        default="Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø§ÛŒÙ† Ù…Ø­ØµÙˆÙ„ Ø±Ø§ Ø³ÙØ§Ø±Ø´ Ø¯Ù‡ÛŒØ¯ØŸ ğŸ›’",
        verbose_name="Ù…ØªÙ† Ø¯Ø¹ÙˆØª Ø¨Ù‡ Ø§Ù‚Ø¯Ø§Ù… (CTA)",
        help_text="Ù…ØªÙ†ÛŒ Ú©Ù‡ AI Ø¨Ù‡ ØµÙˆØ±Øª Ø·Ø¨ÛŒØ¹ÛŒ Ø¯Ø± Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ ÙØ±ÙˆØ´ Ù…ÛŒâ€ŒÚ¯Ù†Ø¬Ø§Ù†Ø¯ (Ø­Ø¯Ø§Ú©Ø«Ø± 300 Ú©Ø§Ø±Ø§Ú©ØªØ±)"
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“Œ SECTION 4: Response Rules
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    unknown_fallback_text = models.CharField(
        max_length=500,
        default="Ù…Ù† Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù¾Ø§Ø³Ø® Ø¯Ù‚ÛŒÙ‚ Ø§ÛŒÙ† Ø³ÙˆØ§Ù„ Ø±Ø§ Ù†Ø¯Ø§Ø±Ù…ØŒ Ø§Ù…Ø§ Ù‡Ù…Ú©Ø§Ø±Ø§Ù†Ù… Ø¨Ù‡ Ø²ÙˆØ¯ÛŒ Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ Ø±Ø§ Ø®ÙˆØ§Ù‡Ù†Ø¯ Ø¯Ø§Ø¯.",
        verbose_name="Ù¾Ø§Ø³Ø® Ø¹Ø¯Ù… Ø§Ø·Ù„Ø§Ø¹",
        help_text="Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ø§ÛŒÙ† Ù…ØªÙ† Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù† ÙˆÙ‚ØªÛŒ Ø¬ÙˆØ§Ø¨ Ø³ÙˆØ§Ù„ Ø±Ø§ Ù†Ù…ÛŒâ€ŒØ¯Ø§Ù†ÛŒ (Ø­Ø¯Ø§Ú©Ø«Ø± 500 Ú©Ø§Ø±Ø§Ú©ØªØ±)"
    )
    
    custom_instructions = models.TextField(
        max_length=1000,
        blank=True,
        null=True,
        verbose_name="Ø¯Ø³ØªÙˆØ±Ø§Øª Ø§Ø¶Ø§ÙÛŒ",
        help_text="Ù‚ÙˆØ§Ù†ÛŒÙ† Ø§Ø¶Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ AI Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ (Ø§Ø®ØªÛŒØ§Ø±ÛŒØŒ Ø­Ø¯Ø§Ú©Ø«Ø± 1000 Ú©Ø§Ø±Ø§Ú©ØªØ±)"
    )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“Œ Metadata
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = "ğŸ­ AI Behavior Settings"
        verbose_name_plural = "ğŸ­ AI Behavior Settings"
        db_table = "settings_ai_behavior"
    
    def __str__(self):
        return f"AI Behavior for {self.user.username}"
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ“Œ Core Methods
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def get_prompt_additions(self) -> str:
        """
        Generate structured flags for AI behavior interpretation.
        
        Uses flag-based approach (not descriptive text) for:
        - Lower token consumption (~30 tokens vs 150-200)
        - Centralized behavior mapping in Mother Prompt
        - Easier A/B testing and modifications
        - Consistent with modern LLM structured outputs
        
        Mother Prompt should contain interpretation rules like:
        [TONE=friendly] â†’ Use friendly, casual language
        [EMOJI=moderate] â†’ Use 1-2 emojis per message
        [LENGTH=short] â†’ Keep responses to 1-2 sentences
        
        Returns:
            str: Space-separated flags for injection into prompt
        """
        flags = []
        
        # Core personality flags (always in English for consistency)
        flags.append(f"[TONE={self.tone}]")
        flags.append(f"[EMOJI={self.emoji_usage}]")
        flags.append(f"[LENGTH={self.response_length}]")
        flags.append(f"[USE_NAME={'yes' if self.use_customer_name else 'no'}]")
        flags.append(f"[USE_BIO={'yes' if self.use_bio_context else 'no'}]")
        flags.append(f"[PERSUASIVE={'on' if self.persuasive_selling_enabled else 'off'}]")
        
        # Fallback text for when AI doesn't know the answer (CRITICAL!)
        if self.unknown_fallback_text and self.unknown_fallback_text.strip():
            fallback_clean = self.unknown_fallback_text.strip().replace('\n', ' ')[:200]
            flags.append(f"[FALLBACK_TEXT={fallback_clean}]")
        
        # CTA text (can be Persian - it's content, not instruction)
        if self.persuasive_selling_enabled and self.persuasive_cta_text.strip():
            cta_clean = self.persuasive_cta_text.strip().replace('\n', ' ')[:250]
            flags.append(f"[CTA={cta_clean}]")
        
        # Custom instructions (should be in English for consistency)
        if self.custom_instructions and self.custom_instructions.strip():
            custom_clean = self.custom_instructions.strip().replace('\n', ' ')[:500]
            flags.append(f"[CUSTOM={custom_clean}]")
        
        return " ".join(flags)
    
    def get_max_output_tokens(self) -> int:
        """
        Calculate max output tokens based on response_length preference.
        
        Token allocation aligned with actual response needs:
        - short: 400 tokens (~250-300 Persian words, 1-2 short paragraphs)
        - balanced: 700 tokens (~450-500 words, 2-3 paragraphs) [DEFAULT]
        - detailed: 1200 tokens (~800-900 words, 3-5 detailed paragraphs)
        
        These limits ensure:
        1. AI has enough tokens to complete thought
        2. Responses stay within user preference
        3. Total budget (input + output) stays safe:
           - Max input: 2200 tokens (TokenBudgetController)
           - Max output: 1200 tokens (this method)
           - Total: 3400 tokens << Gemini context window (1M tokens) âœ…
        
        Returns:
            int: Maximum output tokens for this user's preference
        """
        token_limits = {
            'short': 400,      # Short but complete (1-2 paragraphs)
            'balanced': 700,   # Balanced explanation (2-3 paragraphs)
            'detailed': 1200,  # Detailed response (3-5 paragraphs)
        }
        return token_limits.get(self.response_length, 700)
    
    def get_fallback_text(self) -> str:
        """
        Get exact text to return when AI lacks information.
        
        This is NOT a prompt instruction - it's the actual message text
        that will be sent to the customer. Detection logic stays centralized,
        only the output text is per-user customizable.
        
        Returns:
            str: Exact customer-facing message (Persian or any language)
        """
        return self.unknown_fallback_text.strip()
    
    def should_use_bio_context(self) -> bool:
        """Check if bio context should be injected into prompt"""
        return self.use_bio_context
    
    def should_use_customer_name(self) -> bool:
        """Check if customer name should be used in greeting"""
        return self.use_customer_name


class Settings(SingletonModel):
    IR_yearly = models.IntegerField(default=0)
    IR_monthly = models.IntegerField(default=0)
    TR_yearly = models.IntegerField(default=0)
    TR_monthly = models.IntegerField(default=0)
    EN_yearly = models.IntegerField(default=0)
    EN_monthly = models.IntegerField(default=0)
    token1M = models.IntegerField(default=0)
    token3M = models.IntegerField(default=0)
    token5M = models.IntegerField(default=0)
    token10M = models.IntegerField(default=0)
    email1K = models.IntegerField(default=0)
    email3K = models.IntegerField(default=0)
    email5K = models.IntegerField(default=0)
    email10K = models.IntegerField(default=0)

    class Meta:
        verbose_name = "ğŸ’° System Settings"
        verbose_name_plural = "ğŸ’° System Settings"

    def __str__(self):
        return str(self.IR_yearly) + " | " + str(self.IR_monthly) + " | " + str(self.EN_yearly) + " | " + str(self.EN_monthly)

class BusinessPrompt(models.Model):
    name = models.CharField(max_length=200, help_text="Name of the business prompt")
    prompt = models.TextField(help_text="The business prompt content")
    ai_answer_prompt = models.TextField(null=True, blank=True, help_text="AI answer prompt for responses")
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = "ğŸ’¼ Business Prompt"
        verbose_name_plural = "ğŸ’¼ Business Prompts"
        ordering = ['-updated_at']
    
    def __str__(self):
        return self.name


class BusinessPromptData(models.Model):
    """
    Model to store custom key-value data (with optional file) for BusinessPrompts.
    Admin can assign custom data fields to any BusinessPrompt.
    Supports both text values and file attachments.
    """
    business = models.ForeignKey(
        BusinessPrompt,
        on_delete=models.CASCADE,
        related_name='prompt_data',
        help_text="The BusinessPrompt this data belongs to"
    )
    key = models.CharField(
        max_length=255,
        help_text="Name of the data field (e.g., 'logo', 'document', 'config')"
    )
    value = models.TextField(
        blank=True,
        default='',
        help_text="Text value of the data field (optional if file is provided)"
    )
    file = models.FileField(
        upload_to='business_prompt_data/%Y/%m/%d/',
        null=True,
        blank=True,
        help_text="File attachment for this data field (e.g., logo, document, PDF)"
    )
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        verbose_name = "ğŸ“ Business Prompt Data"
        verbose_name_plural = "ğŸ“ Business Prompt Data"
        unique_together = ['business', 'key']  # Each key must be unique per BusinessPrompt
        ordering = ['-created_at']

    def __str__(self):
        value_preview = self.value[:50] if self.value else '[File Only]'
        return f"{self.business.name} | {self.key}: {value_preview}"
    
    @property
    def file_url(self):
        """Return the file URL if file exists"""
        if self.file:
            return self.file.url
        return None
    
    @property
    def file_name(self):
        """Return the file name if file exists"""
        if self.file:
            return self.file.name.split('/')[-1]
        return None


class UpToPro(models.Model):
    rate = models.IntegerField(help_text="Rating value")
    signedup = models.IntegerField(help_text="Number of signups")
    comment = models.TextField(help_text="User comment")
    name = models.CharField(max_length=200, help_text="User name")
    profileimage = models.ImageField(upload_to='uptopro_profiles/', null=True, blank=True, help_text="Profile image")
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = "â­ UpToPro"
        verbose_name_plural = "â­ UpToPros"
        ordering = ['-created_at']
    
    def __str__(self):
        return f"{self.name} - Rating: {self.rate}"


class AffiliationConfig(SingletonModel):
    """
    Affiliate/Referral System Configuration
    
    This model stores the commission percentage for the affiliate reward system.
    Only one instance can exist (singleton pattern).
    
    When a referred user makes a payment, X% commission is automatically
    added to the referring user's wallet balance - but only within the
    validity period after registration.
    """
    percentage = models.DecimalField(
        max_digits=5,
        decimal_places=2,
        default=10.00,
        verbose_name="Commission Percentage (%)",
        help_text="Percentage of payment to give as commission to referring user (e.g., 10 = 10%)"
    )
    commission_validity_days = models.PositiveIntegerField(
        default=30,
        verbose_name="Commission Validity (Days)",
        help_text="Number of days after registration during which payments qualify for commission (0 = unlimited)"
    )
    is_active = models.BooleanField(
        default=True,
        verbose_name="Affiliate System Active",
        help_text="Enable or disable the entire affiliate reward system"
    )
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = "ğŸ¤ Affiliation Configuration"
        verbose_name_plural = "ğŸ¤ Affiliation Configuration"
    
    def __str__(self):
        status = "Active" if self.is_active else "Inactive"
        return f"Affiliate System: {self.percentage}% ({status})"
    
    @classmethod
    def get_config(cls):
        """Get or create the affiliation config instance"""
        config, created = cls.objects.get_or_create(pk=1)
        return config
    
    def calculate_commission(self, amount):
        """Calculate commission amount from payment"""
        from decimal import Decimal
        # Ensure both amount and percentage are Decimal for proper calculation
        amount_decimal = Decimal(str(amount))
        percentage_decimal = Decimal(str(self.percentage))
        commission = (amount_decimal * percentage_decimal / Decimal('100')).quantize(Decimal('0.01'))
        return commission
    
    def is_within_validity_period(self, user_registration_date, payment_date=None):
        """
        Check if a payment is within the commission validity period.
        
        Args:
            user_registration_date: The date when the referred user registered
            payment_date: The date of the payment (defaults to now if not provided)
            
        Returns:
            bool: True if payment qualifies for commission, False otherwise
        """
        from django.utils import timezone
        from datetime import timedelta
        
        # If validity is 0, commission applies forever (unlimited)
        if self.commission_validity_days == 0:
            return True
        
        if payment_date is None:
            payment_date = timezone.now()
        
        # Make both dates timezone-aware for comparison
        if timezone.is_naive(user_registration_date):
            user_registration_date = timezone.make_aware(user_registration_date)
        if timezone.is_naive(payment_date):
            payment_date = timezone.make_aware(payment_date)
        
        # Calculate the validity deadline
        validity_deadline = user_registration_date + timedelta(days=self.commission_validity_days)
        
        return payment_date <= validity_deadline
    
    def get_validity_display(self):
        """Human-readable validity period"""
        if self.commission_validity_days == 0:
            return "Unlimited (forever)"
        elif self.commission_validity_days == 1:
            return "1 day after registration"
        else:
            return f"{self.commission_validity_days} days after registration"