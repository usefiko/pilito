from django.db import models
from django.core.exceptions import ValidationError
from accounts.models import User


class TelegramChannel(models.Model):
    is_connect = models.BooleanField(default=False)
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    bot_token = models.CharField(max_length=200,unique=True)
    bot_username = models.CharField(max_length=100,unique=True)
    profile_picture = models.ImageField(upload_to='telegram_bot_pictures/', null=True, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = "üì± Telegram Channel"
        verbose_name_plural = "üì± Telegram Channels"
    
    def __str__(self):
        return str(self.bot_username)


class InstagramChannel(models.Model):
    is_connect = models.BooleanField(default=False)
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    username = models.CharField(max_length=100, unique=True)
    access_token = models.TextField(null=True, blank=True)  # Store Instagram access token
    token_expires_at = models.DateTimeField(null=True, blank=True)  # Track token expiration
    instagram_user_id = models.CharField(max_length=100, null=True, blank=True)  # Instagram user ID
    page_id = models.CharField(max_length=100, null=True, blank=True)  # Instagram page/business ID for webhooks
    account_type = models.CharField(max_length=50, null=True, blank=True)  # business/personal
    followers_count = models.IntegerField(null=True, blank=True)
    following_count = models.IntegerField(null=True, blank=True)
    media_count = models.IntegerField(null=True, blank=True)
    profile_picture_url = models.CharField(max_length=5000,null=True, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = "üì∑ Instagram Channel"
        verbose_name_plural = "üì∑ Instagram Channels"
    
    def __str__(self):
        return str(self.username)


class AIPrompts(models.Model):
    user = models.OneToOneField(User, on_delete=models.CASCADE, related_name='ai_prompts')
    manual_prompt = models.TextField(max_length=90000000, null=True, blank=True)
    knowledge_source = models.JSONField(null=True, blank=True)
    product_service = models.JSONField(null=True, blank=True)
    question_answer = models.JSONField(null=True, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = "ü§ñ AI Prompt"
        verbose_name_plural = "ü§ñ AI Prompts"
    
    def __str__(self):
        return f"AI Prompts for {self.user.username}"
    
    @classmethod
    def get_or_create_for_user(cls, user):
        """Get or create AIPrompts for a user with default prompts"""
        prompts, created = cls.objects.get_or_create(
            user=user,
            defaults={
                'manual_prompt': '',  # Empty by default - user must fill this
            }
        )
        return prompts, created
    
    def validate_for_ai_response(self):
        """
        Validate that AIPrompts are ready for AI response generation
        Raises ValueError if manual_prompt is empty
        """
        if not self.manual_prompt or not self.manual_prompt.strip():
            raise ValueError(
                "Manual prompt is required for AI responses. "
                "Please configure your AI prompt in settings before using AI features."
            )
        return True
    
    def get_combined_prompt(self):
        """
        Get combined prompt for AI response generation
        Returns system_prompt + manual_prompt (system first for priority!)
        
        ‚ö†Ô∏è IMPORTANT: System prompt MUST be first because:
        - Contains core behavior rules (language, tone, length)
        - Gets trimmed to tokens, so first prompts have priority
        - Manual prompt is secondary context (business info)
        
        Now uses modular get_combined_system_prompt() for better management!
        """
        self.validate_for_ai_response()  # Ensure manual_prompt is not empty
        
        combined = ""
        
        # ‚úÖ 1. SYSTEM PROMPT FIRST (highest priority - behavior rules)
        # Now using modular approach from GeneralSettings
        try:
            general_settings = GeneralSettings.get_settings()
            system_prompt = general_settings.get_combined_system_prompt()
            if system_prompt and system_prompt.strip():
                combined += system_prompt.strip()
        except Exception as e:
            # If GeneralSettings is not available, continue without system_prompt
            pass
        
        # ‚úÖ 2. MANUAL PROMPT SECOND (business context)
        if self.manual_prompt and self.manual_prompt.strip():
            if combined:
                combined += "\n\n"
            combined += self.manual_prompt.strip()
        
        return combined


class IntercomTicketType(models.Model):
    """
    Intercom Ticket Type Configuration
    Maps Fiko departments to Intercom ticket types
    """
    DEPARTMENT_CHOICES = [
        ('technical_support', 'Technical Support'),
        ('billing_support', 'Billing Support'),
        ('general_inquiry', 'General Inquiry'),
        ('account_support', 'Account Support'),
    ]
    
    name = models.CharField(
        max_length=100,
        help_text="Ticket type name (e.g., 'Technical Support', 'Billing Issue')"
    )
    department = models.CharField(
        max_length=20,
        choices=DEPARTMENT_CHOICES,
        unique=True,
        help_text="Department to map this ticket type to"
    )
    intercom_ticket_type_id = models.CharField(
        max_length=50,
        help_text="Intercom Ticket Type ID from Intercom settings (e.g., '2918773')"
    )
    is_active = models.BooleanField(
        default=True,
        help_text="Whether this ticket type is active"
    )
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        ordering = ['department']
        verbose_name = "üé´ Intercom Ticket Type"
        verbose_name_plural = "üé´ Intercom Ticket Types"
    
    def __str__(self):
        return f"{self.name} ({self.get_department_display()}) ‚Üí ID: {self.intercom_ticket_type_id}"


class SupportTicket(models.Model):
    STATUS_CHOICES = [
        ('open', 'Open'),
        ('under_review', 'Under Review'),
        ('support_response', 'Support Response'),
        ('customer_reply', 'Customer Reply'),
        ('closed', 'Closed'),
    ]
    
    DEPARTMENT_CHOICES = IntercomTicketType.DEPARTMENT_CHOICES
    
    title = models.CharField(max_length=200)
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    department = models.CharField(max_length=20, choices=DEPARTMENT_CHOICES, default='general_inquiry')
    status = models.CharField(max_length=20, choices=STATUS_CHOICES, default='open')
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    # Intercom integration
    intercom_conversation_id = models.CharField(
        max_length=255, 
        blank=True, 
        null=True, 
        unique=True,
        help_text='[DEPRECATED] Old Conversations API ID - kept for backward compatibility'
    )
    
    intercom_ticket_id = models.CharField(
        max_length=255,
        blank=True,
        null=True,
        unique=True,
        help_text='Intercom Ticket ID from Tickets API for two-way sync'
    )
    
    class Meta:
        ordering = ['-updated_at']
        verbose_name = "üé´ Support Ticket"
        verbose_name_plural = "üé´ Support Tickets"
    
    def __str__(self):
        return f"#{self.id:03d} - {self.title}"
    
    @property
    def intercom_id(self):
        """Returns ticket_id if exists, else conversation_id (backward compatibility)"""
        return self.intercom_ticket_id or self.intercom_conversation_id


class SupportMessage(models.Model):
    ticket = models.ForeignKey(SupportTicket, on_delete=models.CASCADE, related_name='messages')
    content = models.TextField()
    is_from_support = models.BooleanField(default=False)
    sender = models.ForeignKey(User, on_delete=models.CASCADE, null=True, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        ordering = ['-created_at']  # ÿ¨ÿØ€åÿØÿ™ÿ±€åŸÜ Ÿæ€åÿßŸÖ‚ÄåŸáÿß ÿßŸàŸÑ
        verbose_name = "üí¨ Support Message"
        verbose_name_plural = "üí¨ Support Messages"
    
    def __str__(self):
        sender_type = "Support" if self.is_from_support else "Customer"
        return f"{sender_type} message in ticket #{self.ticket.id:03d}"


class SupportMessageAttachment(models.Model):
    message = models.ForeignKey(SupportMessage, on_delete=models.CASCADE, related_name='attachments')
    file = models.FileField(upload_to='support_attachments/')
    original_filename = models.CharField(max_length=255)
    file_size = models.PositiveIntegerField()  # Size in bytes
    file_type = models.CharField(max_length=100)  # MIME type
    uploaded_at = models.DateTimeField(auto_now_add=True)
    
    class Meta:
        ordering = ['uploaded_at']
        verbose_name = "üìé Support Message Attachment"
        verbose_name_plural = "üìé Support Message Attachments"
    
    def __str__(self):
        return f"Attachment: {self.original_filename} for message #{self.message.id}"
    
    def save(self, *args, **kwargs):
        if self.file:
            self.file_size = self.file.size
            self.original_filename = self.file.name.split('/')[-1]
            # Get file MIME type
            import mimetypes
            self.file_type = mimetypes.guess_type(self.file.name)[0] or 'application/octet-stream'
        super().save(*args, **kwargs)


# Not complete V

class SingletonModel(models.Model):
    class Meta:
        abstract = True
    def save(self, *args, **kwargs):
        if not self.pk and self.__class__.objects.exists():
            raise ValidationError('There can be only one instance of this model.')
        return super(SingletonModel, self).save(*args, **kwargs)



class GeneralSettings(SingletonModel):
    """
    General AI Settings - Modular Prompt Management (Standard Approach)
    Similar to: OpenAI ChatGPT, Intercom Fin, Zendesk AI
    
    This model uses a modular approach to manage AI prompts, allowing
    each aspect of AI behavior to be configured separately for better
    maintainability and clarity.
    """
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìå SECTION 1: Core Identity & Behavior
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    ai_role = models.TextField(
        max_length=500,
        default="""You are a sales assistant, NOT a support agent.
Your goal is to understand customer needs and recommend relevant products/services.
Always look for opportunities to suggest products that match their needs.
Be helpful, friendly, and proactive in offering solutions.""",
        verbose_name="ü§ñ AI Role & Identity",
        help_text=(
            "ÿ™ÿπÿ±€åŸÅ ⁄©ŸÜ€åÿØ ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å ⁄ÜŸá ⁄©ÿ≥€å ÿßÿ≥ÿ™ (ŸÖÿ´ŸÑÿßŸã '€å⁄© ÿØÿ≥ÿ™€åÿßÿ± ŸÅÿ±Ÿàÿ¥ ÿØŸàÿ≥ÿ™ÿßŸÜŸá' €åÿß '€å⁄© ŸÖÿ¥ÿßŸàÿ± ŸÅŸÜ€å')\n"
            "ÿß€åŸÜ ÿ®ÿÆÿ¥ ŸáŸà€åÿ™ ÿßÿµŸÑ€å AI ÿ±ÿß ŸÖÿ¥ÿÆÿµ ŸÖ€å‚Äå⁄©ŸÜÿØ."
        )
    )
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìå SECTION 2: Language & Communication Style
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    language_rules = models.TextField(
        max_length=1000,
        default="""Always reply in Persian (Farsi).
Convert Latin names to Persian equivalents (e.g., Omid ‚Üí ÿßŸÖ€åÿØ).
Use everyday Persian expressions, not formal sentences.""",
        verbose_name="üåê Language & Localization",
        help_text=(
            "ŸÇŸàÿßŸÜ€åŸÜ ÿ≤ÿ®ÿßŸÜ€å Ÿà ŸÖÿ≠ŸÑ€å‚Äåÿ≥ÿßÿ≤€å ÿ±ÿß ÿ™ÿπÿ±€åŸÅ ⁄©ŸÜ€åÿØ.\n"
            "ŸÖÿ´ÿßŸÑ: 'ŸáŸÖ€åÿ¥Ÿá ÿ®Ÿá ŸÅÿßÿ±ÿ≥€å Ÿæÿßÿ≥ÿÆ ÿ®ÿØŸá'ÿå 'ŸÜÿßŸÖ‚ÄåŸáÿß€å ŸÑÿßÿ™€åŸÜ ÿ±ÿß ÿ®Ÿá ŸÅÿßÿ±ÿ≥€å ÿ™ÿ®ÿØ€åŸÑ ⁄©ŸÜ'\n"
            "ÿß€åŸÜ ŸÇÿ≥ŸÖÿ™ ÿ™ÿπ€å€åŸÜ ŸÖ€å‚Äå⁄©ŸÜÿØ AI ⁄ÜŸá ÿ≤ÿ®ÿßŸÜ€å Ÿà ÿ®ÿß ⁄ÜŸá ÿ≥ÿ®⁄©€å ÿµÿ≠ÿ®ÿ™ ⁄©ŸÜÿØ."
        )
    )
    
    tone_and_style = models.TextField(
        max_length=1000,
        default="""Speak casually and emotionally, not like a brochure.
Write like a person chatting on Instagram.
Keep responses under 2 short lines.""",
        verbose_name="üí¨ Tone & Style (ŸÑÿ≠ŸÜ Ÿà ÿ≥ÿ®⁄©)",
        help_text=(
            "ŸÑÿ≠ŸÜ Ÿà ÿ≥ÿ®⁄© ŸÖ⁄©ÿßŸÑŸÖŸá AI ÿ±ÿß ÿ™ÿπ€å€åŸÜ ⁄©ŸÜ€åÿØ.\n"
            "ŸÖÿ´ÿßŸÑ: 'ÿµŸÖ€åŸÖ€å Ÿà ÿßÿ≠ÿ≥ÿßÿ≥€å ÿµÿ≠ÿ®ÿ™ ⁄©ŸÜ'ÿå 'ŸÖÿ´ŸÑ €å⁄© ŸÅÿ±ÿØ ŸàÿßŸÇÿπ€å ÿØÿ± ÿß€åŸÜÿ≥ÿ™ÿß⁄Øÿ±ÿßŸÖ ÿ®ŸÜŸà€åÿ≥'\n"
            "ÿß€åŸÜ ÿ®ÿÆÿ¥ ÿ¥ÿÆÿµ€åÿ™ AI ÿ±ÿß ÿ¥⁄©ŸÑ ŸÖ€å‚ÄåÿØŸáÿØ."
        )
    )
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìå SECTION 3: Response Guidelines
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    response_length = models.CharField(
        max_length=20,
        choices=[
            ('concise', 'üîπ Concise (1-2 ÿ¨ŸÖŸÑŸá ⁄©Ÿàÿ™ÿßŸá)'),
            ('moderate', 'üî∏ Moderate (2-4 ÿ¨ŸÖŸÑŸá ŸÖÿ™Ÿàÿ≥ÿ∑)'),
            ('detailed', 'üî∂ Detailed (4+ ÿ¨ŸÖŸÑŸá ÿ™ŸÅÿµ€åŸÑ€å)'),
        ],
        default='concise',
        verbose_name="üìè Response Length (ÿ∑ŸàŸÑ Ÿæÿßÿ≥ÿÆ)",
        help_text=(
            "ÿ™ÿπ€å€åŸÜ ⁄©ŸÜ€åÿØ Ÿæÿßÿ≥ÿÆ‚ÄåŸáÿß€å AI ⁄ÜŸÇÿØÿ± ÿ∑ŸàŸÑÿßŸÜ€å ÿ®ÿßÿ¥ŸÜÿØ.\n"
            "⁄©Ÿàÿ™ÿßŸá: ÿ®ÿ±ÿß€å Ÿæ€åÿßŸÖ‚ÄåŸáÿß€å ÿ≥ÿ±€åÿπ (ŸÖÿ´ŸÑ ÿß€åŸÜÿ≥ÿ™ÿß⁄Øÿ±ÿßŸÖ)\n"
            "ŸÖÿ™Ÿàÿ≥ÿ∑: ÿ®ÿ±ÿß€å ÿ™Ÿàÿ∂€åÿ≠ÿßÿ™ ⁄©ŸÑ€å\n"
            "ÿ™ŸÅÿµ€åŸÑ€å: ÿ®ÿ±ÿß€å Ÿæÿßÿ≥ÿÆ‚ÄåŸáÿß€å ⁄©ÿßŸÖŸÑ Ÿà ÿ¨ÿßŸÖÿπ"
        )
    )
    
    response_guidelines = models.TextField(
        max_length=1000,
        default="""Maximum 600 characters for Instagram compatibility.
Maximum 3-4 sentences per response.
Limit emojis to 1 per message.
Avoid long introductions ‚Äî go straight to the point.
If topic is complex, give a short summary. User can ask for details.

üéØ PERSONALIZATION WITH BIO:
- If customer has a bio, USE IT in your first response
- Mention their work/interest naturally to show you understand them
- Example: "ÿØ€åÿØŸÖ ÿßÿ≥ÿ™ÿ±ÿßÿ™⁄ò€åÿ≥ÿ™ ÿ®ÿ±ŸÜÿØ€åŸÜ⁄Ø Ÿáÿ≥ÿ™€åÿå ŸÅ€å⁄©Ÿà ÿ®ÿ±ÿßÿ™ ÿπÿßŸÑ€åŸá!"
- Convert Latin names to Persian (Omid ‚Üí ÿßŸÖ€åÿØ)

üì∑üé§ MEDIA MESSAGE RULE:
- If you see '[sent an image]:', the customer SENT an image (not described it)
- If you see '[sent a voice message]:', the customer SENT audio (not typed it)
- The text after is AI analysis of their media
- Respond naturally about what they sent, don't say 'you described'""",
        verbose_name="üìù Response Guidelines (ÿ±ÿßŸáŸÜŸÖÿß€å Ÿæÿßÿ≥ÿÆ‚ÄåÿØŸá€å)",
        help_text=(
            "ŸÇŸàÿßŸÜ€åŸÜ ÿßÿ∂ÿßŸÅ€å ÿ®ÿ±ÿß€å ŸÅÿ±ŸÖÿ™ Ÿà ÿ≥ÿßÿÆÿ™ÿßÿ± Ÿæÿßÿ≥ÿÆ‚ÄåŸáÿß.\n"
            "ÿ¥ÿßŸÖŸÑ: ÿ∑ŸàŸÑ Ÿæÿßÿ≥ÿÆ (600 ⁄©ÿßÿ±ÿß⁄©ÿ™ÿ± ÿ®ÿ±ÿß€å ÿß€åŸÜÿ≥ÿ™ÿß⁄Øÿ±ÿßŸÖ)ÿå emoji limitÿå media rules\n"
            "ÿß€åŸÜ ÿ®ÿÆÿ¥ ÿ¨ÿ≤ÿ¶€åÿßÿ™ ŸÅÿ±ŸÖÿ™ Ÿæÿßÿ≥ÿÆ ÿ±ÿß ⁄©ŸÜÿ™ÿ±ŸÑ ŸÖ€å‚Äå⁄©ŸÜÿØ."
        )
    )
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìå SECTION 4: Greeting & Name Usage
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    greeting_rules = models.TextField(
        max_length=1000,
        default="""‚õî CRITICAL RULE: Say 'ÿ≥ŸÑÿßŸÖ' or 'Hi' ONLY ONCE per conversation!

When you see "SCENARIO: FIRST_MESSAGE":
‚Üí Greet with customer's name ONCE: "ÿ≥ŸÑÿßŸÖ [ŸÜÿßŸÖ]!"
‚Üí Then answer their question naturally

When you see "SCENARIO: WELCOME_BACK":
‚Üí Say "ÿÆŸàÿ¥ ÿ®ÿ±⁄Øÿ¥ÿ™€å!" ONCE (do NOT say ÿ≥ŸÑÿßŸÖ)
‚Üí Then answer directly

When you see "SCENARIO: RECENT_CONVERSATION":
‚Üí Do NOT greet at all
‚Üí Answer the question DIRECTLY without any greeting word
‚Üí Example: "ÿ®ŸÑŸáÿå ŸÖ€å‚Äåÿ™ŸàŸÜŸÖ ⁄©ŸÖ⁄© ⁄©ŸÜŸÖ..."

‚õî NEVER say "ÿØŸàÿ®ÿßÿ±Ÿá ÿ≥ŸÑÿßŸÖ" or repeat any greeting!""",
        verbose_name="üëã Greeting & Name Usage (ÿßÿ≠ŸàÿßŸÑŸæÿ±ÿ≥€å Ÿà ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ŸÜÿßŸÖ)",
        help_text=(
            "ŸÇŸàÿßŸÜ€åŸÜ ÿ®ÿ±ÿß€å ÿßÿ≠ŸàÿßŸÑŸæÿ±ÿ≥€å Ÿà ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ŸÜÿßŸÖ ŸÖÿ¥ÿ™ÿ±€å.\n"
            "ÿ¥ÿßŸÖŸÑ: first message greeting, welcome back (12+ hours), no repeat greeting\n"
            "ÿ¨ŸÑŸà⁄Ø€åÿ±€å ÿßÿ≤ ÿ™⁄©ÿ±ÿßÿ± ÿ®€åÿ¥ ÿßÿ≤ ÿ≠ÿØ ŸÜÿßŸÖ Ÿà ÿßÿ≠ŸàÿßŸÑŸæÿ±ÿ≥€å‚ÄåŸáÿß€å ŸÖÿ≤ÿßÿ≠ŸÖ."
        )
    )
    
    welcome_back_threshold_hours = models.IntegerField(
        default=12,
        verbose_name="‚è∞ Welcome Back Threshold (ÿ≥ÿßÿπÿ™)",
        help_text=(
            "ÿ®ÿπÿØ ÿßÿ≤ ⁄ÜŸÜÿØ ÿ≥ÿßÿπÿ™ÿå AI ÿ®ÿß€åÿØ ÿ®⁄ØŸà€åÿØ 'ÿÆŸàÿ¥ ÿ®ÿ±⁄Øÿ¥ÿ™€å'ÿü\n"
            "Ÿæ€åÿ¥‚ÄåŸÅÿ±ÿ∂: 12 ÿ≥ÿßÿπÿ™\n"
            "ÿß⁄Øÿ± ŸÖÿ¥ÿ™ÿ±€å ÿ®ÿπÿØ ÿßÿ≤ ÿß€åŸÜ ŸÖÿØÿ™ ÿ®ÿ±⁄Øÿ±ÿØÿØÿå AI ŸÖ€å‚Äå⁄ØŸà€åÿØ 'ÿÆŸàÿ¥ ÿ®ÿ±⁄Øÿ¥ÿ™€å!' ÿ®Ÿá ÿ¨ÿß€å 'ÿ≥ŸÑÿßŸÖ'"
        )
    )
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìå SECTION 5: Anti-Hallucination & Accuracy
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    anti_hallucination_rules = models.TextField(
        max_length=1000,
        default="""üö® ŸÇŸàÿßŸÜ€åŸÜ ÿ∂ÿØ ÿ™ŸàŸáŸÖ‚Äåÿ≤ÿß€å€å (Critical):

1) ŸáŸÖ€åÿ¥Ÿá ÿßŸàŸÑ ⁄©ÿßŸÜÿ™⁄©ÿ≥ÿ™ Ÿà ŸÜÿßŸÑÿ¨ ÿ±ÿß ⁄Ü⁄© ⁄©ŸÜ:
   - ÿß⁄Øÿ± chunk/FAQ/ŸÖÿ≠ÿµŸàŸÑ/ÿ≥ÿß€åÿ™ ÿØÿ± ⁄©ÿßŸÜÿ™⁄©ÿ≥ÿ™ Ÿáÿ≥ÿ™ ‚Üí ÿßÿ≤ ŸáŸÖÿßŸÜ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ
   - ÿß⁄Øÿ± ⁄Ü€åÿ≤€å ÿØÿ± ⁄©ÿßŸÜÿ™⁄©ÿ≥ÿ™ ŸÜ€åÿ≥ÿ™ÿå ÿÆŸàÿØÿ™ ÿßÿ∑ŸÑÿßÿπÿßÿ™ ŸÜÿ≥ÿßÿ≤

2) ÿß€åŸÜ‚ÄåŸáÿß ÿ±ÿß Ÿáÿ±⁄Øÿ≤ ÿßÿÆÿ™ÿ±ÿßÿπ ŸÜ⁄©ŸÜ:
   - ÿ¢ÿØÿ±ÿ≥ÿå ÿ¥ŸÖÿßÿ±Ÿá ÿ™ŸÖÿßÿ≥ÿå ŸÇ€åŸÖÿ™ÿå ŸÖŸàÿ¨ŸàÿØ€åÿå ŸÑ€åŸÜ⁄©
   - ÿ¨ÿ≤ÿ¶€åÿßÿ™ ŸÖÿ≠ÿµŸàŸÑ €åÿß ÿÆÿØŸÖÿßÿ™€å ⁄©Ÿá ÿ™Ÿà ⁄©ÿßŸÜÿ™⁄©ÿ≥ÿ™ ŸÜ€åÿ≥ÿ™
   - Ÿá€å⁄Ü‚ÄåŸàŸÇÿ™ ŸÜ⁄ØŸà "ÿßŸÑÿßŸÜ ŸÖ€å‚ÄåŸÅÿ±ÿ≥ÿ™ŸÖ" ÿß⁄Øÿ± ÿßŸÑÿßŸÜ ŸÜÿØÿßÿ±€å

3) ÿß⁄Øÿ± ÿßÿ∑ŸÑÿßÿπÿßÿ™ ŸÜÿØÿßÿ±€å:
   - ÿµÿßÿØŸÇÿßŸÜŸá ÿ®⁄ØŸà: "ÿß€åŸÜ ÿßÿ∑ŸÑÿßÿπÿßÿ™ ÿßŸÑÿßŸÜ ÿ™Ÿà ÿØÿßŸÜÿ¥ ŸÖŸÜ ŸÜ€åÿ≥ÿ™"
   - ÿßÿ≤ ŸÖÿ™ŸÜ knowledge_limitation_response ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ

4) ŸÑ€åŸÜ⁄© Ÿà Ÿàÿ®‚Äåÿ≥ÿß€åÿ™ (ÿÆ€åŸÑ€å ŸÖŸáŸÖ):
   - ÿß⁄Øÿ± ŸÅŸÇÿ∑ €å⁄© ŸÑ€åŸÜ⁄© ŸÖ€å‚Äåÿ®€åŸÜ€å Ÿà ŸÖÿ≠ÿ™Ÿàÿß€å ÿµŸÅÿ≠Ÿá ÿØÿ± ⁄©ÿßŸÜÿ™⁄©ÿ≥ÿ™ ŸÜ€åÿ≥ÿ™ÿå ÿßÿµŸÑÿßŸã ÿ≠ÿØÿ≥ ŸÜÿ≤ŸÜ
   - ÿ®⁄ØŸà: "ŸÖÿ™ÿ£ÿ≥ŸÅÿßŸÜŸá ŸÖŸÜ ŸÜŸÖ€å‚Äåÿ™ŸàŸÜŸÖ ŸÖÿ≠ÿ™Ÿàÿß€å ÿß€åŸÜ ŸÑ€åŸÜ⁄© ÿ±ÿß ÿ®ÿ®€åŸÜŸÖ. ÿß⁄Øÿ± ÿ≥ŸàÿßŸÑ€å ÿ±ÿßÿ¨ÿπ ÿ®Ÿáÿ¥ ÿØÿßÿ±€åÿå ŸÑÿ∑ŸÅÿßŸã ÿ™Ÿàÿ∂€åÿ≠ ÿ®ÿØŸá."
   
   ‚ö†Ô∏è CRITICAL: If user sends ONLY a URL without context:
   - NEVER guess what the link is about
   - Say you can't see the content

5) Ÿæÿ≥ÿ™/ÿ±€åŸÑÿ≤ ÿß€åŸÜÿ≥ÿ™ÿß⁄Øÿ±ÿßŸÖ:
   - ÿ™Ÿà ŸÅŸÇÿ∑ caption/ŸÖÿ™ŸÜ ÿ±ÿß ŸÖ€å‚Äåÿ®€åŸÜ€åÿå ŸÜŸá ÿ™ÿµŸà€åÿ±/Ÿà€åÿØ€åŸà
   - ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ŸáŸÖÿßŸÜ ŸÖÿ™ŸÜ ÿ¨Ÿàÿßÿ® ÿ®ÿØŸáÿå ŸÜŸá ⁄Ü€åÿ≤€å ⁄©Ÿá ÿØÿßÿÆŸÑ ÿ™ÿµŸà€åÿ± ŸÖŸÖ⁄©ŸÜ ÿßÿ≥ÿ™ ÿ®ÿßÿ¥ÿØ""",
        verbose_name="üö® Anti-Hallucination Rules (ŸÇŸàÿßŸÜ€åŸÜ ÿ∂ÿØ ÿ™ŸàŸáŸÖ‚Äåÿ≤ÿß€å€å)",
        help_text=(
            "‚ö†Ô∏è ÿ®ÿ≥€åÿßÿ± ŸÖŸáŸÖ: ŸÇŸàÿßŸÜ€åŸÜ ÿ®ÿ±ÿß€å ÿ¨ŸÑŸà⁄Ø€åÿ±€å ÿßÿ≤ ÿßÿ∑ŸÑÿßÿπÿßÿ™ ŸÜÿßÿØÿ±ÿ≥ÿ™.\n"
            "ŸÖÿ´ÿßŸÑ: 'Ÿáÿ±⁄Øÿ≤ ŸÜ⁄ØŸà \"ÿßŸÑÿßŸÜ ŸÖ€å‚ÄåŸÅÿ±ÿ≥ÿ™ŸÖ\" ÿß⁄Øÿ± ÿßÿ∑ŸÑÿßÿπÿßÿ™ ŸÜÿØÿßÿ±€å'\n"
            "ÿß€åŸÜ ŸÇÿ≥ŸÖÿ™ ÿßÿ≤ ÿØÿ±Ÿàÿ∫ ⁄ØŸÅÿ™ŸÜ AI ÿ¨ŸÑŸà⁄Ø€åÿ±€å ŸÖ€å‚Äå⁄©ŸÜÿØ."
        )
    )
    
    knowledge_limitation_response = models.TextField(
        max_length=500,
        default="ŸÖÿ™ÿ£ÿ≥ŸÅÿßŸÜŸá ÿß€åŸÜ ÿßÿ∑ŸÑÿßÿπÿßÿ™ ÿ±Ÿà ŸÜÿØÿßÿ±ŸÖ. ŸÖ€å‚Äåÿ™ŸàŸÜŸÖ ÿ®Ÿáÿ™ ÿØÿ±ÿ®ÿßÿ±Ÿá ŸÖÿ≠ÿµŸàŸÑÿßÿ™ ÿßÿµŸÑ€å‚ÄåŸÖŸàŸÜ ⁄©ŸÖ⁄© ⁄©ŸÜŸÖÿå €åÿß ŸÖ€å‚ÄåÿÆŸàÿß€å ÿ®ÿß ÿ™€åŸÖ Ÿæÿ¥ÿ™€åÿ®ÿßŸÜ€å ÿµÿ≠ÿ®ÿ™ ⁄©ŸÜ€åÿü",
        verbose_name="üì¢ Knowledge Limitation Response (Ÿæÿßÿ≥ÿÆ ŸÖÿ≠ÿØŸàÿØ€åÿ™ ÿØÿßŸÜÿ¥)",
        help_text=(
            "Ÿæÿßÿ≥ÿÆ Ÿæ€åÿ¥‚ÄåŸÅÿ±ÿ∂ ŸàŸÇÿ™€å AI ÿßÿ∑ŸÑÿßÿπÿßÿ™ ŸÜÿØÿßÿ±ÿØ.\n"
            "ŸÖ€å‚Äåÿ™ŸàÿßŸÜ€åÿØ ÿßÿ≤ placeholder {contact_method} ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ.\n"
            "ŸÖÿ´ÿßŸÑ: 'ÿß€åŸÜ ÿßÿ∑ŸÑÿßÿπÿßÿ™ ÿ±Ÿà ŸÜÿØÿßÿ±ŸÖÿå ŸàŸÑ€å ÿßÿ≤ {contact_method} ÿ®Ÿæÿ±ÿ≥'"
        )
    )
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìå SECTION 6: Link & URL Handling
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    link_handling_rules = models.TextField(
        max_length=500,
        default="""üîó LINK RULES:
1. For IMPORTANT links (website/product): [[CTA:ÿπŸÜŸàÿßŸÜ|https://url]]
   Example: [[CTA:ÿ≥ÿß€åÿ™ ŸÖÿß|https://pilito.com]]
2. For casual links: plain URL (https://...)
3. NEVER use placeholders like [link] or invent URLs""",
        verbose_name="üîó Link & URL Handling (ŸÖÿØ€åÿ±€åÿ™ ŸÑ€åŸÜ⁄©‚ÄåŸáÿß)",
        help_text=(
            "‚ö†Ô∏è ÿ®ÿ≥€åÿßÿ± ŸÖŸáŸÖ: ŸÇŸàÿßŸÜ€åŸÜ ÿ®ÿ±ÿß€å ÿßÿ±ÿ≥ÿßŸÑ ŸÑ€åŸÜ⁄© Ÿà URL.\n"
            "ÿ¥ÿßŸÖŸÑ: ŸÅÿ±ŸÖÿ™ CTA ÿ®ÿ±ÿß€å ÿØ⁄©ŸÖŸá‚ÄåŸáÿß€å ÿß€åŸÜÿ≥ÿ™ÿß⁄Øÿ±ÿßŸÖ [[CTA:ÿπŸÜŸàÿßŸÜ|URL]]\n"
            "ÿ¨ŸÑŸà⁄Ø€åÿ±€å ÿßÿ≤ ŸÑ€åŸÜ⁄©‚ÄåŸáÿß€å ŸÜÿßŸÇÿµ €åÿß ÿ¨ÿπŸÑ€å."
        )
    )
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìå SECTION 7: Advanced (Optional)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    custom_instructions = models.TextField(
        max_length=2000,
        blank=True,
        null=True,
        verbose_name="‚ö° Custom Instructions (ÿØÿ≥ÿ™Ÿàÿ±ÿßÿ™ ÿ≥ŸÅÿßÿ±ÿ¥€å - ÿßÿÆÿ™€åÿßÿ±€å)",
        help_text=(
            "ÿØÿ≥ÿ™Ÿàÿ±ÿßÿ™ ÿßÿ∂ÿßŸÅ€å ⁄©Ÿá ÿØÿ± ÿ®ÿÆÿ¥‚ÄåŸáÿß€å ÿ®ÿßŸÑÿß ŸÜ⁄ØŸÜÿ¨€åÿØŸá ÿßÿ≥ÿ™.\n"
            "ÿß€åŸÜ ÿ®ÿÆÿ¥ ÿ®ÿ±ÿß€å ŸÜ€åÿßÿ≤Ÿáÿß€å ÿÆÿßÿµ Ÿà ŸÖŸÜÿ≠ÿµÿ± ÿ®Ÿá ŸÅÿ±ÿØ ÿ¥ŸÖÿßÿ≥ÿ™.\n"
            "ÿß⁄Øÿ± ŸÜ€åÿßÿ≤€å ŸÜÿØÿßÿ±€åÿØ ÿÆÿßŸÑ€å ÿ®⁄Øÿ∞ÿßÿ±€åÿØ."
        )
    )
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìå DEPRECATED FIELD (for backward compatibility)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    auto_prompt = models.TextField(
        max_length=5000,
        default='''You are an AI customer service representative.
Respond to customer inquiries professionally and helpfully.
Always respond in the same language the customer uses.
Keep your responses clear and concise.

üîó CRITICAL - Links & URLs:
- Always include FULL URLs (e.g., https://fiko.net/pricing)
- NEVER use placeholders like [link] or [URL]
- Write complete clickable links in your responses''',
        blank=True,
        null=True,
        verbose_name="‚ö†Ô∏è [DEPRECATED] Old Auto Prompt",
        help_text=(
            "‚ö†Ô∏è ÿß€åŸÜ ŸÅ€åŸÑÿØ ŸÖŸÜÿ≥ŸàÿÆ ÿ¥ÿØŸá ÿßÿ≥ÿ™ (Deprecated).\n"
            "ÿßÿ≤ ŸÅ€åŸÑÿØŸáÿß€å ÿ¨ÿØ€åÿØ ÿ®ÿßŸÑÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ.\n"
            "ÿß€åŸÜ ŸÅ€åŸÑÿØ ŸÅŸÇÿ∑ ÿ®ÿ±ÿß€å ÿ≥ÿßÿ≤⁄Øÿßÿ±€å ÿ®ÿß ŸÜÿ≥ÿÆŸá‚ÄåŸáÿß€å ŸÇÿØ€åŸÖ ŸÜ⁄ØŸá ÿØÿßÿ¥ÿ™Ÿá ÿ¥ÿØŸá."
        )
    )
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìå API Keys
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    gemini_api_key = models.CharField(
        max_length=200,
        null=True,
        blank=True,
        verbose_name="üîë Gemini API Key",
        help_text="⁄©ŸÑ€åÿØ API ⁄ØŸà⁄ØŸÑ ÿ¨ŸÖ€åŸÜÿß€å ÿ®ÿ±ÿß€å ÿ≥ÿ±Ÿà€åÿ≥‚ÄåŸáÿß€å ŸáŸàÿ¥ ŸÖÿµŸÜŸàÿπ€å"
    )
    openai_api_key = models.CharField(
        max_length=200,
        null=True,
        blank=True,
        verbose_name="üîë OpenAI API Key",
        help_text="⁄©ŸÑ€åÿØ API ÿßŸàŸæŸÜ‚Äåÿß€å‚Äåÿ¢€å ÿ®ÿ±ÿß€å embedding ⁄ÜŸÜÿØÿ≤ÿ®ÿßŸÜŸá (text-embedding-3-large)"
    )
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìå Metadata
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        verbose_name = "‚öôÔ∏è General AI Settings"
        verbose_name_plural = "‚öôÔ∏è General AI Settings"

    def __str__(self):
        return "General AI Settings"
    
    def get_combined_system_prompt(self) -> str:
        """
        Combine all modular fields into one system prompt.
        This is called at runtime, NOT stored in DB.
        
        This is the STANDARD approach used by:
        - OpenAI ChatGPT
        - Intercom Fin AI
        - Zendesk AI
        
        Returns:
            str: Combined system prompt from all sections
        """
        sections = []
        
        # 1. Role & Identity
        if self.ai_role and self.ai_role.strip():
            sections.append(self.ai_role.strip())
        
        # 2. Language Rules
        if self.language_rules and self.language_rules.strip():
            sections.append(f"üß† Language:\n{self.language_rules.strip()}")
        
        # 3. Tone & Style
        if self.tone_and_style and self.tone_and_style.strip():
            sections.append(f"üí¨ Style:\n{self.tone_and_style.strip()}")
        
        # 4. Response Guidelines
        if self.response_guidelines and self.response_guidelines.strip():
            guidelines = self.response_guidelines.strip()
            # Add length preference
            length_note = {
                'concise': 'Keep responses CONCISE (1-2 sentences max)',
                'moderate': 'Keep responses MODERATE (2-4 sentences)',
                'detailed': 'Provide DETAILED responses (4+ sentences when needed)'
            }.get(self.response_length, '')
            
            if length_note:
                guidelines = f"{length_note}\n{guidelines}"
            
            sections.append(f"üìù Response Guidelines:\n{guidelines}")
        
        # 5. Greeting Rules
        if self.greeting_rules and self.greeting_rules.strip():
            sections.append(f"üéØ Greeting Rules:\n{self.greeting_rules.strip()}")
        
        # 6. Anti-Hallucination (CRITICAL!)
        if self.anti_hallucination_rules and self.anti_hallucination_rules.strip():
            rules = self.anti_hallucination_rules.strip()
            
            # ‚úÖ Hard cap at 800 characters to prevent token budget overflow
            if len(rules) > 800:
                rules = rules[:800] + "\n\n‚ö†Ô∏è (ŸÇŸàÿßŸÜ€åŸÜ ⁄©ÿßŸÖŸÑ ÿ®Ÿá ÿØŸÑ€åŸÑ ŸÖÿ≠ÿØŸàÿØ€åÿ™ ÿ™Ÿà⁄©ŸÜ trim ÿ¥ÿØŸÜÿØ - ÿßÿµŸàŸÑ ⁄©ŸÑ€åÿØ€å ÿ≠ŸÅÿ∏ ÿ¥ÿØŸá‚ÄåÿßŸÜÿØ)"
            
            sections.append(f"üö® CRITICAL - Anti-Hallucination:\n{rules}")
            
            if self.knowledge_limitation_response and self.knowledge_limitation_response.strip():
                sections.append(f"When lacking information, respond with:\n{self.knowledge_limitation_response.strip()}")
        
        # 7. Link Handling (CRITICAL!)
        if self.link_handling_rules and self.link_handling_rules.strip():
            sections.append(f"üîó CRITICAL - Links & URLs:\n{self.link_handling_rules.strip()}")
        
        # 8. Custom Instructions
        if self.custom_instructions and self.custom_instructions.strip():
            sections.append(f"‚ö° Additional Instructions:\n{self.custom_instructions.strip()}")
        
        # Combine all sections
        combined = "\n\n".join(sections)
        
        # Fallback to deprecated auto_prompt if nothing configured
        if not combined and self.auto_prompt:
            return self.auto_prompt
        
        return combined or "You are a helpful AI assistant."
    
    @classmethod
    def get_settings(cls):
        """Get or create the general settings instance"""
        settings, created = cls.objects.get_or_create(pk=1)
        return settings


class AIBehaviorSettings(models.Model):
    """
    Per-User AI Behavior Customization
    
    Allows each business owner (User = Tenant in current architecture) to customize
    AI personality and behavior without writing prompts. Uses toggle-based approach
    for simplicity.
    
    Architecture Note:
    - In current system: User = Business Owner = Tenant
    - Each User has ONE AIBehaviorSettings (OneToOne)
    - If future multi-staff support needed, this will need refactoring
    
    Integration Points:
    - GeminiChatService.__init__() ‚Üí max_output_tokens based on response_length
    - GeminiChatService._build_prompt() ‚Üí inject behavior flags
    - Greeting logic ‚Üí use_customer_name toggle
    - Bio injection ‚Üí use_bio_context toggle
    - Fallback handling ‚Üí unknown_fallback_text
    
    Token Budget:
    - Flag-based approach uses ~30-40 tokens (vs 150-200 for descriptive)
    - CTA text: max 300 chars (~75 tokens)
    - Fallback text: max 500 chars (~125 tokens)
    - Custom instructions: max 1000 chars (~250 tokens)
    - Total: ~400 tokens max (well within 700 token system prompt budget)
    """
    
    user = models.OneToOneField(
        User,
        on_delete=models.CASCADE,
        related_name='ai_behavior',
        verbose_name="⁄©ÿßÿ±ÿ®ÿ± / ÿµÿßÿ≠ÿ® ⁄©ÿ≥ÿ®‚ÄåŸà⁄©ÿßÿ±"
    )
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìå SECTION 1: Persona (AI Personality)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    TONE_CHOICES = [
        ('formal', 'üé© ÿ±ÿ≥ŸÖ€å Ÿà ÿ≠ÿ±ŸÅŸá‚Äåÿß€å'),
        ('friendly', 'üòä ÿØŸàÿ≥ÿ™ÿßŸÜŸá Ÿà ÿµŸÖ€åŸÖ€å'),
        ('energetic', '‚ö° Ÿæÿ±ÿßŸÜÿ±⁄ò€å Ÿà Ÿá€åÿ¨ÿßŸÜ‚ÄåÿßŸÜ⁄Ø€åÿ≤'),
        ('empathetic', 'ü§ù ŸáŸÖÿØŸÑÿßŸÜŸá Ÿà ÿ≠ŸÖÿß€åÿ™⁄Øÿ±'),
    ]
    tone = models.CharField(
        max_length=20,
        choices=TONE_CHOICES,
        default='friendly',
        verbose_name="ŸÑÿ≠ŸÜ ÿµÿ≠ÿ®ÿ™",
        help_text="ÿ™ÿπ€å€åŸÜ ⁄©ŸÜ€åÿØ AI ÿ®ÿß ⁄ÜŸá ŸÑÿ≠ŸÜ€å ÿ®ÿß ŸÖÿ¥ÿ™ÿ±€å‚ÄåŸáÿß ÿµÿ≠ÿ®ÿ™ ⁄©ŸÜÿØ"
    )
    
    EMOJI_CHOICES = [
        ('none', '‚õî Ÿá€å⁄Ü - ÿ®ÿØŸàŸÜ ÿß€åŸÖŸàÿ¨€å'),
        ('moderate', 'üôÇ ŸÖÿ™ÿπÿßÿØŸÑ - ⁄©ŸÖ€å ÿß€åŸÖŸàÿ¨€å'),
        ('high', 'üòç ÿ≤€åÿßÿØ - Ÿæÿ± ÿßÿ≤ ÿß€åŸÖŸàÿ¨€å'),
    ]
    emoji_usage = models.CharField(
        max_length=20,
        choices=EMOJI_CHOICES,
        default='moderate',
        verbose_name="ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿß€åŸÖŸàÿ¨€å",
        help_text="ŸÖ€åÿ≤ÿßŸÜ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿß€åŸÖŸàÿ¨€å ÿØÿ± Ÿæÿßÿ≥ÿÆ‚ÄåŸáÿß"
    )
    
    LENGTH_CHOICES = [
        ('short', 'üîπ ⁄©Ÿàÿ™ÿßŸá - 1-2 ÿ¨ŸÖŸÑŸá'),
        ('balanced', 'üî∏ ŸÖÿ™ÿπÿßÿØŸÑ - 3-4 ÿ¨ŸÖŸÑŸá'),
        ('detailed', 'üî∂ ÿ™ŸÅÿµ€åŸÑ€å - 5-7 ÿ¨ŸÖŸÑŸá'),
    ]
    response_length = models.CharField(
        max_length=20,
        choices=LENGTH_CHOICES,
        default='balanced',
        verbose_name="ÿ∑ŸàŸÑ Ÿæÿßÿ≥ÿÆ",
        help_text="ÿ™ÿπ€å€åŸÜ ⁄©ŸÜ€åÿØ Ÿæÿßÿ≥ÿÆ‚ÄåŸáÿß ⁄ÜŸÇÿØÿ± ÿ∑ŸàŸÑÿßŸÜ€å ÿ®ÿßÿ¥ŸÜÿØ"
    )
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìå SECTION 2: Behavioral Controls
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    use_customer_name = models.BooleanField(
        default=True,
        verbose_name="ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ŸÜÿßŸÖ ŸÖÿ¥ÿ™ÿ±€å",
        help_text="ÿß⁄Øÿ± ŸÅÿπÿßŸÑ ÿ®ÿßÿ¥ÿØÿå AI ŸÜÿßŸÖ ŸÖÿ¥ÿ™ÿ±€å ÿ±ÿß ÿØÿ± ÿ≥ŸÑÿßŸÖ ÿµÿØÿß ŸÖ€å‚Äåÿ≤ŸÜÿØ"
    )
    
    use_bio_context = models.BooleanField(
        default=True,
        verbose_name="ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿßÿ∑ŸÑÿßÿπÿßÿ™ ÿ®€åŸà",
        help_text="ÿß⁄Øÿ± ŸÅÿπÿßŸÑ ÿ®ÿßÿ¥ÿØÿå AI ÿßÿ≤ ÿ®€åŸà ŸÖÿ¥ÿ™ÿ±€å ÿ®ÿ±ÿß€å ÿ¥ÿÆÿµ€å‚Äåÿ≥ÿßÿ≤€å ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€å‚Äå⁄©ŸÜÿØ"
    )
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìå SECTION 3: Persuasive Selling
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    persuasive_selling_enabled = models.BooleanField(
        default=False,
        verbose_name="ŸÅÿ±Ÿàÿ¥ ŸÅÿπÿßŸÑ",
        help_text="ÿß⁄Øÿ± ŸÅÿπÿßŸÑ ÿ®ÿßÿ¥ÿØÿå AI ÿ®Ÿá ÿµŸàÿ±ÿ™ ŸÅÿπÿßŸÑ ŸÖÿ≠ÿµŸàŸÑÿßÿ™ ÿ±ÿß Ÿæ€åÿ¥ŸÜŸáÿßÿØ ŸÖ€å‚ÄåÿØŸáÿØ"
    )
    
    persuasive_cta_text = models.CharField(
        max_length=300,
        blank=True,
        default="ÿ¢€åÿß ŸÖ€å‚ÄåÿÆŸàÿßŸá€åÿØ ÿß€åŸÜ ŸÖÿ≠ÿµŸàŸÑ ÿ±ÿß ÿ≥ŸÅÿßÿ±ÿ¥ ÿØŸá€åÿØÿü üõí",
        verbose_name="ŸÖÿ™ŸÜ ÿØÿπŸàÿ™ ÿ®Ÿá ÿßŸÇÿØÿßŸÖ (CTA)",
        help_text="ŸÖÿ™ŸÜ€å ⁄©Ÿá AI ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿ∑ÿ®€åÿπ€å ÿØÿ± Ÿæ€åÿßŸÖ‚ÄåŸáÿß€å ŸÅÿ±Ÿàÿ¥ ŸÖ€å‚Äå⁄ØŸÜÿ¨ÿßŸÜÿØ (ÿ≠ÿØÿß⁄©ÿ´ÿ± 300 ⁄©ÿßÿ±ÿß⁄©ÿ™ÿ±)"
    )
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìå SECTION 4: Response Rules
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    unknown_fallback_text = models.CharField(
        max_length=500,
        default="ŸÖŸÜ ÿØÿ± ÿ≠ÿßŸÑ ÿ≠ÿßÿ∂ÿ± Ÿæÿßÿ≥ÿÆ ÿØŸÇ€åŸÇ ÿß€åŸÜ ÿ≥ŸàÿßŸÑ ÿ±ÿß ŸÜÿØÿßÿ±ŸÖÿå ÿßŸÖÿß ŸáŸÖ⁄©ÿßÿ±ÿßŸÜŸÖ ÿ®Ÿá ÿ≤ŸàÿØ€å Ÿæÿßÿ≥ÿÆ ÿ¥ŸÖÿß ÿ±ÿß ÿÆŸàÿßŸáŸÜÿØ ÿØÿßÿØ.",
        verbose_name="Ÿæÿßÿ≥ÿÆ ÿπÿØŸÖ ÿßÿ∑ŸÑÿßÿπ",
        help_text="ÿØŸÇ€åŸÇÿßŸã ÿß€åŸÜ ŸÖÿ™ŸÜ ÿ±ÿß ÿ®ÿ±⁄Øÿ±ÿØÿßŸÜ ŸàŸÇÿ™€å ÿ¨Ÿàÿßÿ® ÿ≥ŸàÿßŸÑ ÿ±ÿß ŸÜŸÖ€å‚ÄåÿØÿßŸÜ€å (ÿ≠ÿØÿß⁄©ÿ´ÿ± 500 ⁄©ÿßÿ±ÿß⁄©ÿ™ÿ±)"
    )
    
    custom_instructions = models.TextField(
        max_length=1000,
        blank=True,
        null=True,
        verbose_name="ÿØÿ≥ÿ™Ÿàÿ±ÿßÿ™ ÿßÿ∂ÿßŸÅ€å",
        help_text="ŸÇŸàÿßŸÜ€åŸÜ ÿßÿ∂ÿßŸÅ€å ÿ®ÿ±ÿß€å AI ÿ®Ÿá ÿ≤ÿ®ÿßŸÜ ÿßŸÜ⁄ØŸÑ€åÿ≥€å (ÿßÿÆÿ™€åÿßÿ±€åÿå ÿ≠ÿØÿß⁄©ÿ´ÿ± 1000 ⁄©ÿßÿ±ÿß⁄©ÿ™ÿ±)"
    )
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìå Metadata
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = "üé≠ AI Behavior Settings"
        verbose_name_plural = "üé≠ AI Behavior Settings"
        db_table = "settings_ai_behavior"
    
    def __str__(self):
        return f"AI Behavior for {self.user.username}"
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìå Core Methods
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def get_prompt_additions(self) -> str:
        """
        Generate structured flags for AI behavior interpretation.
        
        Uses flag-based approach (not descriptive text) for:
        - Lower token consumption (~30 tokens vs 150-200)
        - Centralized behavior mapping in Mother Prompt
        - Easier A/B testing and modifications
        - Consistent with modern LLM structured outputs
        
        Mother Prompt should contain interpretation rules like:
        [TONE=friendly] ‚Üí Use friendly, casual language
        [EMOJI=moderate] ‚Üí Use 1-2 emojis per message
        [LENGTH=short] ‚Üí Keep responses to 1-2 sentences
        
        Returns:
            str: Space-separated flags for injection into prompt
        """
        flags = []
        
        # Core personality flags (always in English for consistency)
        flags.append(f"[TONE={self.tone}]")
        flags.append(f"[EMOJI={self.emoji_usage}]")
        flags.append(f"[LENGTH={self.response_length}]")
        flags.append(f"[USE_NAME={'yes' if self.use_customer_name else 'no'}]")
        flags.append(f"[USE_BIO={'yes' if self.use_bio_context else 'no'}]")
        flags.append(f"[PERSUASIVE={'on' if self.persuasive_selling_enabled else 'off'}]")
        
        # Fallback text for when AI doesn't know the answer (CRITICAL!)
        if self.unknown_fallback_text and self.unknown_fallback_text.strip():
            fallback_clean = self.unknown_fallback_text.strip().replace('\n', ' ')[:200]
            flags.append(f"[FALLBACK_TEXT={fallback_clean}]")
        
        # CTA text (can be Persian - it's content, not instruction)
        if self.persuasive_selling_enabled and self.persuasive_cta_text.strip():
            cta_clean = self.persuasive_cta_text.strip().replace('\n', ' ')[:250]
            flags.append(f"[CTA={cta_clean}]")
        
        # Custom instructions (should be in English for consistency)
        if self.custom_instructions and self.custom_instructions.strip():
            custom_clean = self.custom_instructions.strip().replace('\n', ' ')[:500]
            flags.append(f"[CUSTOM={custom_clean}]")
        
        return " ".join(flags)
    
    def get_max_output_tokens(self) -> int:
        """
        Calculate max output tokens based on response_length preference.
        
        Token allocation aligned with actual response needs:
        - short: 400 tokens (~250-300 Persian words, 1-2 short paragraphs)
        - balanced: 700 tokens (~450-500 words, 2-3 paragraphs) [DEFAULT]
        - detailed: 1200 tokens (~800-900 words, 3-5 detailed paragraphs)
        
        These limits ensure:
        1. AI has enough tokens to complete thought
        2. Responses stay within user preference
        3. Total budget (input + output) stays safe:
           - Max input: 2200 tokens (TokenBudgetController)
           - Max output: 1200 tokens (this method)
           - Total: 3400 tokens << Gemini context window (1M tokens) ‚úÖ
        
        Returns:
            int: Maximum output tokens for this user's preference
        """
        token_limits = {
            'short': 400,      # Short but complete (1-2 paragraphs)
            'balanced': 700,   # Balanced explanation (2-3 paragraphs)
            'detailed': 1200,  # Detailed response (3-5 paragraphs)
        }
        return token_limits.get(self.response_length, 700)
    
    def get_fallback_text(self) -> str:
        """
        Get exact text to return when AI lacks information.
        
        This is NOT a prompt instruction - it's the actual message text
        that will be sent to the customer. Detection logic stays centralized,
        only the output text is per-user customizable.
        
        Returns:
            str: Exact customer-facing message (Persian or any language)
        """
        return self.unknown_fallback_text.strip()
    
    def should_use_bio_context(self) -> bool:
        """Check if bio context should be injected into prompt"""
        return self.use_bio_context
    
    def should_use_customer_name(self) -> bool:
        """Check if customer name should be used in greeting"""
        return self.use_customer_name


class Settings(SingletonModel):
    IR_yearly = models.IntegerField(default=0)
    IR_monthly = models.IntegerField(default=0)
    TR_yearly = models.IntegerField(default=0)
    TR_monthly = models.IntegerField(default=0)
    EN_yearly = models.IntegerField(default=0)
    EN_monthly = models.IntegerField(default=0)
    token1M = models.IntegerField(default=0)
    token3M = models.IntegerField(default=0)
    token5M = models.IntegerField(default=0)
    token10M = models.IntegerField(default=0)
    email1K = models.IntegerField(default=0)
    email3K = models.IntegerField(default=0)
    email5K = models.IntegerField(default=0)
    email10K = models.IntegerField(default=0)

    class Meta:
        verbose_name = "üí∞ System Settings"
        verbose_name_plural = "üí∞ System Settings"

    def __str__(self):
        return str(self.IR_yearly) + " | " + str(self.IR_monthly) + " | " + str(self.EN_yearly) + " | " + str(self.EN_monthly)

class BusinessPrompt(models.Model):
    name = models.CharField(max_length=200, help_text="Name of the business prompt")
    prompt = models.TextField(help_text="The business prompt content")
    ai_answer_prompt = models.TextField(null=True, blank=True, help_text="AI answer prompt for responses")
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = "üíº Business Prompt"
        verbose_name_plural = "üíº Business Prompts"
        ordering = ['-updated_at']
    
    def __str__(self):
        return self.name


class UpToPro(models.Model):
    rate = models.IntegerField(help_text="Rating value")
    signedup = models.IntegerField(help_text="Number of signups")
    comment = models.TextField(help_text="User comment")
    name = models.CharField(max_length=200, help_text="User name")
    profileimage = models.ImageField(upload_to='uptopro_profiles/', null=True, blank=True, help_text="Profile image")
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = "‚≠ê UpToPro"
        verbose_name_plural = "‚≠ê UpToPros"
        ordering = ['-created_at']
    
    def __str__(self):
        return f"{self.name} - Rating: {self.rate}"


class AffiliationConfig(SingletonModel):
    """
    Affil

iate/Referral System Configuration
    
    This model stores the commission percentage for the affiliate reward system.
    Only one instance can exist (singleton pattern).
    
    When a referred user makes a payment, X% commission is automatically
    added to the referring user's wallet balance.
    """
    percentage = models.DecimalField(
        max_digits=5,
        decimal_places=2,
        default=10.00,
        verbose_name="Commission Percentage (%)",
        help_text="Percentage of payment to give as commission to referring user (e.g., 10 = 10%)"
    )
    is_active = models.BooleanField(
        default=True,
        verbose_name="Affiliate System Active",
        help_text="Enable or disable the entire affiliate reward system"
    )
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = "ü§ù Affiliation Configuration"
        verbose_name_plural = "ü§ù Affiliation Configuration"
    
    def __str__(self):
        status = "Active" if self.is_active else "Inactive"
        return f"Affiliate System: {self.percentage}% ({status})"
    
    @classmethod
    def get_config(cls):
        """Get or create the affiliation config instance"""
        config, created = cls.objects.get_or_create(pk=1)
        return config
    
    def calculate_commission(self, amount):
        """Calculate commission amount from payment"""
        from decimal import Decimal
        # Ensure both amount and percentage are Decimal for proper calculation
        amount_decimal = Decimal(str(amount))
        percentage_decimal = Decimal(str(self.percentage))
        commission = (amount_decimal * percentage_decimal / Decimal('100')).quantize(Decimal('0.01'))
        return commission